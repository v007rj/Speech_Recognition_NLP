{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IPython & Jupyter: a PyCon 2017 tutorial"},{"metadata":{"trusted":true},"cell_type":"code","source":"import feedparser\n\nFEED_URL='http://feeds.feedburner.com/oreilly/radar/atom'\n\nfp = feedparser.parse(FEED_URL)\n\nfor e in fp.entries:\n    print (e.title)\n    print (e.links[0].href)\n    print (e.content[0].value)","execution_count":16,"outputs":[{"output_type":"stream","text":"Four short links: 20 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/N8IwquLjmkk/\n<ol>\n<li><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3409578\">The Paradox of Source Code Secrecy</a> &#8212; <i>In a world of privatized decisionmaking, the largely consistent move towards closed code in software sectors, has a number of deleterious results for the public, particularly in the age of algorithmic dominance. However, this Article argues that source code also carries a paradoxical character that is peculiar to software: the very substance of what is secluded often stems from the most public of origins, and often produces the most public of implications. And it is the failures of intellectual property law that has made this possible.</i></li>\n<li><a href=\"https://github.com/chaskiq/chaskiq\">Chaskiq</a> &#8212; <i>Open source messaging platform for marketing, support, &amp; sales.</i> Chat, bots, video, conversation routing, and more.</li>\n<li><a href=\"https://webperl.zero-g.net/\">WebPerl</a> &#8212; The perl interpreter in WebAssembly, so you can put Perl code into your web pages. I&#8217;m not sure many people were itching to do this, but it shows how WebAssembly opens doors.</li>\n<li><a href=\"https://cset.georgetown.edu/wp-content/uploads/CSET-A-National-Security-Research-Agenda-for-Cybersecurity-and-Artificial-Intelligence.pdf\">A National Security Research Agenda for Cybersecurity and Artificial Intelligence</a> &#8212; GWU&#8217;s collection of questions and subjects for research in cybersecurity and intelligence. <i>Four components: offense (vulnerability discovery, spear-phishing, propagation, obfuscation &amp; anti-forensics, destructive-power), defense (detection, interdiction, attribution), adversarial learning (adversarial examples, data poisoning, data pipeline manipulation, model inversion), and overarching questions (cyber-accidents, influence campaigns, speed, offense-defense balance, proliferation, strategic stability).</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/N8IwquLjmkk\" height=\"1\" width=\"1\" alt=\"\"/>\nCloud Adoption in 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/CvXGdmdKaRw/\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<p class=\"has-text-color has-background has-small-font-size has-very-dark-gray-color has-very-light-gray-background-color\">To continue learning and to get ahead with your career, check out O&#8217;Reilly Learning with a free trial.  Live online training, videos, books, certification prep, and more, from O&#8217;Reilly and our partner publishers.</p>\n\n\n\n<div class=\"wp-block-button\"><a class=\"wp-block-button__link has-text-color has-vivid-red-color has-background has-very-light-gray-background-color\" href=\"https://www.oreilly.com/\">O&#8217;Reilly Learning &gt;</a></div>\n<br />\n</div></div>\n</div></div>\n\n\n\n<br />\n<br />\n\n\n\n<p>We wanted to discover what our readers were doing with cloud, microservices, and other critical infrastructure and operations technologies. So we constructed a survey and ran it earlier this year: from January 9th through January 31st, 2020. All told, we received 1,283 responses.</p>\n\n\n\n<p>A lot happened between January and the first week of March, when we got around to analyzing our survey data. It seemed clear to us that the world we’d captured in our survey was going to change (if it hadn’t already)—that some trends would accelerate, that some would decelerate, and that things would never be quite the same. It seems to us that the results of our survey offer a point-in-time snapshot of the latest trends in cloud, microservices, distributed application development, and other emergent areas. Not only do they capture where organizations are, but, more important, they illuminate how they will evolve. We will spend months or even years trying to determine the extent to which we must recalibrate our best-laid plans and assumptions. And as we do so, we will look to surveys like this one as lodestars.</p>\n\n\n\n<p>Without further ado, here are the key results:</p>\n\n\n\n<p>• At first glance, cloud usage seems overwhelming. More than 88% percent of respondents use cloud in one form or another. Most respondent organizations also expect to grow their usage over the next 12 months.<br><br>• A surprising number of respondents—about 25%—said that their companies plan to move <em>all</em> of their applications to a cloud context in the next year. This includes 17% of respondents from large organizations (over 10,000 employees) that have already moved 100% of their applications to the cloud.<br><br>• Public cloud dominates, but most organizations use a mix of cloud options; almost half (49%) continue to run applications in traditional, on-premises contexts.<br><br>• More than half of respondents use multiple cloud services.<br><br>• AWS is far and away the cloud leader, followed by Azure (at more than half of share) and Google Cloud. But most Azure and GCP users also use AWS; the reverse isn’t necessarily true.<br><br>• More than half of respondent organizations use microservices.<br><br>• More than <em>one-third</em> have adopted site reliability engineering<br> (SRE); slightly less have developed production AI services. For<br> this audience, SRE’s future is brighter than AI’s, however.</p>\n\n\n\n<h2>Respondent Demographics</h2>\n\n\n\n<p>Software engineers represent the largest cohort, comprising almost 20% of all respondents (see <a data-type=\"xref\" href=\"#fig_1\">Figure 1</a>). Technical leads and architects (about 11%) are next, followed by software and systems architects (9+%). For the sample as a whole, most respondents (approximately 60%) occupy technical positions. However, a notable minority—some 15%—occupy C-level or executive roles. And about 10% work in technical management positions. That results in roughly 25% share for managers and executives. The “Other” category had a good mix of technical positions (e.g., network engineer, at &gt;2%) and management positions (IT manager, at close to 3%; operations manager at &gt;1%).</p>\n\n\n\n<figure class=\"wp-block-image size-large\" id=\"fig_1\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0101-1048x504.png\" alt=\"\" class=\"wp-image-12818\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0101-1048x504.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0101-300x144.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0101-768x370.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0101.png 1436w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 1. Role of survey respondents</figcaption></figure>\n\n\n\n<p>A significant minority of respondents (22%) have worked in their roles for more than 10 years; the largest single bloc—almost 34% of all respondents—for between one to three years (<a data-type=\"xref\" href=\"#fig_2\">Figure 2</a>). There is atypical longevity in the survey audience: almost 55% have worked in their roles for at least four years, and a surprising number (almost 13%), for more than 12 years. It is a more experienced group than we’re used to seeing in our Radar surveys. The maturity of this audience could be a reflection of the maturity of the topic. Still, a solid third of respondents have between one to three years of experience.</p>\n\n\n\n<figure class=\"wp-block-image size-large\" id=\"fig_2\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0102-1048x634.png\" alt=\"\" class=\"wp-image-12819\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0102-1048x634.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0102-300x181.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0102-768x464.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0102.png 1085w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 2. Length of time in current role</figcaption></figure>\n\n\n\n<p>Almost one-quarter (23%) of respondents work in the software<br> industry (<a data-type=\"xref\" href=\"#fig_3\">Figure 3</a>). Finance and banking (&gt;11%) is the second-largest vertical, followed closely by consulting and professional services (also &gt;11%).</p>\n\n\n\n<figure class=\"wp-block-image size-large\" id=\"fig_3\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0103-1048x732.png\" alt=\"\" class=\"wp-image-12822\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0103-1048x732.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0103-300x210.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0103-768x536.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0103.png 1423w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 3. Industry of survey respondents</figcaption></figure>\n\n\n\n<p>We’re used to seeing these three verticals dominate representation in our Radar surveys. At 23%, however, the software vertical is significantly overrepresented, at least relative to prior surveys. Consulting and professional services, by contrast, could be slightly underrepresented. This may be a source of bias. We imagine that companies in the software industry are more likely to be early (or mid-stage) adopters of technologies like cloud computing.</p>\n\n\n\n<p>There’s a good mix between large and small firms. About half of all respondents work in organizations with fewer than 1,000 employees. More than a quarter work with very large organizations—i.e., 10,000 or more employees. And about 28% work for small outfits of between one and 100 people.</p>\n\n\n\n<p>About two-thirds of respondents work in North America. The next largest region, Asia, is home to about 15% of all respondents. Europe, which in most Radar surveys constitutes the second-largest respondent bloc, was third, accounting for just 11% of all participants. This survey’s disproportionate tilt toward North America is unusual. In our <a href=\"https://oreil.ly/F33Ir\">AI adoption in the enterprise survey</a>, for example, we had close to a 50/50 split between North America and the rest of the world.<sup>1</sup> Regional representation in Radar surveys typically tracks with usage on the O’Reilly learning platform. North American users account for about half of activity on the O’Reilly platform. That isn’t the case here. Again, this is a source of bias: companies in some European countries are much more hesitant about moving workloads to the cloud.</p>\n\n\n\n<h2>Almost Completely Cloud-y</h2>\n\n\n\n<p>Slightly more than 88% of respondent organizations use cloud computing. Just 10% of respondents say they don’t use cloud computing <em>at all</em>, however. If this seems anomalously high, it shouldn’t.</p>\n\n\n\n<p>A strict definition of “cloud” must also include software-as-a-service (SaaS) and platform-as-a-service (PaaS) offerings of all kinds—including email (Google G Suite email; Microsoft Exchange Online), office productivity suites (Google Docs and Sheets; Microsoft Office 365), and similar offerings. Designing a survey inevitably entails making a spate of methodological trade-offs. We <em>could</em> have specified a narrow definition of cloud—inclusive of the SaaS, PaaS, and infrastructure-as-a-service (IaaS) cloud; exclusive of cloud-based email, office productivity, etc.—but the fact remains that a proportion of enterprises either outsource their email hosting to Google, Microsoft, and other providers <em>or</em> subscribe to cloud office productivity services that (in most cases) bundle email hosting, too. These services are also designed to function as gateway drugs to cloud services: e.g., Microsoft integrates its on- and off-premises Excel client experience with its PowerBI cloud analytics service, as well as with its ecosystem of Azure-based advanced analytics and machine learning (ML) services.</p>\n\n\n\n<p>This brings up another, related issue: how much visibility do survey respondents actually have with respect to how and where cloud gets used in their organizations? It’s likely that most respondents lack complete visibility into and across their organizations; in a large enterprise, for example, few if any people have this kind of panoptic view. When we took all of these considerations into account, a more-inclusive frame for cloud adoption made the most sense to us. It encompasses private clouds, the IaaS cloud—also host to virtual private clouds (VPC)—and the PaaS and SaaS clouds. It is less concerned with formal definitions<sup>2</sup> and captures the point-in-time totality of cloud adoption.</p>\n\n\n\n<p>Among non-adopters, culture seems to be the biggest impediment to cloud adoption: just under 5% of non-adopters cited an “organizational preference to keep data on premises” (<a data-type=\"xref\" href=\"#fig_4\">Figure 4</a>). More than 2% cited regulatory concerns as a bulwark to adoption, while a still larger proportion—close to 3%—cited risk, especially with respect to migrating on-premises workloads, services, or data to cloud. Oddly, about 3% of non-adopters cited cost as a primary reason <em>not</em> to move workloads to cloud; cost-efficiency is usually touted as one of cloud’s most attractive features.</p>\n\n\n\n<figure class=\"wp-block-image size-large\" id=\"fig_4\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0104-1048x669.png\" alt=\"\" class=\"wp-image-12834\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0104-1048x669.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0104-300x192.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0104-768x491.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0104.png 1179w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 4. Reasons why organizations have not adopted cloud computing (represents respondents who answered no to the question “Does your organization use cloud computing?”)</figcaption></figure>\n\n\n\n<p>Also of interest: close to 2% of non-adopters cited the prospect of<br> vendor lock-in as a rationale for not using cloud. All told, 22% of<br> respondents selected at least three issues; 46% chose at least two issues. Again, non-adopters comprise just 10% of the survey audience.</p>\n\n\n\n<h2>Cloud Usage Waxing, not Waning</h2>\n\n\n\n<p>Most (90%+) respondent organizations expect to increase their usage of cloud-based infrastructure. This result aligns very closely with the proportion of respondents (88%+) who have already adopted cloud. The upshot is that the overwhelming majority of adopters plan to grow, rather than reduce, their cloud usage share. Oddly, most growth seems to be happening at the extremes: almost one quarter of respondent organizations expect to move all of their applications to the cloud in the next 12 months (<a data-type=\"xref\" href=\"#fig_5\">Figure 5</a>). This was the second biggest cluster, overall. The largest cluster—at just under 34%—consists of respondents who expect to move one-quarter of their applications to the cloud in the next 12 months.</p>\n\n\n\n<figure class=\"wp-block-image size-large\" id=\"fig_5\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0105.png\" alt=\"\" class=\"wp-image-12843\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0105.png 909w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0105-300x173.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0105-768x443.png 768w\" sizes=\"(max-width: 909px) 100vw, 909px\" /><figcaption>Figure 5. Share of applications respondents expect their organizations to migrate to the cloud</figcaption></figure>\n\n\n\n<p>About 45% of respondent organizations expect to move three-quarters or more of their applications to cloud during this same period; 67% expect to shift half or more of their applications during that same period. Zoom out to 36 months, and close to 40% of all respondents expect that all of their applications will run in a cloud context—and about 63% anticipate running at least three-quarters of their applications in the cloud.<sup>3</sup> </p>\n\n\n\n<p>Taken at face value, these results suggest almost irresistible momentum in favor of cloud. Keep in mind, however, that usage share is based <em>on the applications respondents know of</em>, and that few if any respondents have a complete view of deployments across the whole of their organizations. With this caveat in mind, the results nonetheless suggest a wider embrace of cloud infrastructure and support <a rel=\"noreferrer noopener\" aria-label=\"the idea that most organizations now equate cloud with what’s next for their infrastructure decisions (opens in a new tab)\" href=\"https://www.oreilly.com/radar/what-is-next-architecture/\" target=\"_blank\">the idea that most organizations now equate cloud with what’s next for their infrastructure decisions</a>.</p>\n\n\n\n<h2>Public Cloud Dominates, but Most Organizations Opt to Mix Things Up</h2>\n\n\n\n<p>Among cloud adopters, more than 21% host all of their applications in a cloud context of one kind or another. However, organizations that host one-quarter or fewer of their applications in the cloud comprise the largest single cluster, at 39% of all respondents. As might be expected, small companies and startups are likely to host substantial proportions—in some cases, <em>all</em>—of their applications in the cloud. There were some surprises, however. For example, about 17% of companies with 10,000 or more employees host 100% of their applications in a cloud context of some kind (<a data-type=\"xref\" href=\"#fig_6\">Figure 6</a>). This number balloons to about 37% of companies with between one and 100 employees. Just under 50% of companies with 10,000 or more employees host 25% or fewer of their applications in a cloud context.</p>\n\n\n\n<figure class=\"wp-block-image size-large\" id=\"fig_6\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0106-1048x642.png\" alt=\"\" class=\"wp-image-12850\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0106-1048x642.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0106-300x184.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0106-768x471.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0106.png 1232w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 6. A comparison of respondent organization size and share of applications hosted in the cloud</figcaption></figure>\n\n\n\n<p>Public cloud is the most popular overall deployment option, with a usage share greater than 61%. Traditional, on-premises deployment—at just under half (49%) of usage share—is second. Hybrid cloud, which combines public cloud services with on-premises private cloud infrastructure, is third, with approximately 39% usage.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0107-1048x539.png\" alt=\"\" class=\"wp-image-12855\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0107-1048x539.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0107-300x154.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0107-768x395.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0107.png 1172w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 7. Cloud types used by respondents’ organizations (respondents could select all types that apply)</figcaption></figure>\n\n\n\n<p>The survey encouraged respondents to make multiple selections from among five cloud deployment options. Nearly one-tenth (9%) selected all five, and almost one-fifth (19%) selected four out of five. Almost two-thirds (64%) selected at least two cloud deployment options. The upshot is that—even though the public cloud is by far the most popular option—most respondent organizations employ a mix of cloud types. Interestingly, multi-cloud, or the use of multiple cloud computing and storage services in a single homogeneous network architecture, had the fewest users (24% of the respondents).</p>\n\n\n\n<p>However, more than half of respondents (54%) also use multiple cloud services. The poor showing for multi-cloud might be the difference between tactical/ad hoc and strategic usage. In other words, comparatively few respondent organizations appear to be pursuing <em>dedicated</em> multi-cloud strategies.</p>\n\n\n\n<h2>Amazon and AWS Ascendant</h2>\n\n\n\n<p>Not surprisingly, Amazon Web Services (AWS) is far out ahead of the rest of the pack: it’s used by more than two-thirds (~67%) of all respondents. However, close to half (~48%) use Microsoft Azure, and close to one-third (~32%) use Google Cloud Platform (GCP). Respondents were encouraged to select multiple cloud service providers; in fact, a slight majority of respondents—54%—use more than a single provider. Among cloud providers, Amazon, Microsoft, and Google dominate their rivals, with Alibaba Cloud, IBM Cloud, and Oracle Cloud garnering just under 12% of share. (The poor showing for Alibaba Cloud could be a function of the larger-thannormal North American bias in the audience, as could the representations of both IBM and Oracle, which are less.)</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0108.png\" alt=\"\" class=\"wp-image-12856\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0108.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0108-300x150.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0108-768x384.png 768w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 8. Public cloud vendors used by respondents’ organizations (respondents could select all that apply)</figcaption></figure>\n\n\n\n<p>Among respondents who use only public cloud providers, AWS’ share was even larger: it accounted for 75% of usage, compared with 52% for Azure and 34% for GCP. In fact, AWS is clearly the backstop vendor: not only does it have the highest share among respondent organizations, but—of the 54% who use at least two cloud vendors—almost all of them (93%) list AWS as one of those vendors.</p>\n\n\n\n<p>If Microsoft and Google really are coming on strong, they aren’t dislodging Amazon and AWS. If anything, organizations seem to be pursuing multi-cloud strategies—even if they aren’t explicitly “doing” multi-cloud. Among our survey respondents, multi-cloud effectively means AWS + another cloud service.</p>\n\n\n\n<h2>Microservices Achieves Critical Mass, SRE Surging</h2>\n\n\n\n<p>More than half (52%) of respondent organizations say they use microservices concepts, tools, or methods for software development. Of these, a large minority—just over 28%—have been using microservices for more than three years. This was the second-largest cluster among users of microservices. The largest, at more than 55%, has been using microservices for between one and three years. Just 17% of users are new to microservices, with less than one year of adoption and use.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0109.png\" alt=\"\" class=\"wp-image-12857\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0109.png 990w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0109-300x132.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0109-768x339.png 768w\" sizes=\"(max-width: 990px) 100vw, 990px\" /><figcaption>Figure 9. Length of time respondents’ organizations have used microservices</figcaption></figure>\n\n\n\n<p>A few caveats are in order. First, our survey didn’t ask respondents if they (or their organizations) have adopted <em>microservices architecture</em>. There’s a world of difference between experimentation and/or ad hoc usage and adoption; we saw this with agile, and—as we note below—we’re likely seeing it with SRE, too. Just because a development team uses the tools, concepts, and methods of microservices architecture doesn’t mean it has <em>adopted</em> microservices architecture. It may be that microservices patterns, as distinct to conventional software development, are well suited for the particular use case, as with video encoding, which entails multiple parallel or concurrent CPU- or GPU-intensive workloads.</p>\n\n\n\n<p>Second, there is <a rel=\"noreferrer noopener\" aria-label=\"some evidence (opens in a new tab)\" href=\"https://trends.google.com/trends/explore?date=today%205-y\" target=\"_blank\">some evidence</a> that interest in microservices might be at or close to peaking. There is <a rel=\"noreferrer noopener\" aria-label=\"also evidence (opens in a new tab)\" href=\"https://arxiv.org/pdf/1903.11665.pdf\" target=\"_blank\">also evidence</a> that <a rel=\"noreferrer noopener\" aria-label=\"decomposition (opens in a new tab)\" href=\"https://martinfowler.com/articles/break-monolith-into-microservices.html\" target=\"_blank\">decomposition</a>—at least to the degree of granularity prescribed in microservices architecture—is proving to be more difficult than anticipated. Finally, there’s the <a rel=\"noreferrer noopener\" aria-label=\"Perrow-ian (opens in a new tab)\" href=\"https://en.wikipedia.org/wiki/Normal_Accidents\" target=\"_blank\">Perrow-ian</a> critique of microservices architecture, which argues that its complexity constitutes a kind of <em>de facto</em> tight coupling that makes it impossible to anticipate potential edge cases and eliminate risk.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0110.png\" alt=\"\" class=\"wp-image-12859\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0110.png 873w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0110-300x136.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0110-768x347.png 768w\" sizes=\"(max-width: 873px) 100vw, 873px\" /><figcaption>Figure 10. Presence of a Site Reliability Engineering (SRE) team within respondents’ organizations</figcaption></figure>\n\n\n\n<p>Almost 35% of respondent organizations have implemented a Site Reliability Engineering (SRE) function. Even though SRE is less well known than microservices, DevOps, and other topics, <a rel=\"noreferrer noopener\" aria-label=\"it isn’t in any sense new (opens in a new tab)\" href=\"https://trends.google.com/trends/explore?date=2005-01-01%202020-03-22\" target=\"_blank\">it isn’t in any sense new</a>. At this point, interest in SRE actually t<a rel=\"noreferrer noopener\" aria-label=\"racks closely with interest in microservices itself (opens in a new tab)\" href=\"https://trends.google.com/trends/explore?date=today%205-y\" target=\"_blank\">racks closely with interest in microservices itself</a>.</p>\n\n\n\n<p>Close to half of all organizations (47%) in our survey say they expect to implement an SRE function at some point in the future. Should this pan out, SRE adoption share would be roughly comparable to that of microservices. Is there significant overlap between the two, however? In other words, if an organization adopts microservices-oriented concepts, tools, and methods will it <em>also</em> tend to adopt an SRE function? Or is the growth in SRE related to other factors, such as (for example) declining interest in DevOps itself? In <a rel=\"noreferrer noopener\" aria-label=\"our analysis of user activity on the O’Reilly learning platform (opens in a new tab)\" href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis/\" target=\"_blank\">our analysis of user activity on the O’Reilly learning platform</a>, we found that DevOps-related search and usage declined in both 2018 and 2019. We posited that adopters “might be having trouble scaling DevOps” because “developers tend to be less committed to DevOps’ operations component.”</p>\n\n\n\n<p>We’d be remiss if we didn’t note that the strong showing for SRE is almost certainly a function of selection bias in our audience—i.e., our respondents are more likely to be using SRE than not. SRE’s performance could also be a function of the same <a rel=\"noreferrer noopener\" aria-label=\"cargo cult phenomenon (opens in a new tab)\" href=\"https://en.wikipedia.org/wiki/Cargo_cult\" target=\"_blank\">cargo cult phenomenon</a> we saw during the agile revolution, when familiarity with the term and uptake of select ideas or methods was conflated with adoption. As for the declining interest in DevOps we recorded in our platform survey, it’s just as possible that this decline—measured in terms of topic usage and search activity on the O’Reilly learning platform—is actually a function of something else: namely, the <em>maturation</em> of the DevOps topic. Clearly, the DevOps practices that took root over the last decade aren’t going anywhere. Instead, it’s likely that IT professionals are exploring and learning about DevOps-adjacent disciplines (such as SRE) that are new to them.</p>\n\n\n\n<p>As we noted in our <a href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis/\" target=\"_blank\" rel=\"noreferrer noopener\" aria-label=\"platform analysis (opens in a new tab)\">platform analysis</a>, in this and similar cases, it’s helpful to view the problem of user interest through the lens of the so-called <a href=\"https://en.wikipedia.org/wiki/Overton_window\" target=\"_blank\" rel=\"noreferrer noopener\" aria-label=\"Overton Window (opens in a new tab)\">Overton Window</a>, which circumscribes the human cognitive bandwidth that’s available in a certain place at a certain time. Obviously, no combination of issues or trends can exceed more than 100% of available bandwidth. The upshot is that declining interest in a topic doesn’t have to correlate with a decline in use (or usefulness) in practice. Or vice-versa. In the case of decline, a mix of emergent trends might be crowding out a topic. In the case of ascendancy, a trend might be (ephemerally) emergent.</p>\n\n\n\n<h2>Serverless Stagnant</h2>\n\n\n\n<p>We didn’t attempt to define serverless precisely, but for many people in our audience, serverless means “function-as-a-service” (for example, AWS Lambda). Services like AWS S3 are very much “serverless,” but that’s not common usage. With that in mind, one-third (almost 34%, in fact) of respondent organizations say they’re using serverless computing.</p>\n\n\n\n<p>This is roughly on par with the percentage that says they’re using SRE. Unlike with SRE, where almost half (47%) of respondents expect to add an SRE function at some point in the future, fewer (approximately 37%) expect to adopt serverless.<sup>4</sup> By the same margins—i.e., 37% pro-experimentation, 63% anti—fewer respondent organizations have “experimented” with serverless computing, e.g., by evaluating vendors, scoping serverless scenarios, or testing serverless on a limited basis.</p>\n\n\n\n<p>What’s interesting is that all three topics—viz., microservices, SRE, and serverless—seem to <a rel=\"noreferrer noopener\" aria-label=\"track closely with one another (opens in a new tab)\" href=\"https://trends.google.com/trends/explore?date=today%205-y\" target=\"_blank\">track closely with one another</a>. Is there a meaningful correlation here, or is this consonance spurious? Clearly, microservices <a rel=\"noreferrer noopener\" aria-label=\" (opens in a new tab)\" href=\"https://trends.google.com/trends/explore?date=2013-09-01%202020-03-22\" target=\"_blank\">are not a new thing</a>—but <a rel=\"noreferrer noopener\" aria-label=\"neither is SRE (opens in a new tab)\" href=\"https://trends.google.com/trends/explore?date=2013-09-01%202020-03-22\" target=\"_blank\">neither is SRE</a>. Is it possible that the complexity of microservice architecture, serverless computing, service mesh architecture, and other next-generation patterns is contributing to (if not driving) interest in SRE? We don’t have the data to begin to answer this question.</p>\n\n\n\n<p>But it’s one we’d plan to keep an eye on.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0111-1048x518.png\" alt=\"\" class=\"wp-image-12863\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0111-1048x518.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0111-300x148.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0111-768x379.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0111.png 1138w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 11. When respondents whose organizations do not currently use serverless expect their organizations to adopt serverless</figcaption></figure>\n\n\n\n<h2>Critical Skills for Success</h2>\n\n\n\n<p>Which skills are most important for migrating or implementing cloud-based infrastructure? Expertise in containers, Kubernetes, and monitoring all scored highly, but the number one skill area was cloud-based security. (The survey design encouraged respondents to select from among multiple listed skills.)</p>\n\n\n\n<p>Almost two-thirds of respondents (65%) selected cloud security, with monitoring (58%) a distant number two. General cloud knowledge was third (just over 56%), followed by containers and Kubernetes (just under 56%), respectively. All told, six separate skills polled at 50% or greater; 10 listed skills polled at 45% or greater. Clearly, respondents believe that they—along with other infrastructure and ops practitioners—need to skill up, with emphasis on security. Almost half (48%) of respondents selected six or more listed skills; 85% selected at least three listed skills. And 15% selected all 10 listed skills.</p>\n\n\n\n<p>We looked at the intersection of skills to see if respondents had selected specific combinations of skills more frequently than might otherwise be expected. We discovered obvious examples of correlation (i.e., a threshold at least 5% higher than expected) with containers and Kubernetes; containers and microservices; monitoring and observability; and between security and compliance. We found several examples of correlation between cloud-based security and other listed skills, which reinforces the idea that security dominates the thinking of infrastructure and ops practitioners; we found correlations involving security and monitoring; security and performance; and between security and observability.</p>\n\n\n\n<p>Finally, respondents selected some skill combinations less frequently than would be expected.<sup>5</sup> Some of these results are baffling, such as the absence of a correlation between microservices and security. Some examples of strong correlation (microservices and Kubernetes; containers and microservices) are consistent with trends we’ve described elsewhere, e.g., <a rel=\"noreferrer noopener\" aria-label=\"the Next Architecture (opens in a new tab)\" href=\"https://www.oreilly.com/radar/what-is-next-architecture/\" target=\"_blank\">the Next Architecture</a>.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0112-1048x691.png\" alt=\"\" class=\"wp-image-12865\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0112-1048x691.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0112-300x198.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0112-768x506.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0112.png 1296w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 12. Skills respondents’ organizations need for better migration and implementation of cloud-based infrastructure</figcaption></figure>\n\n\n\n<h2>AI in Production, Poised for Growth</h2>\n\n\n\n<p>Almost 36% of respondent organizations have deployed AI services. About 47% expect to deploy AI-based services at some point over the next three years; of these, the largest cohort (almost 20%) expects to do so in the next two years. Still, close to 53% do not anticipate doing anything with AI.</p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0113-1048x555.png\" alt=\"\" class=\"wp-image-12866\" srcset=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0113-1048x555.png 1048w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0113-300x159.png 300w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0113-768x406.png 768w, https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/05/ca20_0113.png 1181w\" sizes=\"(max-width: 1048px) 100vw, 1048px\" /><figcaption>Figure 13. When respondents whose organizations do not currently use AI services expect their organizations to adopt AI services</figcaption></figure>\n\n\n\n<p>The discrepancy isn’t surprising. A survey on infrastructure and operations will tend to attract people who are interested in infrastructure and operations. Ditto for ML and AI. Every survey has a self-selection bias.</p>\n\n\n\n<p>Still, the result seems anomalous. In the first case, it flies in the face of predominant trends. In <a rel=\"noreferrer noopener\" aria-label=\"our recent machine learning (ML) and AI adoption survey (opens in a new tab)\" href=\"https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2020/\" target=\"_blank\">our recent machine learning (ML) and AI adoption survey</a>, for example, we found that most organizations—about 53%—are using AI in production today. Even granting that AI is (over-)hyped, we should expect to see a <em>majority</em> result for planned AI adoption, shouldn’t we? In the second case, there are very good reasons why AI should be of interest to IT professionals who work in infrastructure and operations and (more important) the companies that employ them. Take <a rel=\"noreferrer noopener\" aria-label=\"observability (opens in a new tab)\" href=\"https://learning.oreilly.com/library/view/distributed-systems-observability/9781492033431/ch01.html\" target=\"_blank\">observability</a>, for example. It’s an important concept in software architecture, especially in next-generation regimes, such as microservice architecture. Machine learning and similar advanced techniques (e.g., deep learning) will likely play an important role in <em>observing</em> the observable systems that we build, just as AI-directed rules and AI-driven automation will be critical for managing and securing these systems.</p>\n\n\n\n<p>How, then, can an organization expect to manage the thousands or tens of thousands of services that comprise an observable system without building AI services? One explanation is that respondents simply lack visibility into this aspect of their organization’s planning. In other words, because AI-related development is owned by one or more different groups—data scientists, ML and AI engineers, Data‐Ops practitioners—many respondents genuinely aren’t aware of what their organizations are doing. An equally likely explanation is that respondents are failing to appreciate what actually constitutes AI. <a rel=\"noreferrer noopener\" aria-label=\"As we noted in another context (opens in a new tab)\" href=\"https://www.oreilly.com/radar/6-trends-framing-the-state-of-ai-and-ml/\" target=\"_blank\">As we noted in another context</a>, “AI” used to be identified with so-called <a rel=\"noreferrer noopener\" aria-label=\"artificial general intelligence (opens in a new tab)\" href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\" target=\"_blank\">artificial general intelligence</a>, or AGI. Increasingly, however, we’re seeing it used to describe the application of machine learning to solve problems, increase productivity, accelerate processes, and in many cases deliver wholly new products and services. Almost any consumer-facing site that makes product recommendations is using AI (although possibly in a very simple form.) It’s possible that some proportion of respondents had AGI in mind. Had we asked more specific questions, we likely would have gotten different results.</p>\n\n\n\n<h2>Conclusion</h2>\n\n\n\n<p>The survey was conceived and conducted in the months prior to the tumult of March and April. It is a product of a pre-pandemic sensibility.</p>\n\n\n\n<p>The impact of a pandemic event isn’t just disruptive, it’s transformative: it fundamentally changes the status quo; it compels the revaluation of virtually all assumptions. This invites the obvious question: Were we to conceive this survey today, what would we do differently? Obviously, we’d ask questions that take into account the realities—e.g., an unprecedented emphasis on social isolation; a new (and mostly unprecedented) acceptance of telework, geographical separation, and distance(-ing); a business climate characterized by extreme uncertainty, with most analysts forecasting severe recession, if not possible depression—that serve as backdrop to this, our moment.</p>\n\n\n\n<p>The most challenging thing about what’s happening is that it’s <em>very much happening</em>: we’re still coming to terms with it. Changes, compromises, reconfigurations that we never thought possible could become <em>de rigueur</em>. Other major changes will unfold over much larger periods of time.</p>\n\n\n\n<p>It’s naïve to think we could anticipate even the broad strokes of these changes, let alone the specificity of their content. And it’s unhelpful—perhaps even dangerous—to overthink things. That said, it is useful to speculate about what could change in the near term, at least now that we have precedent for the unprecedented. It’s possible that the public cloud could become an even more attractive option for companies of all sizes. It’s possible that hybrid clouds combining PaaS or IaaS services with the virtual private cloud—that is, private cloud deployments which live in the public cloud—could see increased uptake, too. It’s also possible that more organizations will pursue multi-cloud as a strategy to hedge against potential disruption.</p>\n\n\n\n<p>The hope of reducing costs won’t be the only thing driving new interest in cloud. Almost all enterprises are already dealing with staffing problems on several fronts: <em>first</em>, illness-related staffing shortages; <em>second</em>, staffing shortages that stem from shelter-in-place orders at the municipal, county, or state levels; <em>third</em>, furlough- or layoff-related staffing shortages. In some cases, IT workers have opted to withdraw from the workforce, e.g., to safeguard the health and well-being of their families. The combination of these and other staffing-related issues could compel companies to revisit not only the necessity for on-site/on-premises work, but the responsibility for hiring, recruiting, and managing IT staff to support applications or services that could shift to a third-party provider. Is it more credible for a large cloud service like Amazon, Google, IBM, or Microsoft to argue that its employees are essential than—for example—the IT staff of a major cosmetics retailer? More to the point, are the major cloud providers more likely to keep their datacenters running in the face of quarantines than a business with a private datacenter? The answer to the latter question has to be “yes.”</p>\n\n\n\n<p>These are just a few possible changes. Had we the opportunity to redo our survey, we would almost certainly ask questions that drill down deeper into these issues. Nevertheless, we believe the results we capture here have considerable merit: not as quaint relics of a prelapsarian past, but as valid indications of where we were and <em>where we’ll be</em> when things pick back up again. There’s no reason to assume that the underlying trends here will be annulled by the effects of COVID-19. Impacted, yes; annulled, no. The shift to cloud, uptake of microservices, increasing interest in SRE, emphasis on Kubernetes, container virtualization, and other critical skills: each of these trends has staying power, especially to the degree that they’re implicated in or correlated to one another.</p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<br />\n</div></div>\n\n\n\n<p>————————————————————————————————</p>\n\n\n\n<p><sup>1</sup> Regional representation in Radar surveys typically tracks with usage on the O’Reilly learning platform. North American users account for about half of activity on the O’Reilly platform. That isn’t the case here.</p>\n\n\n\n<p><sup>2</sup> For example: What criteria do we use to distinguish between private and public cloud? How do these criteria—and the distinction itself—relate to hybrid cloud? To virtual private cloud? What if an organization hosts its cloud in a colocation facility? Is it public or private? Is tenancy—e.g., a single-tenant cloud hosted in an off-site facility is a private cloud—the most important criterion? If an organization uses a combination of virtualization and automation to host some of its workloads, has it created a private cloud?</p>\n\n\n\n<p><sup>3</sup> But <em>which</em> cloud? Or in which cloud context? The essential characteristics of modern software architecture—loose coupling; abstraction, isolation, and atomicity—are eliding the boundaries between what we think of as “cloud” versus “on-premises” contexts. As we wrote in <a href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis/\" target=\"_blank\" rel=\"noopener noreferrer\">our analysis of search and usage on the O’Reilly learning platform</a>: “Specific deployment contexts will still matter, of course … but the clear boundaries that used to demarcate the public cloud from the private cloud from conventional on-premises systems will fall away. It’s all cloud-like, irrespective of context.”</p>\n\n\n\n<p><sup>4</sup> This looks like another case in which interest in a technology—namely, serverless—also tracks with interest in other, not necessarily related technologies, <a href=\"https://trends.google.com/trends/explore?date=today%205-y\" target=\"_blank\" rel=\"noopener noreferrer\">in this case, microservices and SRE</a>. Even if serverless adoption lags, interest in it seems to wax and wane with (and perhaps benefit from) interest in these other technologies.</p>\n\n\n\n<p><sup>5</sup> These include general cloud knowledge + security; general cloud knowledge + performance; microservices + security; compliance + monitoring; compliance + performance. All with a threshold 5% lower than expected.</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/CvXGdmdKaRw\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 19 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/FqNNC0fSq2k/\n<ol>\n<li><a href=\"https://krebsonsecurity.com/2020/05/this-service-helps-malware-authors-fix-flaws-in-their-code/\">This Service Helps Malware Authors Fix Flaws in their Code</a> (Krebs on Security) &#8212; Of course the Bad Guys(tm) are going to want security audits. Of course! <i>“We can examine your (or not exactly your) PHP code for vulnerabilities and backdoors,” reads his offering on several prominent Russian cybercrime forums. “Possible options include, for example, bot admin panels, code injection panels, shell control panels, payment card sniffers, traffic direction services, exchange services, spamming software, doorway generators, and scam pages, etc.”</i></li>\n<li><a href=\"https://www.oreilly.com/radar/what-to-do-when-ai-fails/\">What to Do When AI Fails</a> (O&#8217;Reilly) &#8212; <i>Why even think about incident response differently in the world of AI? The answers boil down to three major reasons, which may also exist in other large software systems but are exacerbated in AI. First and foremost is the tendency for AI to decay over time. Second is AI’s tremendous complexity. And last is the probabilistic nature of statistics and machine learning (ML).</i></li>\n<li><a href=\"https://gtoolkit.com/\">Glamorous Toolkit</a> &#8212; <i>a live notebook. It is a flexible search interface. It is a fancy code editor. It is a software analysis platform. It is a data visualization engine. All in one. And it is free and open-source under an MIT license.</i></li>\n<li><a href=\"http://interconnected.org/home/2020/05/15/video_talks\">Rethinking Conference Calls for Video Calls</a> (Matt Webb) &#8212; <i>I find the idea of Zoom talks fascinating. What does it means to do something: which is live; where everyone in the audience is potentially multitasking; that includes a text chat backchannel which is visible to everyone?</i> Matt&#8217;s been thinking about how we might remake &#8220;The Talk&#8221; in the age of Zoom. One thing&#8217;s clear: there&#8217;s huge room for tools to evolve.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/FqNNC0fSq2k\" height=\"1\" width=\"1\" alt=\"\"/>\nWhat to Do When AI Fails\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/wRCxGTdcchA/\n<p>These are unprecedented times, at least by information age standards. Much of the U.S. economy has ground to a halt, and social norms about our data and our privacy have been thrown out the window throughout much of the world. Moreover, things seem likely to keep changing until a vaccine or effective treatment for COVID-19 becomes available. All this change could wreak havoc on artificial intelligence (AI) systems. <em>Garbage in, garbage out </em>still holds in 2020. The most common types of AI systems are still only as good as their training data. If there’s no historical data that mirrors our current situation, <a href=\"https://www.americanbanker.com/opinion/ai-models-could-struggle-to-handle-the-market-downturn\">we can expect our AI systems to falter</a>, if not fail.&nbsp;<br><br>To date, at least 1,200 reports of AI incidents <a href=\"http://aiid.partnershiponai.org/\">have been recorded</a> in various public and research databases. That means that <em>now</em> is the time to start planning for AI <em>incident response</em>, or how organizations react when things go wrong with their AI systems. While incident response is a field that’s well developed in the traditional cybersecurity world, it has no clear analogue in the world of AI.&nbsp; What is an incident when it comes to an AI system? When does AI create liability that organizations need to respond to? This article answers these questions, based on our combined experience as both a lawyer and a data scientist responding to cybersecurity incidents, crafting legal frameworks to manage the risks of AI, and building sophisticated interpretable models to mitigate risk. Our aim is to help explain when and why AI creates liability for the organizations that employ it, and to outline how organizations should react when their AI causes major problems.<br></p>\n\n\n\n<h2>AI Is Different—Here’s Why</h2>\n\n\n\n<p>Before we get into the details of AI incident response, it’s worth raising these baseline questions: What makes AI different from traditional software systems? Why even think about incident response differently in the world of AI? The answers boil down to three major reasons, which may also exist in other large software systems but are exacerbated in AI. First and foremost is the tendency for AI to decay over time. Second is AI’s tremendous complexity. And last is the probabilistic nature of statistics and machine learning (ML).</p>\n\n\n\n<p><strong>Most AI models decay overtime: </strong>This phenomenon, known more widely as <em>model decay</em>, refers to the declining quality of AI system results over time, as patterns in new data drift away from patterns learned in training data. This implies that even if the underlying code is perfectly maintained in an AI system, the accuracy of its output is likely to decrease. As a result, the probability of an AI incident often increases over time.<sup>1</sup> And, of course, the risks of model decay are exacerbated in times of rapid change.</p>\n\n\n\n<p><strong>AI systems are more complex than traditional software: </strong>The complexity of most AI systems is greater on a <a href=\"https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/\">near-exponential level</a> than that of traditional software systems. If “[t]he worst enemy of security is complexity,” to <a href=\"https://www.schneier.com/essays/archives/1999/11/a_plea_for_simplicit.html\">quote Bruce Schneier</a>, AI is in many ways inherently insecure. In the context of AI incidents, this complexity is problematic because it can make audits, debugging, and simply even understanding what went wrong nearly impossible.<sup>2</sup> </p>\n\n\n\n<p><strong>Because statistics: </strong>Last is the inherently probabilistic nature of ML. All predictive models are wrong at times⁠—just hopefully less so than humans. As the renowned statistician <a href=\"https://en.wikipedia.org/wiki/All_models_are_wrong\">George Box once quipped</a>, “All models are wrong, but some are useful.” But unlike traditional software, where wrong results are often considered bugs, wrong results in ML are expected features of these systems. This means organizations should always be ready for their ML systems to fail in ways large and small⁠—or they might find themselves in the midst of an incident they’re not prepared to handle. </p>\n\n\n\n<p>Taken together, AI is a high-risk technology, perhaps akin today to commercial aviation or nuclear power. It can provide substantial benefits, but even with diligent governance, it’s still likely to cause incidents—with or without external attackers.</p>\n\n\n\n<h2>Defining an “AI Incident”</h2>\n\n\n\n<p>In standard software programming, incidents generally require some form of an attacker.<br></p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<figure class=\"wp-block-image\"><img src=\"https://lh6.googleusercontent.com/EQJSCSV2Wtrcjf53QQOuXzhhQB3z_oJTZ2ATbW4YbCnvHLooW9Ryut2vk5xP-9rdVvN-tY76YGpFpFnfcC7-9U5Tz3_1Bte5_sd7PpTdv-VQ61PBseZIS2q8Vl-LWd5funV1M0X4\" alt=\"\" /></figure>\n</div></div>\n</div></div>\n\n\n\n<p><strong>A basic taxonomy that divides AI incidents into malicious attacks and failures. Failures can be caused by accidents, negligence, or unforeseeable external circumstances</strong>.</p>\n</div></div>\n\n\n\n<p>But incidents in AI systems are different. An AI incident should be considered <em>any </em>behavior by the model with the potential to cause harm, expected or not. This includes potential violations of privacy and security, like an external attacker attempting to <a href=\"https://fpf.org/wp-content/uploads/2019/09/FPF_WarningSigns_Report.pdf\">manipulate the model or steal data encoded in the model</a>. But this also includes incorrect predictions, which can cause enormous harm if left unaddressed and unaccounted for. AI incidents, in other words, don’t require an external attacker. The likelihood of AI system failures makes AI <a href=\"https://research.google/pubs/pub43146\">high-risk in and of itself</a>—and especially if not monitored correctly.<sup>3</sup></p>\n\n\n\n<p>This framework is certainly broad—indeed, it’s aligned with how an unmonitored AI system practically <em>guarantees</em> incidents.<sup>4</sup> But is it too broad to be useful? Quite the contrary. At a time when organizations rely on increasingly complex software systems (both AI related and not), deployed in ever-changing environments, security efforts cannot stop all incidents from occurring altogether. Instead, organizations must acknowledge that incidents will occur, perhaps even many of them. And that means that <a href=\"https://www.hoover.org/research/flat-light\">what counts as an incident</a> ends up being just as important as how organizations respond when they do occur.</p>\n\n\n\n<p>Understanding where AI is creating harms and when incidents are actually occurring is therefore only the first step. The next step lies in determining <em>when</em> and <em>how </em>to respond. We suggest considering two major factors: preparation and materiality.</p>\n\n\n\n<h3>Gauging Severity Based on Preparedness</h3>\n\n\n\n<p>The first factor in deciding when and how to respond to AI incidents is preparedness, or how much the organization has anticipated and mitigated the potential harms caused by the incident in advance.</p>\n\n\n\n<p>For AI systems, it is possible to prepare for incidents before they occur, and even to automate many of the processes that make up key phases of incident response. Take, for example, a medical image classification model used to detect malign tumors. If this model begins to make dangerous and incorrect predictions, preparation can make the difference between a full-blown incident and a manageable deviation in model behavior.</p>\n\n\n\n<p>In general, allowing users to appeal decisions or operators to flag suspicious model behavior, along with built-in redundancy and rigorous model monitoring and auditing programs, can help organizations recognize potentially harmful behavior in near-real time. If our model generates false negative predictions for tumor detection, organizations could combine automated imaging results with activities like follow up radiologist reviews or blood tests to catch any potentially incorrect predictions—and even improve the accuracy of the combined human and machine efforts.<sup>5</sup></p>\n\n\n\n<p>How prepared you are, in other words, can help to determine the severity of the incident, the speed at which you must respond, and the resources your organization should devote to its response. Organizations that have anticipated the harms of any given incident and minimized its impact may only need to carry out minimal response activities. Organizations that are caught off guard, however, may need to devote significantly more resources to understanding what went wrong, what its impact could be, and only then engage in recovery efforts.</p>\n\n\n\n<h3>How Material Is the Threat?</h3>\n\n\n\n<p>Materiality is a widely used concept in the world of <a href=\"http://crocouncil.org/images/CROC_Model_Risk_Management_-_Practices_and_Principles_August_2016.pdf\">model risk management</a>, a regulatory field that governs how financial institutions document, test, and monitor the models they deploy. Broadly speaking, materiality is the product of the impact of a model error times the probability of that error occuring. Materiality relates to both the scale of the harm and the likelihood that the harm will take place. If the probability is high that our hypothetical image classification model will fail to identify malign tumors, and if the impact of this failure could lead to undiagnosed illness and to loss of life for patients, the materiality for this model would be high. If, however, the impact of this type of failure was diminished–by, for example, the model being used as one of several overlapping diagnostic tools–materiality would decrease.</p>\n\n\n\n<p>Data sensitivity also tends to be a helpful measure for the materiality of any incident. From a data privacy perspective, sensitive data–like consumer financials or data relating to health, ethnicity, sexual orientation, or gender–tend to carry higher risk and therefore a greater potential for liability and harm. Additional real-world considerations for increased materiality also include threats to health, safety, and third parties, legal liabilities, and reputational damage.</p>\n\n\n\n<p>Which brings us to a point that many may find unfamiliar: it’s never too early to get legal and compliance personnel involved in an AI project.</p>\n\n\n\n<h2>It’s All Fun and Games—Until the Lawsuits</h2>\n\n\n\n<p>Why involve lawyers in AI? The most obvious reason is that AI incidents can give rise to serious legal liability, and liability is always an inherently legal problem. The so-called <em>AI transparency paradox</em>, under which <a href=\"https://hbr.org/2019/12/the-ai-transparency-paradox\">all data creates new risks</a>, forms another general reason why lawyers and legal privilege are so important in the world of data science—indeed, this is why legal privilege already functions as a central factor in the world of traditional incident response. What’s more, existing laws propose standards that AI incidents can run afoul of. Without understanding how these laws affect each incident, organizations can steer themselves into a world of trouble, from litigation to regulatory fines, to denial of insurance coverage after an incident.</p>\n\n\n\n<p>Take, for example, the Federal Trade Commission’s (FTC) <em>reasonable security</em> standard, which the FTC uses to assign liability to companies in the aftermath of breaches and attacks. Companies that fail to meet this standard can be on the hook for hundreds of millions of dollars following an incident. Earlier this month, the FTC even published <a href=\"https://www.ftc.gov/news-events/blogs/business-blog/2020/04/using-artificial-intelligence-algorithms\">specific guidelines related to AI</a>, hinting at enforcement actions to come. Additionally, there are a host of breach reporting laws, at both the state and the federal level, that mandate reporting to regulators or to consumers after experiencing specific types of privacy or security problems. Fines for violating these requirements can be astronomical, and some AI incidents related to privacy and security <a href=\"https://royalsocietypublishing.org/doi/10.1098/rsta.2018.0083\">may trigger these requirements</a>.</p>\n\n\n\n<p>And that’s just related to <em>existing</em> laws on the books. A variety of new and proposed laws at the state, federal, and international level are focused on AI explicitly, which will likely increase the compliance risks of AI over time. The Algorithmic Accountability Act, for example, was introduced in both chambers of Congress last year as one way to increase regulatory oversight over AI. Many more such proposals are on their way.<sup>6</sup></p>\n\n\n\n<h2>Getting Started&nbsp;</h2>\n\n\n\n<p>So what can organizations do to prepare for the risks of AI? How can they implement plans to manage AI incidents? The answers will vary across organizations—depending on the size, sector, and maturity of their existing AI governance programs. But a few general takeaways can serve as a starting point for AI incident response.</p>\n\n\n\n<h3>Response Begins with Planning&nbsp;</h3>\n\n\n\n<p>Incident response requires planning: who responds when an incident occurs, how they communicate to business units and to management, what they do, and more. Without clear plans in place, it is incredibly hard for organizations to identify, little less contain, all the harms AI is capable of generating. That means that to begin with, organizations should have clear plans to identify the personnel capable of responding to AI incidents, and outline their expected behavior when incidents do occur. Drafting these types of plans is a complex endeavor, but there are a variety of existing tools and frameworks. NIST’s <a href=\"https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-61r2.pdf\">Computer Security Incident Handling Guide</a> which, while not tailored to the risks of AI specifically, provides one good starting point.</p>\n\n\n\n<p>Beyond planning, organizations don’t actually need to wait until incidents occur to mitigate their impact—indeed, there are a host of best practices they can implement long before any incidents take place. Organizations should, among other best practices:</p>\n\n\n\n<p><strong>Keep an up-to-date inventory of all AI systems:</strong> This allows organizations to form a baseline understanding of where potential incidents could occur.</p>\n\n\n\n<p><strong>Monitor all AI systems for anomalous behavior: </strong>Proper monitoring ends up being central to both incident detection and to ensure a full recovery during the latter stages of the response.</p>\n\n\n\n<p><strong>Standup AI-specific preventive security measures:</strong> Activities like <em>red-teaming</em> or bounty programs can help to identify potential problems long before they cause full-blown incidents.<br><br><strong>Thoroughly document all AI and ML systems:</strong> Along with pertinent technical and personnel information, documentation should include expected normal behavior for a system and the business impact of shutting down a system.</p>\n\n\n\n<h3>Transparency Is Key</h3>\n\n\n\n<p>Beyond these best practices, it’s also important to emphasize AI interpretability—both in creating accurate and trustworthy models, and also as a central feature in the ability to successfully respond to AI incidents. (We’re such proponents of interpretability that one of us even wrote <a href=\"https://learning.oreilly.com/library/view/an-introduction-to/9781098115487/\">an e-book </a>on the subject.) From an incident response perspective, transparency turns out to be a core requirement in every stage of incident response. You can’t clearly identify an incident, for example, if you can’t understand how the model is making its decisions. Nor can you contain or remediate errors without insight into the inner-workings of the AI. There are a variety of methods organizations can use to prioritize transparency and to manage interpretability concerns, from inherently interpretable and accurate models, like <a href=\"https://github.com/interpretml/interpret\">GA<sup>2</sup>M</a>, to new research on <a href=\"https://github.com/slundberg/shap\">post-hoc explanations</a> for black-box models.</p>\n\n\n\n<p> </p>\n\n\n\n<h3>Participate in Nascent AI Security Efforts</h3>\n\n\n\n<p>Broader endeavors to enable trustworthy AI are also underway throughout the world, and organizations can connect their own AI incident response efforts to these larger programs in a variety of ways. One international group of researchers, for example, <a href=\"https://arxiv.org/pdf/2004.07213.pdf\">just released</a> a series of guidelines that include ways to <a href=\"http://aiid.partnershiponai.org/\">report AI incidents</a> to improve collective defenses. Although a host of potential liabilities and barriers may make this type of public reporting difficult, organizations should, where feasible, consider reporting AI incidents for the benefit of broader AI security efforts. Just like <a href=\"https://cve.mitre.org/cve/researcher_reservation_guidelines\">the common vulnerabilities and exposures database</a> is central to the world of traditional information security, collective information sharing is critical to the safe adoption of AI.</p>\n\n\n\n<h2>The Biggest Takeaway: Don’t Wait Until It’s Too Late</h2>\n\n\n\n<p>Once <a href=\"https://research.google/pubs/pub43146/\">called</a> “the high interest credit card of technical debt,” AI carries with it a world of exciting new opportunities, but also risks that challenge traditional notions of accuracy, privacy, security, and fairness. The better prepared organizations are to respond when those risks become incidents, the more value they’ll be able to draw from the technology.</p>\n\n\n\n<p><p>———————————————————————————— </p>\n<p><sup>1</sup> The sub-discipline of adaptive learning attempts to address this problem with systems that can update themselves. But as illustrated by Microsoft’s notorious Tay chatbot, such systems can present even greater risks than model decay.</p>\n<p><sup>2</sup> New branches of ML research have provided some antidotes to the complexity created by many ML algorithms. But many organizations are still in the early phases of adopting ML and AI technologies, and seem unaware of recent progress in interpretable ML and explainable AI.  Tensorflow, for example, has 140,000+ stars on Github, while DeepExplain has 400+ stars.</p>\n<p><sup>3</sup> This framework is also explicitly aligned with how a group of AI researchers recently defined AI incidents, which they described as “cases of undesired or unexpected behavior by an AI system that causes or could cause harm.”</p>\n<p><sup>4</sup> In a recent paper about AI accountability, researchers noted that, “complex systems tend to drift toward unsafe conditions unless constant vigilance is maintained. It is the sum of the tiny probabilities of individual events that matters in complex systems—if this grows without bound, the probability of catastrophe goes to one.”</p>\n<p><sup>5</sup> This hypothetical example is inspired by a very similar real-world problem. Researchers recently reported on a certain tumor model for which, “overall performance &#8230; may be high, but the model still consistently misses a rare but aggressive cancer subtype.”</p>\n<p><sup>6</sup> Governments of at least Canada, Germany, Netherlands, Singapore, the U.K. and the U.S. (the White House, DoD, and FDA) have proposed or enacted AI-specific guidance.</p></p>\n\n\n\n<p> </p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/wRCxGTdcchA\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 18 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/YUxv4Qh1K7U/\n<ol>\n<li><a href=\"https://paulbutler.org/2020/the-webassembly-app-gap/\">The Web Assembly App Gap</a> &#8212; <i>This essay states the case for the modern browser as a platform, and explores some components that might fill the gaps in a modern stack. [&#8230;] Content-aware, versioned data; UI Framework; Standard interfaces for automation; Stateful Service Architecture.</i> (via <a href=\"https://twitter.com/paulgb/status/1262093424850882560\">Paul Butler</a>)</li>\n<li><a href=\"https://www.microsoft.com/en-us/research/publication/hints-and-principles-for-computer-system-design-3/\">Hints and Principles for Computer System Design</a> &#8212; <i>suggests the goals you might have for your system—Simple, Timely, Efficient, Adaptable, Dependable, Yummy (STEADY)—and effective techniques for achieving them—Approximate, Incremental, Divide &amp; Conquer (AID)</i>.</li>\n<li><a href=\"https://www.ida.org/-/media/feature/publications/i/in/initial-analysis-of-underhanded-source-code/d-13166.ashx\">Initial Analysis of Underhanded Source Code</a> &#8212; <i>source code that appears benign to human review but is actually malicious.</i> This paper looks at examples, summarizes literature, identifies promising mechanisms for countering it, and digs deep into one dataset (the Obfuscated V Contest).</li>\n<li><a href=\"https://github.com/git-artes/gr-tempest\">Tempest in GNU Radio</a> &#8212; <i>TEMPEST (or Van Eck Phreaking) is a technique to eavesdrop video monitors by receiving the electromagnetic signal emitted by the VGA/HDMI cable and connectors (although other targets are possible, such as keyboards, for which the same term is generally used[&#8230;]). This is basically a re-implementation of Martin Marinov&#8217;s excellent TempestSDR in GNU Radio.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/YUxv4Qh1K7U\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 15 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/22fFY7896NU/\n<ol>\n<li><a href=\"https://news.ycombinator.com/item?id=23118940\">Favourite Developer-Efficiency Tips</a> &#8212; <i>Before putting a project or incomplete task away, make notes of what the next thing was that you were going to work on. This lets you bypass that 10 minute orientation getting back into the project the next time you pick it up.</i> I&#8217;d not heard it called that before. All the suggestions are very good.</li>\n<li><a href=\"https://github.com/sonictruth/vr-dos\">VR-DOS</a> &#8212; <i>an experimental &#8220;PC running DOS&#8221; emulator inside a VR environment.</i></li>\n<li><a href=\"https://moxon6.github.io/cobol-js-emscripten/\">Web Assembly COBOL Pong</a> &#8212; The silliest flex of the week: <i>Pong written in COBOL, compiled to WebAssembly.</i></li>\n<li><a href=\"https://medium.com/@arush/scaling-an-engineering-team-from-zero-to-infinity-a07b6b67595\">Scaling an Engineering Team from 0 to Infinity</a> &#8212; Really good breakdown of the different ways engineering team needs and structure change as the company grows.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/22fFY7896NU\" height=\"1\" width=\"1\" alt=\"\"/>\nPractical Skills for The AI Product Manager\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/OCLvXNrobdo/\n<p>In our previous article, <a href=\"https://www.oreilly.com/radar/what-you-need-to-know-about-product-management-for-ai/\">What You Need to Know About Product Management for AI</a>, we discussed the need for an AI Product Manager.&nbsp; This role includes everything a traditional PM does, but also requires an operational understanding of machine learning software development, along with a realistic view of its capabilities and limitations.<br></p>\n\n\n\n<p>In this article, we shift our focus to the AI Product Manager’s skill set, as it is applied to day to day work in the design, development, and maintenance of AI products. To understand the skills that product managers need, we’ll start with the process of product development, then consider how this&nbsp; process differs in different kinds of organizations.</p>\n\n\n\n<h4>The AI Product Pipeline</h4>\n\n\n\n<p>We’ll start by defining the different phases of AI product development.&nbsp; Though this is not an exhaustive list, most AI products pass through these stages.&nbsp; In some organizations, a separate product manager shepherds the product through each stage.&nbsp; Whether or not that’s how your organization works, every AI PM must consider how their products relate to these phases.&nbsp; Which stage is the product in currently?&nbsp; What stages will it have to go through before it becomes “real,” and how will it get there?&nbsp;&nbsp;<br></p>\n\n\n\n<p><strong>Innovation/Ideation/Design for UI/X: </strong>&nbsp;In traditional software engineering projects, product managers are key stakeholders in the activities that influence product and feature innovation. AI is no different. It’s incredibly important to determine what outcome is desired, how that outcome will be delivered, and how the product will be used before embarking on the long (and expensive) development journey. In the ideation phase, AI product managers should be able to use the same rapid innovation tools used by design experts, including UX mockups, wireframes, and user surveys.&nbsp; At this stage, it is also critical to frame the problem or opportunity that the product addresses. In his article “<a href=\"https://medium.com/@neal_lathia/machine-learning-for-product-managers-ba9cf8724e57\">Machine Learning for Product Managers</a>,” Neal Lathia distilled ML problem types into six categories: ranking, recommendation, classification, regression, clustering, and anomaly detection. AI PMs should enter feature development and experimentation phases only after deciding what problem they want to solve as precisely as possible, and placing the problem into one of these categories. Understanding exactly what you’re doing, and how it relates to other kinds of projects, will be a huge help in researching and building solutions.</p>\n\n\n\n<p><strong>Feature Development and Data Management: </strong>This phase focuses on the inputs to a machine learning product; defining the features in the data that are relevant, and building the data pipelines that fuel the machine learning engine powering the product.</p>\n\n\n\n<p><strong>Experimentation: </strong>It’s just not possible to create a product by building, evaluating, and deploying a single model.&nbsp; In reality, many candidate models (frequently hundreds or even thousands) are created during the development process.&nbsp; Which model is selected for the final product is often a complex, cross-functional decision based on both qualitative and quantitative factors.&nbsp; As a result, designing, implementing, and managing AI experiments (and the associated software engineering tools) is at times an AI product in itself.&nbsp; Tools like <a href=\"https://mlflow.org/\">MLFlow</a> and <a href=\"https://www.wandb.com/\">Weights &amp; Biases</a> are designed to help manage experimentation.</p>\n\n\n\n<p><strong>Research: </strong>Many organizations make the mistake of hiring brilliant people with a passion for research, then putting them in a proverbial room with little to no direction and expecting “innovation” to emerge.&nbsp; The result is often an overly decentralized mess that yields little value before being abandoned. The product manager for the research phase understands that AI Research products are first and foremost products, and therefore develops all of the necessary tools, structure, relationships, and resources needed to be successful. This includes product roadmaps, experiments, and investments into user interface and design. In addition, the Research PM defines and measures the lifecycle of each research product that they support.</p>\n\n\n\n<p><strong>Modelling: </strong>The model is often misconstrued as the most important component of an AI product.&nbsp; In reality, the model is often the smallest amount of code in the codebase, with the smallest human dependency.&nbsp; That said, repeatable success in deployment and use of a model proves elusive even for some of the most advanced organizations.&nbsp; Assuming that the selected machine learning technique is suitable, the product manager will have to make several important decisions about the model. A product manager must decide whether to refactor the research code (perhaps porting it into a different language altogether), determine the scope of the ML model’s inference engine, decide on model format (for reusability and version control), ensure that the modeling technique can support the service level agreement (SLA) of the AI system, and plan for deployment and maintenance. </p>\n\n\n\n<p><strong>Serving Infrastructure: </strong>Our previous article mentioned the need to “walk before running” in the development of AI products.&nbsp; The foundation of any data product consists of “solid data infrastructure, including data collection, data storage, data pipelines, data preparation, and traditional analytics.” A product manager for this phase prepares the way for putting products into production by building the infrastructure needed to support the design, development, and use of future products. This includes tools for model development (such as the <a href=\"https://www.cloudera.com/products/data-science-and-engineering/data-science-workbench.html\">Cloudera Data Science Workbench</a>, <a rel=\"noreferrer noopener\" href=\"https://www.dominodatalab.com/\" target=\"_blank\">Domino Data Lab</a>,&nbsp;<a rel=\"noreferrer noopener\" href=\"https://www.datarobot.com/\" target=\"_blank\">Data Robot</a>, and&nbsp;<a rel=\"noreferrer noopener\" href=\"http://dataiku.com/\" target=\"_blank\">Dataiku</a>) and production serving infrastructure (such as <a href=\"https://www.seldon.io/\">Seldon</a>,&nbsp;<a rel=\"noreferrer noopener\" href=\"https://aws.amazon.com/sagemaker/\" target=\"_blank\">Sagemaker</a>, and <a href=\"https://www.tensorflow.org/tfx\">TFX</a>).</p>\n\n\n\n<p>Companies have widely different practices, so the roles that AI PMs play varies substantially. Therefore, it’s a good idea to develop some competence in all of these core capabilities.&nbsp; As the field, technology, and individual organizations mature, specialization will become both necessary and common. In a large company, product management may change hands several times as a product moves through the pipeline. There may be a “product owner” who has end-to-end responsibility for the product’s development. In a small company, a single PM may shepherd a product from conception to operation.</p>\n\n\n\n<h4>Consumer Companies Versus B2B Companies</h4>\n\n\n\n<p>It’s not surprising that the company’s business model has a huge effect on the product manager’s work.&nbsp; Not only are the product’s raw components vastly different in different types of businesses (data, technology infrastructure, and talent), the types of AI products required to serve the customer also differ.</p>\n\n\n\n<p>In consumer companies, product managers are more likely to align directly with a feature team, and have much more customer-driven work.&nbsp; Because they are building an AI product that will be consumed by the masses, it’s possible (perhaps even desirable) to optimize for rapid experimentation and iteration over accuracy—especially at the beginning of the product cycle.&nbsp; This means that AI PMs must be more hands-on during the experimentation and research phases; it’s their responsibility to align the customer’s voice and needs with research goals.</p>\n\n\n\n<p>In addition, product managers at consumer companies often have clearer technical problems to solve.&nbsp; Many peers or competitors have already created AI products, resulting in ML/AI techniques that are far more mature than in other areas.&nbsp; For example, product managers for companies that buy or sell advertising are working in a well-researched algorithmic environment and data ecosystem where the emphasis is less on software engineering and more on the development of novel modeling techniques that will move the needle on product outcomes. </p>\n\n\n\n<p>The disadvantage of working in a consumer company⁠—especially one that is just getting started⁠—is that there is often a problem with data volume. Modeling techniques that serve interventions to customers rely on detailed demographic information.&nbsp; The need for specific types of training data is a major challenge. Organizations often find themselves without enough data to determine which experiments to run or which data to obtain. The process of getting the right data can take a long time, and usually goes something like this: you start to build something, ask questions about the data you need, realize you don’t have the right data, start collecting the data (or retrofitting old data), and finally do the analysis and build the product you wanted at the start. To shorten this lengthy cycle, product managers must bring qualitative means of decision making to the table, and should not expect Data Scientists or ML Engineers to have all of the answers.</p>\n\n\n\n<p>In contrast, AI product managers working in Business to Business (B2B) firms tend to focus on the first and last mile of the AI product cycle.&nbsp; B2B firms solve highly complex problems for a very narrow set of consumers.&nbsp; Take security: many AI/ML-enabled security firms are solely focused on application threat and anomaly detection.&nbsp; Although the companies they serve may be very diverse, the firms providing these AI products have a clear focus on one or two product types—an advantage that consumer AI products rarely have.</p>\n\n\n\n<p>These companies often have access to a lot of data at the beginning of the development cycle—also unlike consumer products.&nbsp; However, it may not be easy to access or contextualize this data, especially in enterprises.</p>\n\n\n\n<p>Once the data challenges are resolved, the model development cycle may prove intractable.&nbsp; Consider threat detection again: even if we find a significant number of identifiable threats within the dataset, current ML techniques for time series anomaly detection are notoriously difficult to tune. The product manager needs to decide on a technique that meets the precision levels required by businesses, but is interpretable enough to explain and maintain over a product lifecycle.</p>\n\n\n\n<p>Finally, integrating AI products into business tech stacks (especially in enterprises) is nontrivial. PMs in B2B firms can’t afford to ignore the stack with which their products will be deployed, nor can they ignore the problems of designing for scale. </p>\n\n\n\n<h4>Startups Versus Large Companies</h4>\n\n\n\n<p>Product managers for AI have very different roles and responsibilities in small and large companies.&nbsp; Large organizations tend to have a lot of data, but that data is usually complex, older, and stored on less flexible (and harder to integrate) technology than in smaller companies. Enterprise data may be logically (or physically) separated into silos, and development of a consistent, cross-enterprise data platform may be a high priority. AI product managers will be more involved in the data products, platform conversations, and project management than they would be in a startup environment.</p>\n\n\n\n<p>In enterprises, AI product managers may evolve out of the need to coordinate and manage several cross-functional teams that have developed organically (i.e., data platform, metrics, ML/AI research, and applied ML). One benefit of this evolutionary growth is that enterprise AI PMs will be able to rely on cross-functional domain experience and existing processes from day one, in contrast to those working in startups.&nbsp; The tradeoff for that collaboration and support is speed of execution and flexibility.&nbsp; According to <a href=\"https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/\">VentureBeat</a>, fewer than 15% of Data Science projects actually make it into production.&nbsp; The number of projects that actually add value (especially in an enterprise context) is probably even lower.&nbsp; Lack of alignment on a coherent overall data strategy, a focus on technology over impact, an inability to embrace an iterative, experimentational development cycle and lack of leadership support are among the many reasons AI projects falter. Most of these factors are inherent to or exacerbated by the enterprise environment.&nbsp; AI PMs may have a narrower, less technical focus in large organizations, but the stakes are no lower and the challenges are certainly not simpler or easier to tackle.</p>\n\n\n\n<p>In contrast, in startups it’s unlikely that AI PM will be a distinct role, unless one or more products are central to the overall business model (for example, AdTech or search).&nbsp; As a result, product managers from other functions may find that they need to adopt the roles and responsibilities of an AI PM in their own product areas.&nbsp; Lack of a specific role definition doesn’t prevent success, but it does introduce the risk that technical debt will accumulate as the business scales.&nbsp; It is important that an organization’s overall data strategy include waypoints (which may be the stages in the product pipeline) that mark the appropriate time and conditions for upgrading AI resources, technology, and leadership.&nbsp; This responsibility falls to executive leadership.&nbsp; Strong AI product management and engineering leadership cannot thrive without support from the C-suite.</p>\n\n\n\n<p>In startup environments, the lack of data, the relative immaturity of artificial intelligence and machine learning, the platform environment, and access to AI talent precludes more ambitious projects.&nbsp; This is both an advantage and a disadvantage! AI PMs in startups enjoy the benefits of flexibility, velocity, and rapid experimentation that enterprise AI PMs could only dream of.&nbsp; When managed properly, AI products in small firms can add value for the customer and the business almost immediately, and customer feedback can be integrated rapidly.&nbsp; However, as the business scales (or if the original AI product requires significant cross-team coordination), the responsibilities of the startup AI PM can quickly prove to be overwhelming, requiring negotiation between different teams with different goals, objectives, metrics, and responsibilities.</p>\n\n\n\n<p>For example, consider a company that aims to build and sell an AI-enabled personal finance app.&nbsp; The product’s core features, predicting users’ most common financial planning, banking and expense activities, then executing them automatically, are simple enough when the user population is low and the set of actions that the product must support is small.&nbsp; A single PM can manage the roadmap for the entire product, including the core model, data platform, APIs, and UI/X.&nbsp; Now consider the same product as it reaches its 100,000th user and expands to its first international city.&nbsp; It’s highly unlikely that the same ML model will generalize to the growing user population, and it’s nearly impossible that the same APIs and other integrations will scale globally to support international use. Usage will be different; what people expect from financial institutions will be different; regulation will be different. Organizations that can successfully navigate the transition from startup to enterprise AI are the ones that carefully consider the skill set and experience of the AI PM at each stage of growth.</p>\n\n\n\n<h4>The Data Expertise of the AI PM</h4>\n\n\n\n<p>Product Managers are expected to bring a cross-functional skill set to the table, so that they can support all aspects of bringing a product to market and supporting it through its lifecycle.&nbsp; Some product managers may be more technical, perhaps with a background or education in software engineering; others may specialize in design, customer success, UI/UX, or some other aspect of product development. Product managers for AI must be able to support their products throughout the entire pipeline, and as a result some expertise in each of the key categories is required.&nbsp; It is not our aim to provide an exact specification for the skills that will ultimately make an AI PM successful, but rather to identify the minimum viable skill set necessary to support the AI product lifecycle.</p>\n\n\n\n<p><strong>Skill-Data Lifecycle and Pipeline Management: </strong>No AI product can succeed without quality data. AI PMs must learn to operate in an environment where the economics and resource constraints inherent to obtaining data, processing it for use in experiments and customer-facing AI products, and ensuring quality over time are seldom favorable.&nbsp; At a minimum, AI PMs must understand the vocabulary of this space and be able to contribute to platform decisions that will impact AI products downstream.</p>\n\n\n\n<p><strong>Skill-Experimentation and Measurement: </strong>Whether through exploratory experimentation, pre-deployment A/B testing, or post-deployment evaluation of adoption and engagement, AI PMs must be excellent designers of experiments and experts at interpreting experiment results. The minimum viable skill set in this area includes a basic understanding of probability theory (distributions, cohorting, confidence, power, etc.), a deep understanding of <a href=\"https://hbr.org/2017/09/the-surprising-power-of-online-experiments\">A/B testing</a>, and a similarly deep knowledge of model evaluation techniques. Avinash Kaushik’s <a href=\"https://learning.oreilly.com/library/view/web-analytics-20/9780470529393/\">Web Analytics 2.0</a> is an excellent introduction to metrics and analytics.</p>\n\n\n\n<p><strong>Skill-DS/ML/AI Development Process:</strong> At a minimum, Software Engineering PMs should be fluent in the processes and language of effective software development.&nbsp; They should be familiar with agile software development practices, continuous integration and <a href=\"https://learning.oreilly.com/library/view/continuous-delivery-reliable/9780321670250/\">continuous deployment</a> (<a href=\"https://learning.oreilly.com/videos/engineering-practices-for/9781491908181\">CI/CD</a>), and the <a href=\"https://learning.oreilly.com/library/view/effective-devops/9781491926291/\">principles</a> of <a href=\"https://learning.oreilly.com/library/view/python-for-devops/9781492057680/\">DevOps</a>.&nbsp; AI PMs should possess some degree of expertise in development processes for data science and machine learning, such as <a href=\"https://www.ibm.com/support/knowledgecenter/SS3RA7_15.0.0/com.ibm.spss.crispdm.help/crisp_overview.htm\">CRISP-DM</a>, the Microsoft Team Data Science Process (<a href=\"https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview\">TDSP</a>), or <a href=\"https://martinfowler.com/articles/cd4ml.html\">Continuous Delivery for Machine Learning</a>. If the AI product manager doesn’t have a background in software products, they should be sure to enlist the support of a product manager who does. The point isn’t so much what process you use, but to have a process.</p>\n\n\n\n<h4>Conclusion</h4>\n\n\n\n<p>Nobody has all of the skills at the same time, so get to work building the ones you need. There are many resources available for people who want to develop AI skills: blogs, papers, competitions, and courses, all both paid and free. A product manager for AI doesn’t have to be an expert in everything–or even in anything.&nbsp; But a successful product manager does need to have a broad view of how AI products are built, from start to finish.</p>\n\n\n\n<p>In our next article, we’ll look in more detail at the development process and the product manager’s responsibilities at each stage of that process.<br></p>\n\n\n\n<p> <br></p>\n\n\n\n<p><br></p>\n\n\n\n<p><br></p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/OCLvXNrobdo\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 14 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/rCWzPESnrkM/\n<ol>\n<li><a href=\"https://www.welivesecurity.com/2020/05/13/ramsay-cyberespionage-toolkit-airgapped-networks/\">Malware Toolkit Targetting Airgapped Networks</a> &#8212; <i>ESET researchers have discovered a previously unreported cyber-espionage framework that we named Ramsay and that is tailored for collection and exfiltration of sensitive documents and is capable of operating within air‑gapped networks.</i></li>\n<li><a href=\"https://www.technologyreview.com/2020/05/11/1001563/covid-pandemic-broken-ai-machine-learning-amazon-retail-fraud-humans-in-the-loop/\">Our Weird Behavior During the Pandemic is Messing with AI Models</a> &#8212; <i>Machine-learning models trained on normal human behavior are now finding that normal has changed, and some are no longer working as they should.</i></li>\n<li><a href=\"https://github.com/johnboiles/obs-mac-virtualcam\">OBS Mac</a> &#8212; <i>Creates a virtual webcam device from the output of OBS. Especially useful for streaming smooth, composited video into Zoom, Hangouts, Jitsi etc.</i></li>\n<li><a href=\"https://deno.land/\">Deno</a> &#8212; <i>Deno is a new runtime for executing JavaScript and TypeScript outside of the web browser.</i> Server-side JavaScript from some of the folks behind node.js and built in Rust.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/rCWzPESnrkM\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 13 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/KQ5CMAVsal8/\n<ol>\n<li><a href=\"https://www.wired.com/story/confessions-marcus-hutchins-hacker-who-saved-the-internet/\">The Confessions of Marcus Hutchins, the Hacker Who Saved the Internet</a> &#8212; Story of the MalwareTech security researcher who foiled WannaCry, only to be arrested by the FBI for having sold malware as a kid. Young Marcus had terrible opsec.</li>\n<li><a href=\"https://www.nfx.com/post/next-social-era/\">The Next Social Era is Here</a> &#8212; Arguing we&#8217;re ready for another boom in social software. <i>First, the pandemic is creating a new topology of psychological and emotional needs. [&#8230;] Second, the work environment is now open game for new social products. Two reasons for this. First, we see how good communication can be with consumer products and demand the same excellence in our work lives. But second, and newer, is that in the last few months, the distance between our work identities and our home identities have blurred. </i></li>\n<li><a href=\"https://blogs.gartner.com/martin-kihn/cookies-chaos-and-the-browser-meet-lou-montulli/\">Cookies, Chaos and the Browser: Meet Lou Montulli</a> &#8212; An interview with a Web oldbie, the guy who worked on https, cookies, forms, animated GIFs, but who will always have a treasured spot in my heart for the Curses-based text-mode browser Lynx.</li>\n<li><a href=\"https://saagarjha.com/blog/2020/05/10/why-we-at-famous-company-switched-to-hyped-technology/\">Why we at $FAMOUS_COMPANY Switched to $HYPED_TECHNOLOGY</a> &#8212; Hilarious parody of a tech announcement.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/KQ5CMAVsal8\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 12 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/V6dF5m1ZxBM/\n<ol>\n<li><a href=\"https://github.com/SanderMertens/flecs\">flecs</a> &#8212; <i>a Fast and Lightweight ECS (Entity Component System). An ECS [&#8230;] is a way to organize code that is mostly used in gaming and simulation projects. ECS code generally performs better than traditional OOP, and is typically easier to reuse. The main differences between ECS and OOP are composition is a first class citizen in ECS, and that data is represented as plain data types rather than encapsulated classes.</i></li>\n<li><a href=\"https://spin.atomicobject.com/2020/05/11/categorize-software-errors/\">Two Ways to Categorize Errors</a> &#8212; <i>two dimensions that are useful for categorizing errors: Exceptional Errors vs. Failures; Internal vs. External Errors.</i> Often the first step to solving a problem is finding the right lens to look at it through.</li>\n<li><a href=\"https://a9.io/glue-comic/\">Chatting with Glue</a> &#8212; An interestingly-presented set of ideas about how we might offer more structural affordances in chat software to assist comprehension. I&#8217;m not doing it justice: it&#8217;s provocative. How to help people think better with software is a conversation I&#8217;m always up for, so this has really hit my buttons.</li>\n<li><a href=\"https://fivebooks.com/best-books/politics-of-information-henry-farrell/\">The Best Books on the Politics of Information</a> &#8212; <i>If we are to understand how politics and markets work at the moment, we need to pay attention to how algorithms work, and how the economy is being remade from the ground up by these new forms of information processing. [&#8230;] My starting point was ‘Okay, if we started thinking about the core of a curriculum for a course on this topic, what could we include?’ These would be the core books you would want as part of the discussion.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/V6dF5m1ZxBM\" height=\"1\" width=\"1\" alt=\"\"/>\nWhen models are everywhere\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/sGh3eBhuYOo/\n<p>You probably interact with fifty to a hundred machine learning products every day, from your social media feeds and YouTube recommendations to your email spam filter and the updates that the New York Times, CNN, or Fox News decide to push, not to mention the hidden models that place ads on the websites you visit, and that redesign your &#8216;experience&#8217; on the fly. Not all models are created equal, however: they operate on different principles, and impact us as individuals and communities in different ways. They differ fundamentally from each other along dimensions such as alignment of incentives between stakeholders, “creep factor”, and the nature of how their feedback loops operate.&nbsp;<br></p>\n\n\n\n<p>To understand the menagerie of models that are fundamentally altering our individual and shared realities, we need to build a typology, a classification of their effects and impacts. This typology is based on concepts such as the nature of different feedback loops in currently deployed algorithms, and how incentives can be aligned and misaligned between various stakeholders. Let’s start by looking at how models impact us.<br></p>\n\n\n\n<p><strong>SCREENS, FEEDBACK, AND “THE ENTERTAINMENT”</strong><br></p>\n\n\n\n<p>Many of the models you interact with are mediated through screens, and there’s no shortage of news about how many of us spend our lives glued to them. <a href=\"https://www.theguardian.com/technology/2018/aug/22/kids-are-glued-to-their-screens-but-parents-are-in-no-position-to-criticize\">Children, parents, friends, relatives</a>: we are all subject to screens, ranging from screens that fit on our wrist to screens that occupy entire walls. You may have seen loved ones sitting on the couch, watching a smart TV while playing a game on an iPad, texting on their smartphones, and receiving update after update on their Apple Watch, a kaleidoscope of screens of decreasing size. We even have apps to monitor and limit screen time. Limiting screen time has been an option on iPhones for over a year, and there are <a href=\"https://www.educationalappstore.com/best-apps/best-parental-control-apps-to-monitor-and-limit-screen-time\">apps</a> for iPhones and Android that not only monitor your childrens’ screen time, they let you <a href=\"https://www.educationalappstore.com/app/screen-time-parental-control\">reward</a> them for doing their chores or their homework by giving them more. Screen time has been gamified: where are you on the leaderboard?&nbsp;<br></p>\n\n\n\n<p>We shouldn’t be surprised. In the 70s, TV wasn’t called the “boob tube” for nothing. In David Foster Wallace’s novel <em>Infinite Jest</em>, there is a video tape known as “The Entertainment.” When somebody watches it, they are unable to look away, no longer caring about food, shelter or sleep, and they eventually enter a state of immobile, catatonic bliss. There’s a telling sequence in which more and more people approach those watching it to see what all the hullabaloo is about and also end up with their eyes glued to the screen.&nbsp;<br></p>\n\n\n\n<p><em>Infinite Jest</em> was published in 1996, just as the modern Web was coming into being. It predates recommendation engines, social media, engagement metrics, and the recent explosion of AI, but not by much. And like a lot of near-future SciFi, it’s remarkably prescient. It’s a shock to read a novel about the future, and realize that you’re living that future.&nbsp;<br></p>\n\n\n\n<p>“The Entertainment” is <em>not</em> the result of algorithms, business incentives and product managers optimizing for engagement metrics. There’s no Facebook, Twitter, or even a Web; it’s a curious relic of the 80s and 90s that The Entertainment appeared in the form of a VHS tape, rather than an app. “The Entertainment” <em>is</em> a tale of the webs that connect form, content and addiction, along with the societal networks and feedback loops that keep us glued to our screens. David Foster Wallace had the general structure of the user–product interaction correct. That loop isn’t new, of course; it was well-known to TV network executives. Television only lacked the immediate feedback that comes with clicks, tracking cookies, tracking pixels, online experimentation, machine learning, and “agile” product cycles.&nbsp;&nbsp;</p>\n\n\n\n<p>Does “The Entertainment” show people what they want to see? In a highly specific, short-term sense, possibly. In a long-term sense, definitely not. Regardless of how we think of ourselves, humans aren’t terribly good at trading off short-term stimulus against long-term benefits. That’s something we’re all familiar with: we’d rather eat bacon than vegetables, we’d rather watch Game of Thrones than do homework, and so on.&nbsp; Short-term stimulus is addictive: maybe not as addictive as “The Entertainment,” but addictive nonetheless.&nbsp;&nbsp;<br></p>\n\n\n\n<p><strong>YOUTUBE, CONSPIRACY, AND OPTIMIZATION</strong><br></p>\n\n\n\n<p>We’ve seen the same argument play out on YouTube: when their recommendation algorithm was optimized for how long users would keep their eyeballs on YouTube, resulting in more polarizing conspiracy videos being shown, we were told that YouTube was showing people what they wanted to see. This is a subtle sleight-of-mind, and it’s also wrong. As Zeynep Tufekci <a href=\"https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth\">points out</a>, this is analogous to an automated school cafeteria loading plates with fatty, salty, and sweet food because it has figured out that’s what keeps kids in the cafeteria the longest. What’s also interesting is that YouTube never wrote &#8216;Show more polarizing conspiracy videos&#8217; into their algorithm: that was merely a result of the optimization process. YouTube’s algorithm was measuring what kept viewers there the longest, not what they wanted to see, and feeding them more of the same. Like sugar and fat, conspiracy videos proved to be addictive, regardless of the viewer’s position on any given cause. If “The Entertainment” were posted to YouTube, it would be highly recommended on the platform: viewers can’t leave. It’s the ultimate <a href=\"https://www.darkpatterns.org/types-of-dark-pattern/roach-motel\">virtual roach trap</a>. If that’s not engagement, what is? But it’s clearly not what viewers want–viewers certainly don’t want to forget about food and shelter, not even for a great TV show.&nbsp;<br></p>\n\n\n\n<p>One result of this is that in 2016, out of 1,000 videos recommended by YouTube after an equal number of searches for “Trump” and “Clinton”,<a href=\"https://www.theguardian.com/technology/2018/feb/02/youtube-algorithm-election-clinton-trump-guillaume-chaslot\"> 86% of recommended videos favored the Republican nominee</a>. In retrospect, the recommendation algorithm’s “logic” is inescapable. If you’re a Democrat, Trump videos made you mad. If you’re a Republican, Trump’s content was designed to make you mad. And anger and polarization are bankable commodities that drive the feedback loop in an engagement-driven world.&nbsp;<br></p>\n\n\n\n<p>Another result is the weirdness encountered in certain parts of kids’ Youtube, such as “<a href=\"https://vicki.substack.com/p/the-reign-of-big-recsys\">surprise Eggs videos [that] depict, often at excruciating length, the process of unwrapping Kinder and other egg toys</a>.” Some of these have up to<a href=\"http://nymag.com/intelligencer/2016/04/inside-the-strange-world-of-million-view-surprise-egg-youtube-videos.html\"> 66 million views</a>. These are all results of business incentives for both YouTube and its content providers, the metrics used to measure success and the power of feedback loops on an individual level and in society, as manifested in modern big tech recommender systems.&nbsp;<br></p>\n\n\n\n<p>It’s important to note that the incentives of YouTube, its advertisers, and its users are often misaligned, in that users searching for “real news” continually end up being shunted down conspiracy theory and “fake news” rabbit holes due to the mixed incentive structure of the advertising-based business model. Such mixed incentives were even noted by Google founders Sergey Brin and Larry Page in their 1998 paper <em>The Anatomy of a Large-Scale Hypertextual Web Search Engine</em>, which details their first implementation of the Google Search algorithm. In <a href=\"http://infolab.stanford.edu/~backrub/google.html#a\">Appendix A</a>, aptly titled ‘Advertising and Mixed Motives’, Brin and Page state explicitly that “the goals of the advertising business model do not always correspond to providing quality search to users” and “we expect that advertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers.” *Gulp*. Also note that they refer to the user of Search here as a consumer.</p>\n\n\n\n<p><strong>FEEDBACK LOOPS, FILTER BUBBLES, ECHO CHAMBERS, AND INCENTIVE STRUCTURES</strong><br></p>\n\n\n\n<p>YouTube is a case study on the impact of feedback loops on the individual: if I watch something for a certain amount of time, YouTube will recommend similar things to me, for some definition of similar (similarity is defined by broader societal interactions with content), resulting in what we now call “filter bubbles”, a term coined by internet activist Eli Pariser in his 2011 book <a href=\"https://books.google.com/books/about/The_Filter_Bubble.html?id=-FWO0puw3nYC\"><em>The Filter Bubble: What the Internet Is Hiding from You</em></a>. Netflix’s algorithm has historically resulted in similar types of recommendations and filter bubbles (although business incentives are now forcing them to<a href=\"https://vicki.substack.com/p/big-recsys-redux-recs-at-netflix\"> surface more of their own content</a>).</p>\n\n\n\n<p>Twitter and Facebook have feedback loops that operate slightly differently, because every user can be both a content provider and a consumer, and the recommendations arise from a network of multi-sided interactions. If I’m sharing content and liking content, the respective algorithms will show me more that is similar to both, resulting in what we call “echo chambers.” These echo chambers represent a different kind of feedback that doesn’t just involve a single user: it’s a feedback loop that involves the user and their connections. The network that directly impacts me is that of my connections and the people I follow.&nbsp;<br></p>\n\n\n\n<p>We don’t have to look far to see other feedback loops offline. There are runaway <a href=\"https://www.smithsonianmag.com/innovation/artificial-intelligence-is-now-used-predict-crime-is-it-biased-180968337/\">feedback loops in “predictive policing”</a>, whereby more police are sent to neighborhoods with higher “reported &amp; predicted crime,” resulting in more police being sent there and more reports of crime and so on. Due to the information and power asymmetries at play here, along with how such feedback loops discriminate against specific socioeconomic classes, projects such as <a href=\"https://whitecollar.thenewinquiry.com/\"><em>White Collar Crime Risk Zones</em></a>, which maps predictions of white collar crime, are important. <a href=\"https://www.theverge.com/2019/10/24/20929337/care-algorithm-study-race-bias-health\">An application that hospitals use to screen for patients</a> with high-risk conditions that require special care wasn’t recommending that care for black patients as often; white patients spend more on health care, making their conditions appear to be more serious. While these applications look completely different, the feedback loop is the same. If you spend more, you get more care; if you police more, you make more arrests. And the cycle goes on. Note that in both cases, a major part of the problem was also the use of proxies for metrics: cost as a proxy for health, police reports a proxy for crime, not dissimilar to the use of Youtube view-time as a proxy for what a viewer <em>wants</em> to watch (for more on metrics and proxies, we <em>highly </em>recommend the post <a href=\"https://www.fast.ai/2019/09/24/metrics/\">The problem with metrics is a big problem for AI</a> by Rachel Thomas, Director of the Center for Applied Data Ethics at USF). There are also interaction effects between many models deployed in society that mean they feedback into each other: those most likely to be treated unfairly by the healthcare algorithm are more likely to be discriminated against by models used in employment hiring flows and more likely to be targeted by predatory payday loan ads online, as detailed by Cathy O’Neil in <a href=\"https://weaponsofmathdestructionbook.com/\">Weapons of Math Destruction</a>.</p>\n\n\n\n<p>Google search operates at another scale of networked feedback, that of <em>everybody</em>. When I search for “Artificial Intelligence,” the results aren’t only a function of what Google knows about me, but also of how successful each link has been for everybody that has seen it previously. Google Search also operates in a fundamentally different way to many modern recommendation systems: historically, it has optimized its results to get you off its platform, though recently <a href=\"https://qz.com/1540608/the-problem-with-silicon-valleys-obsession-with-blitzscaling-growth/\">its emphasis has shifted</a>. Whereas so many tech companies optimize for engagement with their platforms, trying to keep you from going elsewhere, Google’s incentive with Search was to direct you to another site, most often for the purpose of discovering facts. Under this model, there is an argument that the incentives of Google, advertisers, and users were all aligned, at least when searching for basic facts: all three stakeholders <em>want </em>to get the right fact in front of the user, at least in theory. This is why Search weighs long clicks more heavily than short clicks (the longer the time before the user clicks back to Google, the better).&nbsp; Now that Google has <a href=\"https://www.oreilly.com/ideas/antitrust-regulators-are-using-the-wrong-tools-to-break-up-big-tech\">shifted to providing answers to questions</a> rather than links to answers, they are valuing engagement with their platform over engagement with other advertisers; as an advertiser, you’re more likely to succeed if you advertise directly on Google’s result page. Even more recently, Google <a href=\"https://www.blog.google/products/search/search-language-understanding-bert/\">announced</a> its incorporation of BERT (Bidirectional Encoder Representations from Transformers, a technology enabling “anyone to train their own state-of-the-art question answering system”) into Search, which will allow users to make more complex and conversational queries and will enable you to “search in a way that feels natural for you” (according to Google, this is “one of the biggest leaps forward in the history of Search”). Fundamental changes in Search to encourage more complex queries could result in a shift of incentives.&nbsp;<br></p>\n\n\n\n<p>Also, this theoretical alignment of incentives between Google, advertisers, and users is an idealization. In practice, Google search encodes all types of cultural and societal biases, such as racial discrimination, as investigated in Safiya Noble’s <a href=\"https://nyupress.org/9781479837243/algorithms-of-oppression/\"><em>Algorithms of Oppression</em></a>. An example of this is that, for many years, when using Google image search with the keyword “beautiful,” the results would be dominated by photos of white women. In the words of <a href=\"https://www.ruhabenjamin.com/\">Ruha Benjamin</a>, Associate Professor of African American Studies at Princeton University, “race and technology are co-produced.”&nbsp;&nbsp;<br></p>\n\n\n\n<p>A final word (for now) on developing healthy Google Search habits and practices: know that the SEO (Search Engine Optimization) industry is worth close to $80 billion and that the way you’re served results and the potential mis-alignment of incentives depends on whether your search is <em>informational </em>(searching for information, such as “Who was the 44th President of the United States?”), <em>navigational </em>(searching for a particular website, such as “Wikipedia”), or <em>transactional </em>(searching to buy something, such as “Buy Masterclass subscription”). Keep a skeptical mind about the results you’re served! Personalization of search results may be handy in the short-term.&nbsp; However, when making informational searches, you’re being served what you regularly assume is ground truth but is tailored to you, based on what Google already knows about your online and, increasingly, offline behavior. There is also an information asymmetry, in that you don’t know what Google knows about you, and how that information plays into the incentives of Google’s ad-based business model. For informational searches, this could be quite disturbing. As Jaron Lanier points out in <a href=\"http://www.jaronlanier.com/tenarguments.html\"><em>Ten Arguments for Deleting Your Social Media Accounts Right Now</em></a>, how would you feel if Wikipedia showed you and I different histories, based on our respective browser activities? To take this a step further, what if Wikipedia tailored the “facts” served to us as a function of an ad-based business model?<br></p>\n\n\n\n<p>For advertisers, incentive systems are also strangely skewed. We recently searched for Stitch Fix, the online personal styling service. This is a basic navigational search and Google could easily have served us the Stitch Fix website and they did, but above it were two advertisements: the first one was for Stitch Fix and the second one was for Trunk Club, a Stitch Fix competitor. This means that Trunk Club is buying ads for the keywords of their competitor, a common practice, and Stitch Fix then had to engage in defensive advertising due to how much traffic Google Search has, even when the user is clearly looking for their product! As a result, the user sees only ads above the scroll (at least on a cell phone) and needs to scroll down to find the correct and obvious search result. There is an argument that, if a user is explicitly searching to buy a product, it should be illegal for Google to force the product in question into defensive advertising.</p>\n\n\n\n<p><strong>TOWARDS A TYPOLOGY OF MODEL IMPACT AND EFFECTS</strong><br></p>\n\n\n\n<p>YouTube, the Facebook feed, Google Search, and Twitter are examples of modern algorithms and models that alter our perceptions of reality; applications like predictive policing reflect biased perceptions of reality that may have little to do with actual reality–indeed, these models create their own realities, becoming self-fulfilling prophecies. They all operate in different ways and on different principles. The nature of the feedback loops, the resulting phenomena, and the alignment of incentives between user, platform, content providers and advertisers are all different. In a world that’s increasingly filled with models, we need to assess their impact, identify challenges and concerns, and discuss and implement paths in the solution space.</p>\n\n\n\n<p>This first attempt at a model impact and effect classification probed several models that are part of our daily lives by looking at the nature of their feedback loops and the alignment of incentives between stakeholders (model builders, users, and advertisers). Other key dimensions to explore include “creep” factor, “hackability” factor, and how networked the model itself is (is it constantly online and re-trained?). Such a classification will allow us to assess the potential impact of classes of models, consider how we wish to interact with them, and to propose paths forward. This work is part of a broader movement of users, researchers, and builders who are actively engaged in discovering and documenting how these models work, are deployed, and what their impacts are. If you are interested in exploring this space, we encourage you to check out the non-exhaustive reading list below.<br></p>\n\n\n\n<p>***<br></p>\n\n\n\n<p>The authors would like to thank <a href=\"https://twitter.com/shiraamitchell\">Shira Mitchell</a> for valuable feedback on an early draft of this essay and <a href=\"https://datasociety.net/people/moss-emanuel/\">Manny Moss</a> for valuable feedback on a late draft.<br></p>\n\n\n\n<p><strong>READING LIST</strong><br></p>\n\n\n\n<ul><li><a href=\"https://arxiv.org/abs/1810.03993\">Model Cards for Model Reporting</a> by Mitchell et al.</li><li><a href=\"https://arxiv.org/abs/1803.09010\">Datasheets for Datasets</a> by Gerbu et al.</li><li><a href=\"https://www.aclweb.org/anthology/Q18-1041/\">Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science</a> by Bender &amp; Friedman</li><li><a href=\"https://anatomyof.ai/\">Anatomy of an AI System</a> by Crawford and Joler</li><li><a href=\"https://nyupress.org/9781479837243/algorithms-of-oppression/\">Algorithms of Oppression</a> by Safiya Umoja Noble</li><li><a href=\"https://weaponsofmathdestructionbook.com/\">Weapons of Math Destruction</a> by Cathy O’Neil</li><li><a href=\"https://www.ruhabenjamin.com/race-after-technology\">Race after Technology</a> by Ruha Benjamin</li><li><a href=\"https://us.macmillan.com/books/9781250074317\">Automating Inequality</a> by Virginia Eubanks</li><li><a href=\"https://www.twitterandteargas.org/\">Twitter and Tear Gas</a> by Zeynep Tufekci</li><li><a href=\"https://yalebooks.yale.edu/book/9780300199000/its-complicated\">It&#8217;s Complicated: The Social Lives of Networked Teens</a> by danah boyd</li><li><a href=\"http://www.jaronlanier.com/tenarguments.html\">Ten Arguments for Deleting Your Social Media Accounts Right Now</a> by Jaron Lanier</li><li><a href=\"https://www.ruinedby.design/\">Ruined by Design</a> by Mike Monteiro</li><li><a href=\"https://ainowinstitute.org/AI_Now_2018_Report.pdf\">AI Now Report 2018</a> by Whittaker et al.</li><li><a href=\"https://datasociety.net/output/owning-ethics-corporate-logics-silicon-valley-and-the-institutionalization-of-ethics/\">Owning Ethics: Corporate Logics, Silicon Valley, and the Institutionalization of Ethics</a> by Jacob Metcalf, Emanuel Moss, and danah boyd (Data &amp; Society)</li><li><a href=\"https://www.youtube.com/watch?v=jIXIuYdnyyk\">21 Fairness Definitions and Their Politics</a>, a tutorial by Arvind Narayanan at <a href=\"https://fatconference.org/\">FAT*</a> 2018</li><li><a href=\"https://arxiv.org/abs/1811.07867\">Prediction-Based Decisions and Fairness: A Catalogue of Choices, Assumptions, and Definitions</a> by Mitchell et al.</li><li><a href=\"https://www.fast.ai/2019/09/24/metrics/\">The problem with metrics is a big problem for AI</a> by Rachel Thomas</li><li><a href=\"https://datascience.columbia.edu/ethical-principles-okrs-and-kpis-what-youtube-and-facebook-could-learn-tukey\">Ethical Principles, OKRs, and KPIs: what YouTube and Facebook could learn from Tukey</a> by Chris Wiggins</li><li><a href=\"https://datasociety.net/output/algorithmic-accountability-a-primer/\">Algorithmic Accountability: A Primer</a> by Caplan et al. (Data &amp; Society)</li><li>The <a href=\"https://www.odbproject.org/wp-content/uploads/2019/03/ODB_DDP_HighRes_Single.pdf\">Digital Defense Playbook</a> by <a href=\"https://www.odbproject.org/\">Our Data Bodies</a></li><li>The <a href=\"https://www.ajlunited.org/\">Algorithmic Justice League</a></li></ul>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/sGh3eBhuYOo\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 11 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/qa0FsPUaJS0/\n<ol>\n<li><a href=\"https://github.com/oragono/oragono\">Oragono</a> &#8212; <i>a modern IRC server written in Go</i>.</li>\n<li><a href=\"https://fifteen.ai/\">DeepFake Cartoon Voices</a> &#8212; Fifteen.ai is <i>a text-to-speech tool that you can use to generate 44.1 kHz voices of various characters. The voices are generated in real time using multiple audio synthesis algorithms and customized deep neural networks trained on very little available data (between 55 seconds and 120 minutes of clean dialogue for each character). This project demonstrates a significant reduction in the amount of audio required to realistically clone voices while retaining their affective prosodies.</i></li>\n<li><a href=\"https://github.com/angrave/SystemProgramming/wiki\">System Programming Book</a> &#8212; CS241 &#8220;Intro to Systems Programming&#8221; textbook that was created in a wiki by University of Illinois students over 5 years.</li>\n<li><a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2009/10/Realizing-Quality-Improvement-Through-Test-Driven-Development-Results-and-Experiences-of-Four-Industrial-Teams-nagappan_tdd.pdf\">Realizing Quality Improvement Through Test Driven Development: Results and Experiences of Four Industrial Teams</a> &#8212; <i>The results of the case studies indicate that the pre-release defect density of the four products decreased between 40% and 90% relative to similar projects that did not use the TDD practice. Subjectively, the teams experienced a 15–35% increase in initial development time after adopting TDD.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/qa0FsPUaJS0\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 8 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/fFqKH7WawVM/\n<ol>\n<li><a href=\"https://mml-book.github.io/\">Mathematics for Machine Learning</a> &#8212; <i>We wrote a book on Mathematics for Machine Learning that motivates people to learn mathematical concepts. The book is not intended to cover advanced machine learning techniques because there are already plenty of books doing this. Instead, we aim to provide the necessary mathematical skills to read those other books.</i></li>\n<li><a href=\"https://github.com/cardsagainstcontainers/deck\">Cards Against Containers</a> &#8212; nerd cards a-la Cards Against Humanity. (But without the swears.)</li>\n<li><a href=\"https://opensafely.org/\">OpenSAFELY</a> &#8212; <i>a new secure analytics platform for electronic health records in the NHS, created to deliver urgent results during the global COVID-19 emergency. It is now successfully delivering analyses across more than 24 million patients’ full pseudonymised primary care NHS records, with more to follow shortly. All our analytic software is open for security review, scientific review, and re-use</i>. An amazing collaborative piece of work that you can read about in <a href=\"https://twitter.com/bengoldacre/status/1258431405450833921\">Ben Goldacre&#8217;s thread</a>.</li>\n<li><a href=\"https://www.oreilly.com/radar/radar-trends-to-watch-may-2020/\">Radar Trends to Watch in May 2020</a> &#8212; Mike Loukides&#8217;s roundup of weak signs of the future.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/fFqKH7WawVM\" height=\"1\" width=\"1\" alt=\"\"/>\nRadar trends to watch: May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/a7i2dB4x85I/\n<p>After last month’s “all coronavirus, all the time” report, I was concerned that this month would be more of the same.&nbsp; And there is, indeed, a lot of coronavirus. But there are many other trends and interesting items to look at–possibly a sign that people are working effectively from home.</p>\n\n\n\n<h3>Coronavirus</h3>\n\n\n\n<ul><li>Coronavirus prompts serious discussion of changes to the financial system. There’s no doubt that money’s dirty; and it isn’t terribly useful in the context of “social distancing.” Rethinking our financial system might lead to a <a href=\"https://www.technologyreview.com/2020/04/17/1000110/coronavirus-public-venmo-new-york/\">public venmo, or even further to a digital dolla</a>r.&nbsp; (China is the leader here–by a large margin.)<br></li></ul>\n\n\n\n<ul><li>Coronavirus and <a href=\"https://www.technologyreview.com/2020/04/16/999944/coronavirus-animal-crossing-video-games-social-media/\">game play</a>: Not surprisingly, COVID-19 has led to a big surge in <a href=\"https://techxplore.com/news/2020-04-digital-video-game-high-virus.html\">game play and virtual reality</a>. Might surviving isolation during a pandemic be the killer app for VR?&nbsp; (This trend arrived too late to help the VR startup Magic Leap, which appears to be <a href=\"https://techcrunch.com/2020/04/27/daily-crunch-what-went-wrong-at-magic-leap/\">failing</a>.) Fred Wilson <a href=\"https://avc.com/2020/04/in-real-life/\">says</a>, wisely I think, that social isolation will teach how much we crave being in “real life.”<br></li></ul>\n\n\n\n<ul><li>It’s hardly news that <a href=\"https://techxplore.com/news/2020-04-coronavirus-misinformation-social-media-users.html\">misinformation</a> about Coronavirus is proliferating. The big question is whether automated attempts to stop that proliferation will succeed. <a href=\"https://www.engadget.com/2020-04-05-youtube-to-remove-5g-coronavirus-videos.html\">YouTube</a>, Twitter, and Facebook (including <a href=\"https://www.cnn.com/2020/04/07/tech/whatsapp-misinformation-forward-limit/index.html\">WhatsApp</a>) are cracking down. Facebook is referring people who see misinformation to “authoritative resources.”<br></li></ul>\n\n\n\n<ul><li>I haven’t heard as much about Citizen Science in the past few years, but it’s making a reappearance. <a href=\"https://fold.it/portal/blog\">Coronavirus binder designs</a> (proteins that bind to Coronavirus) modeled by citizen scientists, are in the pipeline for testing. Fold-it is a game where you design proteins (protein folding) to achieve some goal–in this case, binding to Coronavirus.<br></li></ul>\n\n\n\n<ul><li>Citizens are also playing a role on the front lines, with community-run <a href=\"https://caterina.net/2020/04/20/community-run-testing-for-covid-19/\">COVID-19 testing</a>.  (I’ve also seen pleas for citizens willing to help with contact tracing.)<br></li></ul>\n\n\n\n<ul><li>Apple and Google are <a href=\"https://www.apple.com/newsroom/2020/04/apple-and-google-partner-on-covid-19-contact-tracing-technology/\">collaborating</a> on OS-level tools for privacy-protecting contact tracing that will interoperate between Android and iOS. (Apps will be implemented by third parties, presumably healthcare organizations.) Germany was working on its own framework for contact tracing using cell phone apps, but it is now <a href=\"https://www.reuters.com/article/us-health-coronavirus-europe-tech/germany-flips-to-apple-google-approach-on-smartphone-contact-tracing-idUSKCN22807J\">backing the Apple-Google collaboration</a>.&nbsp;<br></li></ul>\n\n\n\n<ul><li>Will we see “<a href=\"https://techxplore.com/news/2020-04-virus-upends-outsourcing-firms-reshore.html\">re-shoring</a>” of jobs because of coronavirus? Outsourcing isn’t as attractive when lockdowns limit the supply of offshore labor, and it’s impossible to visit overseas contractors.&nbsp; Another consequence will be the increased use of AI, particularly in customer service.</li></ul>\n\n\n\n<h3>Robotics</h3>\n\n\n\n<ul><li><a href=\"https://www.mic.com/p/scientists-have-created-a-new-type-of-robot-that-is-literally-alive-22758584\">Xenobots</a> are living (literally) programmable robots, assembled from cultured frog skin cells.&nbsp;<br></li></ul>\n\n\n\n<ul><li>Farming is very high tech. A European project called ROMI is developing robots for <a href=\"https://cordis.europa.eu/project/id/773875\">weeding</a> crops on small (micro) farms; should cost <a href=\"https://techxplore.com/news/2020-04-robots-weeding-farms-patrolling-greenhouse.html\">under $5000</a>. Uses AI and computer vision to identify weeds and crop diseases.</li></ul>\n\n\n\n<h3>Artificial Intelligence and Machine Learning</h3>\n\n\n\n<ul><li>Good thinking about <a href=\"https://stratechery.com/2020/how-tech-can-build/\">how tech can build</a>: infusing manufacturing with software and intelligence (IoT); enabling remote work; getting beyond the unicorn mindset.<br></li></ul>\n\n\n\n<ul><li>Microsoft uses <a href=\"https://www.microsoft.com/security/blog/2020/04/16/secure-software-development-lifecycle-machine-learning/\">machine learning</a> to inspect source code for security vulnerabilities. They claim they can identify high priority security bugs in new code 97% of the time.<br></li></ul>\n\n\n\n<ul><li>Facebook uses <a href=\"https://www.technologyreview.com/2020/04/15/999871/facebook-ai-bot-simulation/\">AI bots</a> to simulate users for testing new social applications. They start up thousands of bots at a time to experiment with group dynamics, vulnerabilities, and privacy settings.<br></li></ul>\n\n\n\n<ul><li>Google Duo now uses AI to&nbsp; <a href=\"https://ai.googleblog.com/2020/04/improving-audio-quality-in-duo-with.html\">synthesize missing speech segments</a> arising from lost packets in calls.</li></ul>\n\n\n\n<h3>The new workplace</h3>\n\n\n\n<ul><li>Splunk announced Remote Work Insights, a <a href=\"https://www.splunk.com/en_us/blog/leadership/introducing-splunk-remote-work-insights-our-solution-for-the-new-work-from-home-reality.html\">network monitoring</a> product for work-at-home companies. It has been criticized as employee surveillance; Splunk has <a href=\"https://www.splunk.com/en_us/blog/leadership/introducing-splunk-remote-work-insights-our-solution-for-the-new-work-from-home-reality.html\">responded</a> that their intent is to monitor connectedness, not activity.&nbsp;&nbsp;<br></li></ul>\n\n\n\n<ul><li><a href=\"https://www.forbes.com/sites/columbiabusinessschool/2020/04/28/low-code-automation-and-the-future-of-work/\">Low-code automation</a> is another aspect of the democratization of technology. The idea is to build tools that can be used by people without requiring a lot of programming experience. The target audiences are all over the place: from unskilled workers to managers, and even to programmers, where these tools will simplify product development.&nbsp;</li></ul>\n\n\n\n<h3>Programming</h3>\n\n\n\n<ul><li>Microsoft announced IPE, a project that will <a href=\"https://www.zdnet.com/article/microsoft-announces-ipe-a-new-code-integrity-feature-for-linux/\">contribute</a> to the Linux kernel. IPE is for listing allowed binaries, and automatically checking signatures; it is intended for high security versions of Linux. But what’s more important is that this is another sign that Microsoft has changed very deeply.&nbsp;<br></li></ul>\n\n\n\n<ul><li>IBM is offering free <a href=\"https://www.inputmag.com/tech/ibm-will-offer-free-cobol-training-to-address-overloaded-unemployment-systems\">COBOL training</a>, in response to state governments’ needs for more programmers to update unemployment systems.<br></li></ul>\n\n\n\n<ul><li><a href=\"https://jupyterlab.readthedocs.io/en/latest/\">JupyterLab</a> is now a full-fledged, web-based, multi-language IDE for data.<br></li><li>Google is <a href=\"https://tryolabs.com/blog/2020/04/02/swift-googles-bet-on-differentiable-programming/\">adding differentiable programming</a> to the Swift programming language to simplify development of ML models. This means that their enhanced Swift language has primitives for computing the derivative/gradient of a function; in turn, this greatly simplifies key AI algorithms that involve gradient descent.</li></ul>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/a7i2dB4x85I\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 7 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/02gVn4fsoAs/\n<ol>\n<li><a href=\"https://christine.website/blog/super-bootable-64-2020-05-06\">Super Bootable 64</a> &#8212; Super Mario 64 shipped before the SDK was finalised, and it had to be compiled with optimisations turned off. This meant the binary was easily reversed to source code, and now the unportable has been ported. This site probably won&#8217;t last long, because DMCA, but it&#8217;s technically a sweet feat. (via <a href=\"https://lobste.rs/s/lmhaaa/super_bootable_64\">lobsters</a>)</li>\n<li><a href=\"https://mobile.twitter.com/BrianRoemmele/status/1257832168455208963\">IBM System/370 on a Raspberry Pi</a> &#8212; <i>I have been running a full IBM System/370 Mainframe on a $5 Raspberry Pi Zero for ~5 years. About 7 times faster System/370. Millions of lines of COBOL JCLs running flawless on a battery. Tested an entire bank’s mainframe COBOL on it.</i></li>\n<li><a href=\"https://github.com/aftertheflood/sparks\">sparks</a> &#8212; <i>A typeface for creating sparklines in text without code.</i></li>\n<li><a href=\"https://www.oversightboard.com/news/announcing-the-first-members-of-the-oversight-board/\">Announcing the First Members of the Oversight Board</a> &#8212; <i>The Board will review whether content is consistent with Facebook and Instagram’s policies and values, as well as a commitment to upholding freedom of expression within the framework of international norms of human rights. We will make decisions based on these principles, and the impact on users and society, without regard to Facebook’s economic, political or reputational interests. Facebook must implement our decisions, unless implementation could violate the law.</i> Impressive credentials. I&#8217;d love to be a fly on the wall for their conversations, because this problem is Hard.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/02gVn4fsoAs\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 6 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/JzKmpMWaB6M/\n<ol>\n<li><a href=\"http://www.open-raman.org/\">Raman Spectroscopy</a> &#8212; <i>Low Cost, High Performances, 100% Open Source Raman Spectrometer. [&#8230;] We currently offer the spectrometer in a Starter Edition version designed for teaching Raman spectroscopy and we will soon release a Performance Edition version which achieves a tested 12 cm-1 resolution at low costs.</i> Great to see this getting into the hands of hackers.</li>\n<li><a href=\"https://www.svese.de/impact-vs-backlog-frame-in-software-development\">Frames in Software Development</a> &#8212; not the Lisp AI frames, but the semantic frames. <i> I always wondered why it isn’t called “product debt” because product took the credit to get a feature faster and must pay back by investing the time to clean up. Technology is the bank that gave credit.</i></li>\n<li><a href=\"https://www.phoenixframework.org/\">Phoenix Framework</a> &#8212; <i>a web development framework written in Elixir which implements the server-side Model View Controller (MVC) pattern.</i> I&#8217;m reminded of <a href=\"https://twitter.com/ceejbot/status/1257390683930976262\">ceej&#8217;s</a> &#8220;Write your own frameworks. You learn a lot. Your framework might solve a problem your ecosystem needs to have solved. By your tenth one, you know enough to write one worth wide adoption. Progress in our industry depends on all of us pushing it forward.&#8221;</li>\n<li><a href=\"https://blog.twitter.com/engineering/en_us/topics/infrastructure/2020/deleting-data-distributed-throughout-your-microservices-architecture.html\">Deleting Data Distributed Throughout Your Microservices Architecture</a> &#8212; <i>One solution is to think of data deletion not as an event, but as a process. At Twitter, we call this process “erasure” and coordinate data deletion between systems using an erasure pipeline. In this post, we’ll discuss how to set up an erasure pipeline, including data discoverability, access, and processing. We’ll also touch on common problems and how to ensure ongoing maintenance of an erasure pipeline.</i></li>\n<li><a href=\"https://arxiv.org/abs/2003.11755\">A Survey of Deep Learning for Scientific Discovery</a> &#8212; <i>The sheer breadth and diversity of different deep learning techniques makes it difficult to determine what scientific problems might be most amenable to these methods, or which specific combination of methods might offer the most promising first approach. In this survey, we focus on addressing this central issue, providing an overview of many widely used deep learning models, spanning visual, sequential and graph structured data, associated tasks and different training methods, along with techniques to use deep learning with less data and better interpret these complex models &#8212; two central considerations for many scientific use cases. We also include overviews of the full design process, implementation tips, and links to a plethora of tutorials, research summaries and open-sourced deep learning pipelines and pretrained models, developed by the community.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/JzKmpMWaB6M\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 5 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/XxiXn3lntjQ/\n<ol>\n<li><a href=\"https://www.tbray.org/ongoing/When/202x/2020/04/29/Leaving-Amazon\">Leaving Amazon</a> (Tim Bray) &#8212; <i>May 1st was my last day as a VP and Distinguished Engineer at Amazon Web Services, after five years and five months of rewarding fun. I quit in dismay at Amazon firing whistleblowers who were making noise about warehouse employees frightened of Covid-19.</i></li>\n<li><a href=\"https://charity.wtf/2020/03/03/observability-is-a-many-splendored-thing/\">Observability is a Many-Splendoured Thing</a> (Charity Majors) &#8212; <i>if you <b>can’t</b> predict all the questions you’ll need to ask in advance, or if you <b>don’t</b> know what you’re looking for, then you’re in o11y territory.</i></li>\n<li><a href=\"https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html\">Using Neural Networks to Find Answers</a> (Google) &#8212; deep learning to figure out how to turn natural language questions into queries over tables of data.</li>\n<li><a href=\"https://widgets.weforum.org/blockchain-toolkit/\">Redesigning Trust: Blockchain Deployment Toolkit</a> &#8212; World Economic Forum report on distributed ledger deployments, with advice. <i>This toolkit provides tools, resources, and know-how to organizations undertaking blockchain projects. It was developed through lessons from and analysis of real projects, to help organizations embed best practices and avoid possible obstacles in deployment of distributed ledger technology</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/XxiXn3lntjQ\" height=\"1\" width=\"1\" alt=\"\"/>\nOn COBOL\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/qjjGs15OegQ/\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\">\n<p class=\"has-background has-text-align-left has-very-light-gray-background-color\">To continue learning and to get ahead with your career, check out <a rel=\"noreferrer noopener\" href=\"https://www.oreilly.com/\" target=\"_blank\">O&#8217;Reilly Learning</a> with a free trial.  Live online training, videos, books, certification prep, and more, from O&#8217;Reilly and our partner publishers.</p>\n\n\n\n<div class=\"wp-block-button\"><a class=\"wp-block-button__link has-text-color has-vivid-red-color has-background has-very-light-gray-background-color\" href=\"https://www.oreilly.com/\">O&#8217;Reilly Learning &gt;</a></div>\n</div></div>\n</div></div>\n\n\n\n<p><br><br>We’ve all seen that the world (well, governments, specifically <a href=\"https://qz.com/1832988/covid-19-results-in-new-jersey-desperately-needing-cobol-coders/\">state</a> <a href=\"https://onezero.medium.com/our-government-runs-on-a-60-year-old-coding-language-and-now-its-falling-apart-61ec0bc8e121\">governments</a>, to say nothing of the banks) is screaming for COBOL programmers—a cry that goes up roughly every five years. We somehow muddle through the crisis at hand, then people forget that it was ever a problem. It&#8217;s time we asked what the crisis really is, and why it keeps returning.<br></p>\n\n\n<p></p>\n\n\n<p>COBOL is one of the earliest programming languages; it was invented in 1960 and rose to prominence fairly quickly as a language that required minimal programming skills. (Real programmers wrote FORTRAN.) That&#8217;s not how COBOL’s inventors put it, but that is, to some extent, what they meant: a language that was supposed to be easy for programmers to learn, and that could also be understood by business people. Just look at what COBOL stands for: &#8220;Common Business-Oriented Language.&#8221; A programming language for business.<br></p>\n\n\n\n<p>COBOL&#8217;s influence faded in the 1980s, and now, there are billions of lines of code in governments, banks, enterprises, and elsewhere performing essential business functions with nobody to maintain them. COBOL programmers have grown old and retired, and nobody came along afterward.<br></p>\n\n\n\n<p>What&#8217;s the language like? I’ve had occasion to look at COBOL code, and my reaction hasn&#8217;t been what I expected. It doesn&#8217;t look like any &#8220;modern&#8221; language. But it&#8217;s not a strange antique from the days before people knew how to design decent languages. COBOL is a well-thought-out domain-specific language. It&#8217;s a business language that uses the language of businesspeople. Remember when Rubyists were proud that they could write statements that looked like idiomatic English? And that they could use metaprogramming to create domain-specific languages that used the vocabularies and concepts of different application domains? That was no small achievement. And COBOL did it 40-odd years earlier.<br></p>\n\n\n\n<p>Like other useful languages, COBOL never disappeared; but it has had surprisingly little influence on the development of computer languages, and that makes it look like it has died. In <a href=\"https://www.hillelwayne.com/post/influential-dead-languages/\">10 Most(ly) Dead Influential Programming Languages</a>, Hillel Wayne argues that COBOL had little influence on the development of programming languages because it came from the business community, and academics weren&#8217;t interested in it—for academics, it &#8220;wasn&#8217;t worth paying attention to.&#8221; Who wants to write code that&#8217;s readable by bankers and business people anyway? The allure of speaking a secret language that nobody else understood was always attractive to programmers.<br></p>\n\n\n\n<p>COBOL nevertheless made a number of important innovations. It had a concept of records (like rows in a database), which was related to a concept of hierarchical structures, looking forward to C structs and perhaps even objects. And it has a report generator—if that doesn&#8217;t sound interesting, remember that one of the initial applications for Perl was report generation. And that another nearly forgotten early language, <a href=\"https://en.wikipedia.org/wiki/IBM_RPG\">RPG</a>, was invented purely to generate reports. Reports aren&#8217;t glamorous, but they&#8217;re important.<br></p>\n\n\n\n<p>Syntactically, COBOL asked a really good question: Why do we need to use the bastardized language of mathematics to move money around, by saying something like &#8220;total = total + deposit&#8221;? Wouldn&#8217;t it be more natural to MOVE amounts from one account to another? Don&#8217;t get too excited. MOVE sounds like a proto-transaction, but it isn&#8217;t; it&#8217;s just an assignment. However, if you&#8217;re thinking about MOVE-ing money rather than assignment to a variable, those thoughts will lead you to atomic transactional operations sooner rather than later.<br></p>\n\n\n\n<p>Of course, there&#8217;s a lot that COBOL doesn&#8217;t offer. While COBOL has been updated with most of the features you’d expect in a modern language (since 2002, it’s even object-oriented), COBOL tends to lead to very awkward spaghetti code and monoliths. That&#8217;s 1960s programming for you. GOTO was an essential part of every programming language (even C has a goto statement). Modularization wasn&#8217;t well-understood, if it was understood at all. Libraries? The earliest versions of COBOL didn&#8217;t have a standard library, let alone user-defined libraries. Web frameworks? You don’t want to know. Microservices? Forget it.<br></p>\n\n\n\n<p>So, where are we now, with our billions of lines of COBOL running the world’s governments, and finances? I doubt there are many 1960s mainframes left, but there are plenty of emulations of 1960s mainframes running COBOL in the cloud much faster than the hardware it ran on initially. And that&#8217;s one strategy I&#8217;ve seen for maintaining COBOL: leave it as it is, run it on an emulator, wrap it up in a microservice written in some “modern” language, and hope you never have to touch it. That buys time, but while “hope” may solve the immediate problem, it’s a poor long-term strategy.<br></p>\n\n\n\n<p>The real problem isn&#8217;t just the lack of programmers fluent in a language that is no longer popular. There are also cultural problems that need to be addressed—and that have solutions that go beyond &#8220;train up a new batch of COBOL programmers.&#8221; First, one casualty of the &#8220;language wars&#8221; of the 90s and 00s is that we have an increasing number of programmers who identify with one language: they&#8217;re JavaScript programmers, or Java programmers, or Python programmers, or Rubyists. Dave Thomas’ and Andy Hunt’s advice to <a href=\"https://martinfowler.com/bliki/OneLanguage.html\">learn a new programming language every year</a> is just as valid as it was when they first wrote <a href=\"http://www.programmr.com/blogs/learn-new-programming-language-every-year\"><em>The Pragmatic Programmer</em></a>; but it goes sadly unheeded. To be a good programmer, you need to expose yourself to new ideas, new ways of thinking about problems—and, in the case of COBOL, old ideas. Programmers who can&#8217;t be coaxed out of their comfort zone aren&#8217;t going to learn COBOL; but in the long run, they&#8217;ll prove to be less valuable, regardless of what modern language they know.<br></p>\n\n\n\n<p>Second, COBOL programming requires an understanding of business programming. Regardless of the language, that&#8217;s an increasingly rare specialty. How do you handle financial quantities, like dollars and cents? If you say &#8220;floating point,&#8221; go to the back of the class. Roundoff errors will kill you. If you say &#8220;use integers, and divide by 100,&#8221; that&#8217;s not much better. The fundamental problem is that binary numbers are not good at representing decimal fractional values. But that&#8217;s lore that most current programmers have never learned.&nbsp; (And we haven’t even started thinking about currency conversions.)<br></p>\n\n\n\n<p>Third, engineering decisions made in the 1960s, 1970s, and even 1980s aren’t the decisions we’d make today. The engineering was certainly valid for its time, but modern engineers frequently don’t understand why. I&#8217;ve heard many contemporary programmers talk about the Y2K problem (representing years in the 1900s with two digits) as &#8220;technical debt.&#8221; That represents a misunderstanding of the issues the original programmers faced. In an environment when data was entered on 80-column punched cards, saving 2 characters was a Big Deal. In an environment where the largest computers had memories measured in Kilobytes (and a small number of K at that), saving 2 characters was a Big Deal. This isn&#8217;t engineering that has to be replicated, but it does need to be understood.&nbsp;<br></p>\n\n\n\n<p>Fourth, old business software was monolithic—and monolithic in a very deep sense. It tended to model forms that humans would fill out, and that couldn’t be submitted until the form was complete. There&#8217;s often no way to save your work, because—why would you need to? You went to the unemployment office in person; you leave when you hand the application to the person behind the desk. An incomplete form goes into the wastebasket; why waste valuable storage on it? Putting a web interface in front of those monoliths leads to a predictable result: long, complex forms that can take hours to fill out, and that are close to unusable on the modern Web. In creating <a href=\"https://www.codeforamerica.org/news/california-launches-code-for-americas-getcalfresh-in-all-58-counties\">GetCalFresh</a>, a streamlined application for food assistance in California, <a href=\"https://www.codeforamerica.org/\">Code for America</a> found that the old form took an hour to fill out—but applicants often relied on public computers in libraries that didn’t allow sessions longer than a half-hour. Since incomplete forms couldn’t be saved, it was impossible for applicants to finish applying. Moving a COBOL application to an emulator, running it in the cloud, and hacking together a Web frontend isn&#8217;t going to solve problems like this. The good news is that this is an opportunity to re-think your service and make it more effective. The bad news is that it’s not a quick fix.<br></p>\n\n\n\n<p>So, what&#8217;s needed? Yes, we need more people who know and understand COBOL programs. There&#8217;s a lot of old code that needs to be maintained, pure and simple. But it goes deeper. COBOL is just another programming language; if we&#8217;re going to maintain (or replace) that software, we need programmers who understand the engineering decisions that made the software what it is. We also need engineers and managers who are willing to look at our current situation—for example, the huge surge in unemployment applications—and think beyond the short-term solution. What does it take to re-invent current systems, rather than just replace them? How can they become more human-centric? Can they be redesigned to match the way we live and work now? Putting a web front-end on a monolithic business process from the 1950s is the road to failure.<br></p>\n\n\n\n<p>That&#8217;s the new generation of COBOL programmers that we need: people to do the tedious, unglamorous work of re-inventing, re-engineering, and automating government applications, business applications, and much more. Reimagining these processes is creative work, but it requires a different kind of creativity from implementing a new website. I previously wrote about the distinction between <a href=\"https://www.oreilly.com/radar/toward-the-next-generation-of-programming-tools/\">blue- and white-collar programming</a>. COBOL is very, very blue-collar. And very, very important. Every time the cry for COBOL programmers has gone up, we’ve muddled through; this time, we should do something better.<br></p>\n\n\n\n<p>The future of programming is re-understanding the past, and re-inventing it to meet our current challenges.<br></p>\n\n\n\n<div class=\"wp-block-group\"><div class=\"wp-block-group__inner-container\"></div></div>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/qjjGs15OegQ\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 4 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/NLMOWQkWi5U/\n<ol>\n<li><a href=\"http://popcornlinux.org/\">Popcorn Linux</a> &#8212; <i>exploring how to improve the programmability of emerging heterogeneous hardware, in particular, those with Instruction Set Architecture (ISA)-diverse cores, from node-scale (e.g., Xeon/Xeon-Phi, ARM/x86, CPU/GPU/FPGAs) to rack-scale (e.g., Scale-out processors, Firebox, The Machine), in both native and virtualized settings.  Additionally, the project is exploring how to automatically compile/synthesize/execute code on ISA-heterogeneous hardware.</i></li>\n<li><a href=\"https://arxiv.org/pdf/2004.09015.pdf\">Incorporating External Knowledge through Pre-training for Natural Language to Code Generation</a> &#8212; <i> In the second and third example, we can see that the baseline uses the wrong API calls, and sometimes “makes up” APIs on its own (e.g. “random.savefig()”). However, our approach’s outputs, while not perfect, are much more successful at generating correct API calls that actually exist and make sense for the intent.</i> The algorithm developers have made the system guess likely API calls as programmers do.</li>\n<li><a href=\"https://www.theverge.com/2020/4/29/21241251/artificial-intelligence-inventor-united-states-patent-trademark-office-intellectual-property\">US Patent Office Rules that Artificial Intelligence Cannot be a Legal Inventor</a> (Verge) &#8212; <i>“Under current law, only natural persons may be named as an inventor in a patent application,” the agency concluded. <a href=\"https://www.uspto.gov/sites/default/files/documents/16524350_22apr2020.pdf\">The ruling text</a> has the arguments.</i></li>\n<p><i></p>\n<li><a href=\"https://arxiv.org/abs/2004.12330\">Detecting Fake News for the New Coronavirus by Reasoning on the Covid-19 Ontology</a> &#8212; interesting to see symbolic AI (reasoning over propositions) being useful here. <i>In the context of the Covid-19 pandemic, many were quick to spread deceptive information. I investigate here how reasoning in Description Logics (DLs) can detect inconsistencies between trusted medical sources and not trusted ones. The not-trusted information comes in natural language (e.g. &#8220;Covid-19 affects only the elderly&#8221;). To automatically convert into DLs, I used the FRED converter. Reasoning in Description Logics is then performed with the Racer tool.</i></li>\n<p></i></ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/NLMOWQkWi5U\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 1 May 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/td60nlKZt60/\n<ol>\n<li><a href=\"https://github.com/arendst/Tasmota\">Tasmota</a> &#8212; <i>Alternative firmware for ESP8266 with easy configuration using webUI, OTA updates, automation using timers or rules, expandability and entirely local control over MQTT, HTTP, Serial or KNX.</i></li>\n<li><a href=\"https://waifu.lofiu.com/index.html\">Selfie 2 Waifu</a> &#8212; deep learning constructs an anime character from your photo. <a href=\"https://arxiv.org/abs/1907.10830\">Paper for the underlying technique</a>. (via <a href=\"https://twitter.com/tkasasagi\">@tkasasagi</a>)</li>\n<li><a href=\"http://www.wargaming.co/serious/details/handbookcyber.htm\">The Handbook of Cyber Wargames: Wargaming the 21st Century</a> &#8212; <i>Cyber wargaming combines two complex fields:  wargame design and cyber operations.  This handbook is full of examples of such manual games. It includes examples of: Network attack and defence exercises; Committee games; Company and state level games; Example of a Matrix Game; Analysing the cyber security space using Confrontation Analysis; Media Wars: The Battle to Dominate the Information Space; Attack Chain modelling.</i> (via <a href=\"https://twitter.com/SonOfSunTzu/status/1254773545076310016\">Nick Drage</a>)</li>\n<li><a href=\"https://openai.com/blog/jukebox/\">OpenAI Jukebox</a> &#8212; deep learning makes actual music in recognisable styles. There&#8217;s a clever encoding of audio to make it learnable. <i>It takes approximately 9 hours to fully render one minute of audio through our models.</i> Yow.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/td60nlKZt60\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 30 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/-jpqQW9V448/\n<ol>\n<li><a href=\"https://www.infoq.com/news/2020/04/microservices-back-again/\">To Microservices and Back Again: Why Segment Went Back to a Monolith</a> &#8212; <i>microservices came with increased operational overhead and problems around code reuse. &#8230; If microservices are implemented incorrectly or used as a band-aid without addressing some of the root flaws in your system, you&#8217;ll be unable to do new product development because you&#8217;re drowning in the complexity.</i></li>\n<li><a href=\"https://www.gnu.org/software/poke/\">GNU poke</a> &#8212; <i>interactive editor for binary data. Not limited to editing basic entities such as bits and bytes, it provides a full-fledged procedural, interactive programming language designed to describe data structures and to operate on them.</i> (via <a href=\"https://kernel-recipes.org/en/2019/talks/gnu-poke-an-extensible-editor-for-structured-binary-data/\">Kernel Recipes</a>)</li>\n<li><a href=\"https://parl.ai/projects/blender/\">Blender</a> &#8212; Facebook open sourced their open-domain (&#8220;can talk about anything!&#8221;) chatbot. <i>Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements.</i></li>\n<li><a href=\"https://2020.copyleftconf.org/video\">CopyLeft Conf 2020 Videos</a> &#8212; the <a href=\"https://2020.copyleftconf.org/schedule/\">schedule</a> has more info on each talk.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/-jpqQW9V448\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 29 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/TfggNzHCN9Y/\n<ol>\n<li><a href=\"https://podpaperscissors.com/\">podpaperscissors</a> &#8212; <i>From the classic &#8220;prisoner&#8217;s dilemma&#8221; to more obscure coördination games, Pod Paper Scissors takes game theory out of the dry textbook and into the real world. &#8230; Each episode will feature different kinds of games and situations. Experts in a variety of fields will casually converse with the hosts about how the particular game discussed applies to their work. Some episodes feature original music inspired by the topic at hand. The podcast is hosted by game theorist Ben Klemens and science journalist and composer Liz Landau.</i> (via <a href=\"https://twitter.com/b__k/status/1255276222319415300\">Ben Klemens</a>)</li>\n<li><a href=\"https://datajournalism.com/read/handbook/verification-3/\">Verification Handbook (3ed)</a> &#8212; latest guide to <i>investigating disinformation and media manipulation</i>, covering identifying actors, investigating platforms, tracking ads, etc. (via <a href=\"https://twitter.com/CraigSilverman/status/1255106614236979206\">Craig Silverman</a>)</li>\n<li><a href=\"https://www.microsoft.com/security/blog/2020/04/28/ransomware-groups-continue-to-target-healthcare-critical-services-heres-how-to-reduce-risk/\">Ransomware Groups</a> (Microsoft) &#8212; analysis of ransomware campaigns yields this report, which includes a great <a href=\"https://www.microsoft.com/security/blog/wp-content/uploads/2020/04/human-operated-ransomware-payloads-blog-4.png\">graphic taxonomy of ransomware payloads</a>.</li>\n<li><a href=\"http://beza1e1.tuxen.de/lore/index.html\">Bug Stories</a> &#8212; great tales of bugs and bug-hunting from the past.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/TfggNzHCN9Y\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 28 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/JgkxCAvjRqM/\n<ol>\n<li><a href=\"https://www.hillelwayne.com/post/learning-a-language/\">Learning a Language</a> &#8212; this list of questions facing anyone taking a new language for a test run just burns with truth. (Also: encouraging to see how many of these questions are answered by the <a href=\"http://shop.oreilly.com/product/9780596003135.do\">Cookbook format</a>)</li>\n<li><a href=\"https://www.openvas.org/\">OpenVAS</a> &#8212; <i>Open Vulnerability Assessment Scanner</i>, aka &#8220;what a cheap external security assessment vendor will run and then mail you the report from.&#8221;</li>\n<li><a href=\"https://arxiv.org/abs/2004.05074\">Paxos vs Raft: Have we Reached Consensus on Distributed Consensus?</a> &#8212; <i>We find that both Paxos and Raft take a very similar approach to distributed consensus, differing only in their approach to leader election. Most notably, Raft only allows servers with up-to-date logs to become leaders, whereas Paxos allows any server to be leader provided it then updates its log to ensure it is up-to-date. Raft&#8217;s approach is surprisingly efficient given its simplicity as, unlike Paxos, it does not require log entries to be exchanged during leader election. We surmise that much of the understandability of Raft comes from the paper&#8217;s clear presentation rather than being fundamental to the underlying algorithm being presented.</i></li>\n<li><a href=\"https://research-football.dev/\">Google Research Football</a> &#8212; <i>a novel Reinforcement Learning environment where agents aim to master the world’s most popular sport—football. Modeled after popular football video games, it provides a physics based 3D football simulation where agents control either one or all football players on their team, learn how to pass between them, and manage to overcome their opponent’s defense in order to score goals.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/JgkxCAvjRqM\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 27 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/AEEWrXve-nY/\n<ol>\n<li><a href=\"https://thume.ca/2020/04/18/telefork-forking-a-process-onto-a-different-computer/\">Teleforking a Process onto a Different Computer</a> &#8212; a working proof of concept (<i>I just don’t replicate tricky things so that I could keep it simple, meaning it’s just a fun tech demo you probably shouldn’t use for anything real</i>) of a telefork() function call that spawns a process on another machine and returns the instance ID.</li>\n<li><a href=\"https://jepsen.io/consistency\">Consistency Maps</a> &#8212; <i>Jepsen analyses the safety properties of distributed systems–most notably, identifying violations of consistency models. But what are consistency models? What phenomena do they allow? What kind of consistency does a given program really need? In this reference guide, we provide basic definitions, intuitive explanations, and theoretical underpinnings of various consistency models for engineers and academics alike.</i></li>\n<li><a href=\"https://github.com/piranna/wasmachine\">wasmachine</a> &#8212; <i>wasmachine is an implementation of the WebAssembly specification in a FPGA. It follows a sequential 6-steps design.</i></li>\n<li><a href=\"https://www.wired.com/story/opinion-expert-twitter-only-goes-so-far-bring-back-blogs/\">Expert Twitter Only Goes So Far: Bring Back Blogs</a> (Wired) &#8212; we&#8217;re surrounded by opinion machines (because opinion is cheap to produce and make inflammatory, it&#8217;s a natural fit for engagement-driven businesses), so it&#8217;s nice to find knowledgeable people sharing their expertise. I see <a href=\"https://the-syllabus.com/\">The Syllabus</a> and newsletter systems like <a href=\"https://substack.com/\">substack</a> as part of the response to this dearth of high-alpha content. More please!</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/AEEWrXve-nY\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 24 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/iMWXW-TtFNM/\n<ol>\n<li><a href=\"https://www.toptal.com/remote-work-playbook\">The Suddenly Remote Playbook</a> &#8212; I just want to note that if you have to look after kids when you&#8217;re supposed to be working, you&#8217;re not working from home. Not everyone&#8217;s getting a glorious introduction to the delights of working from home.</li>\n<li><a href=\"https://github.com/taichi-dev/taichi\">taichi</a> &#8212; <i>a programming language designed for high-performance computer graphics. It is deeply embedded in Python, and its just-in-time compiler offloads compute-intensive tasks to multi-core CPUs and massively parallel GPUs.</i></li>\n<li><a href=\"https://arxiv.org/abs/2004.08900\">The Cost of Training NLP Models</a> &#8212; <i>We review the cost of training large-scale language models, and the drivers of these costs. The intended audience includes engineers and scientists budgeting their model-training experiments, as well as non-practitioners trying to make sense of the economics of modern-day Natural Language Processing (NLP).</i></li>\n<li><a href=\"https://www.techdirt.com/articles/20200420/08133144330/telecoms-latest-dumb-claim-internet-only-works-during-pandemic-because-we-killed-net-neutrality.shtml\">Killing Net Neutrality Did Not Save the Pandemic Internet</a> &#8212; <i>there&#8217;s no evidence that European networks have fallen apart during the COVID-19 crisis. Or that any differences in performance have anything to do with deregulation or net neutrality. Netflix&#8217;s decision to throttle back its bandwidth usage by 25% was done entirely pro-actively. There was no underlying network data provided by regulators to justify the move. It was just EU regulators being cautious (perhaps overly so). Indeed, similar steps have been taken here in the States. YouTube for example has downgraded video quality to conserve bandwidth. So has game platform Steam, which is slowing some game downloads. You can&#8217;t selectively highlight the EU&#8217;s efforts on this front then ignore the US ones because it supports your flimsy narrative. Well I guess you can, but you should be laughed at.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/iMWXW-TtFNM\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 23 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/Zostx6Dsl7M/\n<p><ol>\n<li><a href=\"https://molo.ch/\">Moloch</a> &#8212; <i>Large scale, open source, indexed packet capture and search.</i></li>\n<li><a href=\"https://github.com/cyrildiagne/instagram-3d-photo\">3Dify Instagram Photos</a> &#8212; open source toolset for adding a 3d effect to photos on Instagram&#8217;s web site. <i>It uses 3d-photo-inpainting running in Colab (free GPU) and Cloud pubsub/storage for communication.</i> A glimpse of the future: we could augment all our apps with deep learning-based services, but we still need to conquer paying for the GPUs and making it easy to use.</li>\n<li><a href=\"https://xkcd.com/2295/\">xkcd 2295</a> &#8212; data science in a nutshell.</li>\n<li><a href=\"https://www.jeremiahlee.com/posts/failed-squad-goals/\">Spotify Doesn’t Use “the Spotify Model” and Neither Should You</a> (Jeremiah Lee) &#8212; <i>I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too.</i> EXTREMELY well-written. Full of killer points like <i>Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.</i></li>\n</ol></p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/Zostx6Dsl7M\" height=\"1\" width=\"1\" alt=\"\"/>\nHow data privacy leader Apple found itself in a data ethics catastrophe\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/zOB3ZaHRzgo/\n<p>Three months ago, Apple released a <a href=\"https://www.cnn.com/2019/11/12/business/apple-card-gender-bias/index.html\">new credit card</a> in partnership with Goldman Sachs that aimed to disrupt the highly regulated world of consumer finance. However, a well-known software developer <a href=\"https://twitter.com/dhh/status/1192540900393705474\">tweeted</a> that he was given 20x the credit line offered to his wife, despite the fact that they have been filing joint tax returns and live in a community property state. The story went viral on Twitter, and led to an official government investigation for bias. </p>\n\n\n\n<p>Even if Apple—the privacy leader—<a href=\"https://www.newsweek.com/apple-card-gender-bias-credit-limit-goldman-sachs-1471146\">did not</a> discriminate on gender, it experienced one of its worst product launches in recent history.&nbsp; </p>\n\n\n\n<p>Apple’s customer base and bankable style combined with Goldman’s knowledge of the financial industry must have seemed like an unbeatable combination. Apple is a great producer of computer hardware, while Goldman knows finance and its complex rules backwards and forwards. If anyone could launch this product right, it would be these two companies.</p>\n\n\n\n<p>Ultimately, Apple learned a critical lesson from this experience. User buy-in cannot end with compliance with rules. It requires ethics, constantly asking <a href=\"https://looker.com/blog/big-data-ethics-privacy\">how to protect, fight for, and empower users</a>, regardless of what the law says. These strategies <a href=\"https://www.pewresearch.org/fact-tank/2019/09/19/americans-perceptions-about-unethical-behavior-shape-how-they-think-about-people-in-powerful-roles/\">contribute</a> to perceptions of trust.</p>\n\n\n\n<p>Trust has to be earned, is easily lost, and is difficult to regain. </p>\n\n\n\n<h2><strong>Compliance and ethics</strong></h2>\n\n\n\n<p>Compliance is a simple concept: “we followed all applicable rules and regulations.” Compliance minimizes the possibility of being fined and gives you a defense if you’re taken to court. You can hire compliance experts to advise you, and lawyers to defend you. That said, compliance allows plenty of room for bad, unethical behavior. For example, payday lending businesses are no doubt compliant with the law, but <a href=\"https://sevenpillarsinstitute.org/payday-lending-an-ethics-evaluation/\">many aren’t</a> models for good corporate citizenship.</p>\n\n\n\n<p>Ethics is much more slippery. It’s not about staying within legal boundaries; ethics is a discussion about what’s right, not a set of rules. It’s about living a “good” life, acting in a way that allows you to live with yourself and others. There aren’t simple standards and tests for ethical behavior, nor are you as likely to be called into court for acting unethically. But unethical behavior is likely to lose your customers’ or business partners’ <a href=\"https://www.pewresearch.org/fact-tank/2019/09/19/americans-perceptions-about-unethical-behavior-shape-how-they-think-about-people-in-powerful-roles/\">trust</a>; they will view your actions with suspicion. </p>\n\n\n\n<h2><strong>The importance of ethics does not, however, mean companies should ignore compliance</strong></h2>\n\n\n\n<p>Compliance functions are powerful because legal violations result in <a href=\"https://www.cnbc.com/2020/01/19/eu-gdpr-privacy-law-led-to-over-100-million-in-fines.html\">clear financial costs</a>. The European Union’s General Data Protection Regulation (GDPR), for instance, imposes fines of up to 2%–4% of global annual revenue. This could mean millions, if not billions, of lost revenue. The era in which fines were merely a cost of doing business appears to be ending. Fines in the billions have been levied against <a href=\"https://www.npr.org/2019/03/20/705106450/eu-fines-google-1-7-billion-over-abusive-online-ad-strategies\">Google</a> and <a href=\"https://www.ftc.gov/news-events/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions\">Facebook</a>, and Practice Fusion (an electronic medical records company) has <a href=\"https://www.justice.gov/opa/pr/electronic-health-records-vendor-pay-145-million-resolve-criminal-and-civil-investigations-0\">agreed</a> to a $145 million settlement for using “its EHR software to influence physician prescribing of opioid pain medications.”</p>\n\n\n\n<p>Because of its clear impact on the bottom line, compliance often reshapes business operations. For instance, financial companies are investing millions into using artificial intelligence to comply with anti-money laundering regulations or stricter data regulations.</p>\n\n\n\n<h2><strong>Because compliance is so clear-cut, it is tempting to substitute compliance for ethics </strong></h2>\n\n\n\n<p>Don’t do it.&nbsp; </p>\n\n\n\n<p>As the Apple case illustrates, rule-following is not sufficient for trust-building. Laws are frequently a minimum standard; they set a low bar. As a privacy leader in the technology space, Apple knows this well and has benefited from a strong reputation as a data steward.</p>\n\n\n\n<p>For one, the law often lags behind technology and user expectations. Organizations that simply follow the rules will be sideswiped by rapidly changing technology and user expectations. Case in point: the public hearings after the outrage over Facebook’s Cambridge Analytica. Here, the public discovered that even highly experienced senators didn’t fully understand <a href=\"https://www.cnet.com/news/some-senators-in-congress-capitol-hill-just-dont-get-facebook-and-mark-zuckerberg/\">key technologies</a>, like Facebook, much less their potential harm on users. </p>\n\n\n\n<p>Furthermore, compliance-only companies will play a seemingly insurmountable game of “<a href=\"https://medium.com/@jeannesheahan/future-proofing-your-privacy-program-5-ways-to-operationalize-a-privacy-and-security-program-c594fd4f34bd\">whack-a-mole</a>” as new data regulations pass around the world. New rules will catch these organizations off-guard, especially when they use <a href=\"https://iapp.org/news/a/why-this-risk-management-best-practice-is-not-fit-for-digital-innovation/\">emerging technologies</a> and face ambiguous rules.</p>\n\n\n\n<p>Finally, investors from <a href=\"https://esgclarity.com/blackstone-launches-impact-platform/\">BlackStone</a> to <a href=\"https://www.jpmorgan.com/commercial-banking/insights/2018-ESG-report-highlights-firms-core-values\">JP Morgan</a> are beginning to prioritize environmental, social, and governance metrics—like ethics—into its definition of shareholder value. Legal compliance is increasingly inadequate for this powerful stakeholder.</p>\n\n\n\n<h2><strong>As a result, to build trust, a company should lead with ethics</strong></h2>\n\n\n\n<p>In our more global, diverse, and rapidly- changing world, ethics may be embodied by the <a href=\"https://www.inc.com/peter-economy/how-the-platinum-rule-trumps-the-golden-rule-every-time.html\">“platinum rule”</a>: Do unto others as they would want done to them. One established field of ethics—bioethics—offers four <a href=\"https://depts.washington.edu/bhdept/ethics-medicine/bioethics-topics/articles/principles-bioethics\">principles</a> that are related to the platinum rule: nonmaleficence, justice, autonomy, and beneficence. </p>\n\n\n\n<p>For organizations that want to be guided by ethics, regardless of what the law says, these principles as essential tools for a <a href=\"https://www.ethicalsystems.org/content/featured-compliance-anti-corruption-and-business-ethics-expert-hui-chen\">purpose-driven</a> mission: protecting (nonmaleficence), fighting for (justice), and empowering users and employees (autonomy and beneficence). </p>\n\n\n\n<p>An ethics leader protects users and workers in its operations by using governance best practices.&nbsp;</p>\n\n\n\n<p>Before creating the product, it understands both the <a href=\"https://www.nature.com/articles/s42256-019-0084-6.epdf?author_access_token=DpKfEINNGpA_AUnRDO27O9RgN0jAjWel9jnR3ZoTv0MVfADFFbYKhRd4tSiZhmMwHoFlOl4yJdWHeFwiv2Bfh3qvaziR1JPvBVZs7NzIFqEB5emJ0YQdBLZ89gFzChJGtqjugP6rC0kOmATFZhB6Bw%3D%3D\">qualitative</a> and quantitative contexts of <a href=\"https://drive.google.com/file/d/1lINZ9xp_ocN4AauyxmniCkIwitwNKXa0/view\">key stakeholders</a>, especially those who will be most impacted, identifying their needs and fears. When creating the product, it uses <a href=\"https://www.complianceweek.com/webcasts/gdpr-is-just-the-beginning-legal-principles-and-tools-to-stay-ahead-of-the-curve/26682.article\">data protection by design</a>, working with cross-functional roles like <a href=\"https://www.fastcompany.com/90372705/dont-call-me-a-lawyer-i-am-a-legal-engineer\">legal and privacy engineers</a> to embed ethical principles into the <a href=\"https://iapp.org/news/a/why-this-risk-management-best-practice-is-not-fit-for-digital-innovation/\">lifecycle</a> of the product and formalize data-sharing agreements. Before launching, it audits the product thoroughly and conducts scenario planning to understand potential ethical mishaps, such as perceived or real gender bias or <a href=\"https://money.cnn.com/2016/08/24/technology/apple-tim-cook-five-years/\">human rights violations in its supply chain</a>. After launching, its terms of service and <a href=\"https://www.projectsbyif.com/\">collection methods</a> are highly <a href=\"https://drive.google.com/open?id=1lINZ9xp_ocN4AauyxmniCkIwitwNKXa0\">readable</a> and enables even disaffected users to <a href=\"https://www.jonesday.com/en/insights/2019/06/proposed-algorithmic-accountability-act\">resolve issues</a> delightfully. </p>\n\n\n\n<p>Ethics leaders <a href=\"https://www.politico.com/news/2020/01/14/apple-rebukes-doj-over-pensacola-iphone-encryption-battle-098684\">also fight for</a> users and workers, who can be forgotten. These leaders may <a href=\"https://looker.com/blog/big-data-ethics-privacy\">champion</a> enforceable consumer protections <a href=\"https://openai.com/blog/cooperation-on-safety/\">in the first place</a>, before a crisis erupts. With social movements, leaders fight powerful actors preying on vulnerable communities or <a href=\"https://www.nytimes.com/2018/05/05/business/patagonia-trump-bears-ears.html\">the public at large</a>—and critically examines and ameliorates its own participation in systemic violence. As a result, instead of last-minute heroic efforts to change compromised operations, it’s been iterating all along. </p>\n\n\n\n<p>Finally, ethics leaders empower their users and workers. With diverse communities and employees, they co-create new products that help improve basic needs and enable more, including the vulnerable, to increase their autonomy and their economic mobility. These entrepreneurial efforts validate <a href=\"https://www.forbes.com/sites/amberjohnson-jimludema/2018/08/15/six-csr-strategies-that-are-good-for-business/#ec8a56a50a89\">new revenue streams</a> and relationships while <a href=\"https://knowledge.wharton.upenn.edu/article/from-soup-to-corporate-social-responsibility-campbells-efforts-to-lead-the-way/\">incubating</a> next-generation workers who <a href=\"https://webcache.googleusercontent.com/search?q=cache:s8TxbY9lQUQJ:https://www.forbes.com/sites/carstentams/2018/06/18/and-now-ethics-2-0-an-argument-for-more-self-governance/+&amp;cd=21&amp;hl=en&amp;ct=clnk&amp;gl=us\">self-govern</a> and push the company’s mission forward. Employees <a href=\"https://www.darden.virginia.edu/ibis/initiatives/giving-voice-to-values/\">voice their values</a> and diversify their relationships. Alison Taylor, the Executive Director of <a href=\"https://www.ethicalsystems.org/\">Ethical Systems</a>, argues that internal processes should “improve [workers’] reasoning and creativity, instead of short-circuiting them.” Enabling this is a culture of <a href=\"https://psycnet.apa.org/record/2009-12532-011\">psychological safety</a> and <a href=\"https://hbr.org/2017/06/changing-company-culture-requires-a-movement-not-a-mandate\">training</a> to engage kindly with <a href=\"https://hbr.org/2019/11/the-ethical-dilemma-at-the-heart-of-big-tech-companies\">divergent ideas</a>.</p>\n\n\n\n<p>These purpose-led strategies boost employee <a href=\"https://scholarship.sha.cornell.edu/cgi/viewcontent.cgi?article=1762&amp;context=articles\">performance</a> and <a href=\"https://www.forbes.com/sites/williamcraig/2018/05/15/the-importance-of-having-a-mission-driven-company/\">retention</a>, drive deep <a href=\"https://www.adweek.com/digital/how-these-3-brands-are-taking-loyalty-beyond-points/\">customer loyalty</a>, and carve legacies. </p>\n\n\n\n<p>To be clear, Apple may be implementing at least some of these strategies already—but perhaps not uniformly or transparently. For instance, Apple has implemented some provisions of the European Union’s <a href=\"https://www.forbes.com/sites/davidphelan/2018/05/26/apple-demonstrates-privacy-by-design-to-benefit-iphone-ipad-and-mac-users-worldwide/#2f0c716e739c\">General Data Protection Regulation</a> for <a href=\"https://www.zdnet.com/article/apple-to-us-users-heres-how-you-can-now-see-what-personal-data-we-hold-on-you/\">all US residents</a>—not just EU and CA residents—including the ability to access and edit data. This expensive move, which goes beyond strict legal requirements, was implemented even without public pressure. </p>\n\n\n\n<h2><strong>But ethics strategies have major limitations leaders must address</strong></h2>\n\n\n\n<p>As demonstrated by the waves of ethical “<a href=\"https://www.aies-conference.com/2020/wp-content/papers/030.pdf\">principles</a>” released by <a href=\"https://www.bloomberg.com/company/press/bloomberg-brighthive-data-democracy-launch-initiative-develop-data-science-code-ethics/\">Fortune 500 companies</a> and <a href=\"http://depts.washington.edu/bhdept/node/242\">commissions</a>, ethics programs can be murky, <a href=\"https://www.manifestno.com/\">dominated</a> by a <a href=\"https://ainowinstitute.org/AI_Now_2019_Report.pdf\">white, male, and Western</a> interpretation. </p>\n\n\n\n<p>Furthermore, focusing purely on ethics gives companies an easy way to “free ride” off social goodwill, but ultimately stay <a href=\"https://ainowinstitute.org/AI_Now_2019_Report.pdf\">unaccountable</a>, given the lack of external oversight over ethics programs. When companies substitute <em>unaccountable</em> data ethics principles for thoughtful engagement with the <em>enforceable</em> data regulation principles, users will be harmed.</p>\n\n\n\n<p>Long-term, without the ability to wave a $100 million fine with clear-cut requirements and lawyers trained to advocate for them internally, ethics leaders may face barriers to buy-in. Unlike their sales, marketing, or compliance counterparts, ethics programs do not directly add revenue or reduce costs. In recessions, these “soft” programs may be the first on the chopping block. </p>\n\n\n\n<p>As a result of these factors, we will likely see a surge in <a href=\"https://hbr.org/2019/11/the-ethical-dilemma-at-the-heart-of-big-tech-companies\">ethics-washing</a>: well-intentioned companies that talk ethics, but don’t walk it. More will view these efforts as PR-driven ethics stunts, which don’t deeply engage with actual ethical issues. If harmful business models do not change, ethics leaders will be fighting a losing battle. </p>\n\n\n\n<h2><strong>Yet despite these tremendous barriers, leaders must weave ethics into their strategies</strong></h2>\n\n\n\n<p>Ethics must be embraced by top leaders, who must fundamentally shift <a href=\"https://benefitcorp.net/faq\">corporate governance</a>, <a href=\"https://www.nytimes.com/2019/10/14/opinion/benioff-salesforce-capitalism.html\">C-suite incentives</a>, <a href=\"http://bit.ly/TCDataEthicsPost\">strategic roadmaps</a>, and <a href=\"https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/accountability-and-governance/data-protection-by-design-and-default/\">daily operations</a> to empower stakeholders. Inconsistent or wishy-washy company behavior will severely harm, not build, trust.</p>\n\n\n\n<p>To move beyond narrow interpretations of ethics, ethical leaders must engage with critiques—like the <a href=\"https://www.manifestno.com/\">Feminist Data Manifest-no</a>. These push leaders to investigate and ameliorate <a href=\"https://venturebeat.com/2019/11/11/ai-ethics-is-all-about-power/\">power relations</a>, marginalizing processes, and the history of injustice against vulnerable communities. </p>\n\n\n\n<p>Similarly, leaders must engage with international human rights frameworks (IHRFs), such as the Universal Declaration of Human Rights and International Covenant on Economic, Social and Cultural Rights. While these have often been enforced <a href=\"https://ainowinstitute.org/AI_Now_2019_Report.pdf\">against states</a> (fighting, <a href=\"https://www.humanrights.com/what-are-human-rights/violations-of-human-rights/\">for instance</a>, censorship, unfair trials, and torture), supporters nonetheless argue IHRFs afford a rich ecosystem of multilateral organizations, compliance <a href=\"https://www.ohchr.org/documents/publications/guidingprinciplesbusinesshr_en.pdf\">approaches</a>, shared <a href=\"https://points.datasociety.net/the-advantages-and-limitations-of-applying-the-international-human-rights-framework-to-artificial-291a2dfe1d8a\">language</a>, and jurisprudence to help organizations balance human rights against <a href=\"https://www.openglobalrights.org/why-do-emerging-ai-guidelines-emphasize-ethics-over-human-rights/\">competing interests</a>, like innovation. </p>\n\n\n\n<p>To gain more buy-in from <a href=\"https://knowledge.wharton.upenn.edu/article/from-soup-to-corporate-social-responsibility-campbells-efforts-to-lead-the-way/\">top internal business leaders</a>, ethics leaders can form coalitions with <a href=\"https://www.ethicalsystems.org/content/featured-compliance-anti-corruption-and-business-ethics-expert-hui-chen\">compliance</a>, data, and even marketing departments. By leading programs with resources and measurable accountability, ethics leaders must articulate how ethics improves <a href=\"http://bit.ly/TCDataEthicsPost\">trust and loyalty</a>. The <a href=\"https://www.linkedin.com/posts/wu12345_culture-strategy-trust-activity-6595422881205764096-59FG\">effectiveness</a> of such coalitions may explain the rise of chief ethics <em>and</em> compliance officers— as well as a host of new <em>chief</em> trust, social responsibility, citizenship, and data officers by technology leaders like Salesforce, Workday, and Unisys. Robert Smith, Director of Ethics and Compliance at InterContinental Hotels Group, <a href=\"https://buildingbusinessethics.wordpress.com/2020/04/07/what-should-an-effective-business-ethics-function-look-like/\">agrees</a>, arguing that these related teams should speak with “one voice.” </p>\n\n\n\n<p>To further bolster support, leaders should consider participating and learning from new cross-sector coalitions. These include those focused (a) on specific technologies like AI, such as <a href=\"https://www.partnershiponai.org/\">The Partnership on AI,</a> (b) on specific industries, such as health (<a href=\"http://dashconnect.org/all-in-data-for-community-health/\">All-in</a>), government (Civic Data Privacy Leaders Network), and cities (Cities Coalition for Digital Rights or the Right to the City Alliance); or (c) on a general set of emerging issues, such as IEEE, WEF, Metrolab, or Data Collaboratives Research Network. Due to the wide variety of community, academic, and nonprofit leaders, these coalitions also provide invaluable opportunities for leaders to diversify their networks and challenge their assumptions. </p>\n\n\n\n<p>While incorporating human rights and ethics into business strategies may be costly in the short run, over the long term, Paul Barrett, deputy director of New York University’s Center for Business and Human Rights, argues that “companies will benefit financially from operating humane, efficient supply chains and employing motivated workers proud of their jobs.&#8221;</p>\n\n\n\n<p>Ultimately, organizations that discard ethics may find themselves on the wrong side of history. They risk becoming the <a href=\"https://en.wikipedia.org/wiki/Redlining\">redlining</a> banks that excluded communities of color from loans due to perceived financial risk, or the <a href=\"https://en.wikipedia.org/wiki/Tuskegee_syphilis_experiment\">government agency</a> that denied treatment to African Americans suffering from syphilis due to a desire to for innovative research, or the billion-dollar company whose planes killed 346 people, after placing “<a href=\"https://www.cnbc.com/2019/10/20/boeing-survey-shows-safety-workers-felt-pressure-from-managers-report.html\">undue</a>” pressure for safety approvals of new algorithms to <a href=\"https://www.wbur.org/cognoscenti/2019/03/27/boeing-crash-algorithm-h-c-robinson\">improve take-off performance</a>. </p>\n\n\n\n<p>In the next decade, leaders—from Apple to the next venture-financed startup— will use cutting-edge technologies in a fight for competitive advantage and better operations. But those that succeed in our history books <a href=\"https://www.bcg.com/publications/2018/winning-the-20s-leadership-agenda-for-next-decade.aspx\">protect, fight for, and empower their users</a>, including the most vulnerable.</p>\n\n\n\n<p>Leaders must not give up.</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/zOB3ZaHRzgo\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 22 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/8fB4w7v--aI/\n<ol><li><a href=\"https://posthog.com/\">Posthog</a> — <em>open source product analytics.</em><br></li><li> <a href=\"https://www.recurse.com/still-computing/issue-4\">Into the Mainframe</a> (Recurse) — the interviews with two mainframe programmers are a great reminder of how much things have changed. And how they haven&#8217;t. <em>For instance, later in my career I kept a weighted punching clown in my office. As programmers, we liked our users, but we also sort of hated them. They would make all these unreasonable requests, give us bad data, stuff like that. So all my staff could come by my office when they were mad at their users and punch the clown to feel better. It was fun. I had two doors in my office, and one time some guy I&#8217;d never seen before in my life walked into my office without knocking, punched the clown, and walked out the other door. Never saw him again.</em><br></li><li><a href=\"https://ccl.northwestern.edu/netlogo/\">NetLogo</a> — <em>a multi-agent programmable modeling environment.</em> For simulations/modeling.<br></li><li><a href=\"https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78\">Things I Wished More Developers Knew About Databases</a> (Jaana B. Dogan) — really good points, hard won from experience. <em>You are lucky if 99.999% of the time network is not a problem.</em></li></ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/8fB4w7v--aI\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 21 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/LdaybsWcIt8/\n<ol>\n<li><a href=\"https://scottberkun.com/2020/its-time-to-learn/\">It&#8217;s Time to Learn</a> (Scott Berkun) &#8212; a strong response to Marc Andreessen&#8217;s <a href=\"https://a16z.com/2020/04/18/its-time-to-build/\">It&#8217;s Time to Build</a>. It feels like we are in a disrupted time when anything is possible, and folks are wondering where the levers are to pull.</li>\n<li><a href=\"https://github.com/graphistry/pygraphistry\">pygraphistry</a> &#8212; <i>a library to extract, transform, and visually explore big graphs.</i></li>\n<li><a href=\"https://desertedislanddevops.com/about/\">Desert Island Devops</a> &#8212; <i>a single-day virtual event, to be livestreamed on twitch.tv/oncallmemaybe on April 30th, 2020. All presentations will take place in the world of Animal Crossing: New Horizons.</i></li>\n<li><a href=\"https://www.microsoft.com/security/blog/2020/04/16/secure-software-development-lifecycle-machine-learning/\">MSFT&#8217;s Machine Learning-Powered Bug Sorting</a> &#8212; <i>Since 2001 Microsoft has collected 13 million work items and bugs. We used that data to develop a process and machine learning model that correctly distinguishes between security and non-security bugs 99 percent of the time and accurately identifies the critical, high priority security bugs, 97 percent of the time. This is an overview of how we did it.</i> Part of the ongoing augmentation of developers by (ML-powered) software.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/LdaybsWcIt8\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 20 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/mi6oOgCeVnY/\n<ol>\n<li><a href=\"http://castledb.org/\">CastleDB</a> &#8212; <i>a structured static database [&#8230;]. CastleDB looks like any spreadsheet editor, except that each sheet has a data model. [&#8230;] stores both its data model and the data contained in the rows into an easily readable JSON file. [&#8230;] allows efficient collaboration on data editing.</i></li>\n<li><a href=\"https://spectrum.ieee.org/tech-talk/computing/software/mainframes-programming-language-cobol-news-coronavirus\">Mainframes Are Having a Moment</a> (IEEE Spectrum) &#8212; <i>Although many college and university computer science departments have cut back or dropped mainframe programming curriculum to focus on more modern languages and technologies, faculty and staff at others report an uptick in interest in Cobol and related classes. The increase began well before pandemic-related layoffs inundated state unemployment agency computer systems, causing government officials to put out the call for programmers who know Cobol to step in and help.</i></li>\n<li><a href=\"https://github.com/swimos/swim\">swimOS</a> &#8212; <i>a complete, self-contained distributed software platform for building stateful, massively real-time streaming applications. swimOS implements a distributed microkernel, called the Swim Kernel, that is persistent without a database, reactive without a message broker, autonomous without a job manager, and which executes general purpose stateful applications without a separate app server.</i></li>\n<li><a href=\"https://simonwillison.net/2020/Apr/20/self-rewriting-readme/\">Using a Self-Rewriting README Powered by GitHub Actions to Track TILs</a> (Simon Willison) &#8212; writing down what you&#8217;ve learned how to do keeps it fresh. I&#8217;ve been doing it for years, as have other people &#8212; check out <a href=\"https://github.com/jbranchaud/til\">this person&#8217;s astonishing collection</a>.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/mi6oOgCeVnY\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 17 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/3qVGYfUcjio/\n<ol>\n<li><a href=\"https://nebula-graph.io/en/\">Nebula</a> &#8212;<a href=\"https://nebula-graph.io/en/\">open source</a> <i>distributed, scalable, lightning-fast graph database.</i></li>\n<p><i></p>\n<li><a href=\"https://github.com/openmainframeproject/cobol-programming-course\">COBOL Programming Course</a> &#8212; from the Open Mainframe Project.</li>\n<li><a href=\"https://serverlesshandbook.dev/\">Serverless Handbook</a> &#8212; <i>a resource teaching frontend engineers everything they need to know to dive into backend.</i></li>\n<li><a href=\"https://spectrum.ieee.org/tech-talk/computing/hardware/japanese-researchers-develop-a-novel-annealing-processor-thats-the-fastest-technology-yet-at-solving-combinatorial-optimization-problems\">Novel Annealing Processor Is the Best Ever at Solving Combinatorial Optimization Problems</a> (IEEE Spectrum) &#8212; <i>Dubbed STATICA (Stochastic Cellular Automata Annealer Architecture), the processor is designed to take on challenges such as portfolio, logistic, and traffic flow optimization when they are expressed in the form of Ising models.</i></li>\n<p></i></ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/3qVGYfUcjio\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 16 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/U0I-RtlD5PE/\n<ol>\n<li><a href=\"https://kanboard.org/\">Kanboard</a> &#8212; free and open source Trello-like Kanban boards.</li>\n<li><a href=\"https://www.estherolatunde.com/posts/17-remote-work-playbook/\">Remote Work Playbook</a> &#8212; really useful advice on the actual mechanics of working remotely, not just which tools to use but how to use them. E.g., <i>As an individual contributor, is there something you just did that you think a colleague would have to do at some point in the future, would this have been easier and faster if you had a document to consult? If your answer to both questions is yes, write documentation for the thing and store in a common place where your team can access. Notion is a great place to store this. You should also share the link in your instant communication channel so your colleagues are aware.</i></li>\n<li><a href=\"https://github.com/alievk/avatarify\">avatarify</a> &#8212; deep fake technology used to give you avatars of your choice for use in Zoom and Skype.</li>\n<li><a href=\"https://github.com/Percona-QA/pstress.git\">pstress</a> &#8212; <i>Database concurrency and crash recovery testing tool.</i> (via <a href=\"https://www.percona.com/blog/2020/04/15/pstress-database-concurrency-and-crash-recovery-testing-tool/\">Percona blog</a>)</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/U0I-RtlD5PE\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 15 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/ZfAUNw01nEU/\n<ol>\n<li><a href=\"https://daringfireball.net/2020/04/cobol_programming_coding\">Coding vs Programming</a> (John Gruber) &#8212; I&#8217;d noticed this linguistic change too. See also Engineering vs Programming vs Computer Science. Coding is shorter so it&#8217;s probably gaining in popularity because shorter is easier to say and thus more convenient.</li>\n<li><a href=\"https://github.com/karpathy/micrograd\">micrograd</a> (Andre Karpathy) &#8212; <i>A tiny Autograd engine (with a bite! :D). Implements backpropagation (reverse-mode autodiff) over a dynamically built DAG and a small neural networks library on top of it with a PyTorch-like API. Both are currently about 50 lines of code each.</i></li>\n<li><a href=\"https://github.com/EngineOwningSoftware/pcileech-webradar/blob/master/readme.md\">Game Cheating in Hardware</a> &#8212; <i>pcileech WebRadar is a browser based radar cheat for CS:GO that can be run on a different PC, connected to a PCIe card providing direct memory access to the target computer</i>. It&#8217;s like doping for e-sports. (via <a href=\"https://twitter.com/lukeweston/status/1249901037160284161\">Luke Weston</a>)</li>\n<li><a href=\"https://www.oreilly.com/radar/radar-trends-to-watch-april-2020/\">Radar Trends to Watch: April 2020</a> &#8212; early weak signals of interesting developments in <i>Ops &amp; Infrastructure, Software Development, AI &amp; ML, and Quantum Computing.</i> Plus the unavoidable Coronavirus-driven changes.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/ZfAUNw01nEU\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 14 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/K0z1jG0Q_GA/\n<ol>\n<li><a href=\"https://www.edx.org/course/the-science-of-happiness-3\">The Science of Happiness</a> &#8212; free enrolment in Berkeley&#8217;s <i>MOOC to teach positive psychology. Learn science-based principles and practices for a happy, meaningful life.</i></li>\n<li><a href=\"https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/\">The New Business of AI</a> (A16Z) &#8212; <i>many AI companies have: Lower gross margins due to heavy cloud infrastructure usage and ongoing human support; Scaling challenges due to the thorny problem of edge cases; Weaker defensive moats due to the commoditization of AI models and challenges with data network effects.</i></li>\n<li><a href=\"https://basecamp.com/guides/group-chat-problems\">Group Chat: The Best Way to Totally Stress Out Your Team</a> &#8212; <i>Group chat is like being in an all-day meeting, with random participants, and no agenda.</i></li>\n<li><a href=\"https://www.reddit.com/r/DataHoarder/comments/fplzki/human_standards_help_share_the_international/\">Human Standards Project</a> &#8212; p2p-shared international and device manufacturer standards to assist diy ventilator and masks teams.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/K0z1jG0Q_GA\" height=\"1\" width=\"1\" alt=\"\"/>\nRadar trends to watch: April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/D3WiTNUnfCI/\n<p>Since early in March, technology news has been all Coronavirus, all the time. That’s a trend we expect to continue through April and probably beyond. So let’s start with Coronavirus news, and hope that we have something different for next month.</p>\n\n\n\n<h2>Coronavirus</h2>\n\n\n\n<ul><li>The Coronavirus pandemic is forcing reconsideration of <a href=\"https://www.technologyreview.com/s/615396/coronavirus-is-forcing-a-trade-off-between-privacy-and-public-health/\">how private data is used</a>.&nbsp; Maciej Ceglowski’s post “<a href=\"https://idlewords.com/2020/03/we_need_a_massive_surveillance_program.htm\">We need A Massive Surveillance Program</a>” is important, particularly since Maciej has a long history as a privacy advocate. At the same time, many other privacy advocates are saying, “Be careful what you give up, because you won’t get it back,” including <a href=\"https://www.businessinsider.com/edward-snowden-coronavirus-surveillance-new-powers-2020-3\">Edward Snowden</a>.</li><li>A number of organizations are using blockchains as a way of <a href=\"https://www.acoer.com/coronavirus\">sharing</a> <a href=\"https://www.scmp.com/print/business/companies/article/3049479/insurance-service-providers-rely-blockchain-fast-track-claims\">coronavirus</a> <a href=\"https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6\">data</a>. I don’t think this will be the blockchain killer app (it’s too specialized), but it might be the killer demo.&nbsp;</li><li>While the maker movement of a decade ago has died back, it’s worth  noting that the coronavirus has spawned a lot of maker projects—from <a href=\"https://mathbabe.org/2020/04/02/making-facemasks-a-step-by-step-guide/\">facemasks</a> to <a href=\"https://www.medicaldesignandoutsourcing.com/diy-ventilator-projects-that-could-save-coronavirus-patients-lives/\">ventilators</a>, and many things in between.&nbsp;</li><li><a href=\"https://www.technologyreview.com/s/615367/coronavirus-24000-research-papers-available-open-data/\">24,000 Coronavirus research papers in one archive</a>: Now the question is how researchers will use this archive effectively. There’s really only one answer: <a href=\"https://primer.ai/\">automatic summarization</a> and intelligent search using AI.&nbsp;</li><li>Apple has made biometrics on watches an essential feature. Other companies with smart watch products will be forced to follow–especially since doctors are now replacing in-office visits with telemedicine. A lot of cultural change is needed before doctors will accept ambient data detection, but Coronavirus may force that change to happen.</li></ul>\n\n\n\n<h2>Operations and Infrastructure</h2>\n\n\n\n<ul><li>Rolling updates for Kubernetes with <a href=\"https://thenewstack.io/kublr-brings-rolling-updates-to-kubernetes/\">Kublr</a>: Rolling updates are an essential feature for groups that are practicing continuous deployment. There have been some hackish workarounds, but Kublr attempts to provide a real solution.</li><li>AWS has a Linux-based <a href=\"https://aws.amazon.com/bottlerocket/\">operating system</a> for containers called Bottlerocket. Bottlerocket’s most important feature is that it streamlines the update process, making updating possible for container orchestrators.</li><li>Monitoring production systems is an essential practice. <a href=\"https://github.com/m3db\">m3</a> is an open source monitoring tool from Uber that is effective at huge scale. It is being commercialized by <a href=\"https://chronosphere.io/\">Chronosphere</a>.</li></ul>\n\n\n\n<h2>Software Development</h2>\n\n\n\n<ul><li><a href=\"https://thenewstack.io/github-acquires-npm-buying-microsoft-a-presence-in-the-node-javascript-community/\">Microsoft buys npm</a>: This certainly isn’t Steve Ballmer’s Microsoft. And, along with Microsoft’s acquisition of GitHub, it makes Microsoft a dominant player in much of the open source movement.&nbsp;</li><li>Chrome has new <a href=\"https://thenextweb.com/dd/2020/03/12/google-chromes-can-now-show-devs-how-their-sites-look-to-users-with-visual-impairments/\">tools</a> to help develop for the visually impaired; they simulate what the page would look like with different vision problems. This is an important step forward for developers working on accessibility. Mozilla also has accessibility checking.</li></ul>\n\n\n\n<h2>Artificial Intelligence and Machine Learning</h2>\n\n\n\n<ul><li>Realtime transcription and translation with Google <a href=\"https://www.blog.google/products/translate/transcribe-speech/\">Translate</a>: This feature is rolling out to Android now, and will be delivered to iOS later. There are lots of issues that they will have to think about—for example, there are significant variations in Spanish from country to country—but it’s an impressive accomplishment for natural language technology.&nbsp;</li><li>We’ve known for some time that AI-based image classification can be tricked. Researchers have shown that it is also possible to spoof <a href=\"https://techxplore.com/news/2020-03-autonomous-vehicles-nonexistent-obstacles.html\">LIDAR</a>, which could have a big effect on the development of autonomous vehicles.&nbsp;</li><li><a href=\"https://towardsdatascience.com/a-dataset-is-a-worldview-5328216dd44d\">A data set is a world view</a>. This isn’t a new idea, but it’s important. A must-read article.</li><li>Facebook has developed a new system called <a href=\"https://www.technologyreview.com/s/615313/how-facebook-uses-machine-learning-to-detect-fake-accounts/\">Deep Entity Classification</a> for detecting fake accounts. It’s based on connection patterns between users and also seems to take advantage of machine-generated labeling.&nbsp;&nbsp;</li></ul>\n\n\n\n<h2>Quantum Computing</h2>\n\n\n\n<ul><li><a href=\"https://ai.googleblog.com/2020/03/announcing-tensorflow-quantum-open.html\">TensorFlow Quantum</a> integrates quantum computing into TensorFlow to jump-start research into machine learning on quantum computers. While TensorFlow does not directly support quantum computing, this makes it a tool for  simulations and prepares the way for supporting real quantum computers.</li><li>Honeywell hasn’t been part of the quantum computing picture so far, but at the beginning of March, it suddenly announced that it had built a <a href=\"https://www.technologyreview.com/f/615309/industrial-giant-honeywell-says-its-built-the-worlds-best-quantum-computer/\">quantum computer</a>. They’re claiming it will be twice as powerful as IBM’s machine.</li></ul>\n\n\n\n<h2>Other</h2>\n\n\n\n<ul><li>There is legislation in the US Senate that would have the effect of <a href=\"https://techxplore.com/news/2020-03-bill-online-child-abuse-encryption.html\">restricting encryption</a>. While this is framed as a bill to combat child sexual abuse, it would have drastic effects on computer security of all kinds.</li></ul>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/D3WiTNUnfCI\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 13 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/P6lgHjTBq-c/\n<ol>\n<li><a href=\"http://www.csis.ul.ie/cobol/course/Default.htm\">Introduction to COBOL</a> &#8212; a 1999 web site (!) with slides from a University of Limerick course. <a href=\"https://www.inputmag.com/tech/ibm-will-offer-free-cobol-training-to-address-overloaded-unemployment-systems\">IBM will offer</a> free (presumably more modern) training.</li>\n<li><a href=\"https://github.com/mcreed/zoombot\">zoombot</a> &#8212; <i>a highly advanced AI to handle Zoom calls.</i></li>\n<li><a href=\"https://storybook.js.org/\">storybook.js</a> &#8212; open source toolkit and <i>sandbox to build UI components in isolation so you can develop hard-to-reach states and edge cases.</i></li>\n<li><a href=\"https://tic.computer/\">tic-80</a> &#8212; <i>a fantasy computer for making, playing and sharing tiny games.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/P6lgHjTBq-c\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 10 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/Wo1OI-hrJWc/\n<ol>\n<li><a href=\"https://github.com/ifzhang/FairMOT\">FairMOT</a> &#8212; <i>one-shot multi-object tracking</i> that <i>remarkably outperforms the state-of-the-arts on the MOT challenge datasets at 30 FPS</i>.</li>\n<li><a href=\"https://pipedream.com/\">pipedream</a> &#8212; IFTTT for coders.</li>\n<li><a href=\"https://godbolt.org/\">Compiler Explorer</a> &#8212; <i>an interactive tool that lets you type code in one window and see the results of its compilation in another window. Using the site should be pretty self-explanatory: by default the left hand pane is the source window and the right hand has the assembly output.</i> (via <a href=\"https://twitter.com/iondiode/status/1247604710208499712\">Tim Westbrook</a>)</li>\n<li><a href=\"https://manytricks.com/moom/\">MOOM</a> &#8212; <i>move and zoom windows</i> on a Mac. See also <a href=\"https://magnet.crowdcafe.com/\">Magnet</a>. (via <a href=\"https://twitter.com/nzben/status/1247467602537897985\">Ben Gracewood</a> and <a href=\"https://twitter.com/kylehqcom/status/1247517621651746817\">@kylehqcom</a>)</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/Wo1OI-hrJWc\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 9 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/JziWImi0zFw/\n<ol>\n<li><a href=\"http://ifyoulived.org/fuzzy/\">The Fuzzy Edges of Character Encoding</a> &#8212; <i>the history, politics, and computational basics of text-based character encoding and digital representations of text, from Morse Code to ASCII to Unicode (and emoji), as well as alternative text encoding schemes.</i> (via <a href=\"https://twitter.com/everestpipkin/status/1247187636214784003\">Everest Pipkin</a>)</li>\n<li><a href=\"https://www.autohotkey.com/\">AutoHotkey</a> &#8212; an <i>automation scripting language for Windows</i>.</li>\n<li><a href=\"https://doi.org/10.1007/s11633-019-1212-9\">The Electronic Nose and its Applications: A Survey</a> &#8212; very good summary of tech, limitations, and applications of &#8220;electronic noses&#8221; aka multiple chemical sensors plus some machine learning/statistics.</li>\n<li><a href=\"https://gitlab.com/edouardklein/falsisign\">falsisign</a> &#8212; <i>Make it look like a PDF has been hand signed and scanned</i>.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/JziWImi0zFw\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 8 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/V8u8aZ2VPaE/\n<ol>\n<li><a href=\"https://robertheaton.com/2020/04/06/systems-design-for-advanced-beginners/\">System Design for Advanced Beginners</a> &#8212; a friendly explanation of the what and why of systems, with acknowledgement of the real world like <i>There are many tools out there, each with different strengths and weaknesses, and many ways to build a technology company. The real, honest reasons that we will make many of our technological choices will be “we chose X because Sara knows a lot about X” and “we chose Y on the spur of the moment when it didn’t seem like a big decision and we never found the time to re-evaluate.”</i></li>\n<li><a href=\"https://meet.primrosevr.com/\">Lozya</a> &#8212; <i>Teleconferencing with an RPG map. Walk around, talk to folks, have private conversations by huddling in a corner, or drop in on other conversations. Ideal for meetups!</i></li>\n<li><a href=\"https://www.hammerspoon.org/\">Hammerspoon</a> &#8212; <i>desktop automation framework for macOS. It lets you write Lua scripts that hook into operating system functionality, allowing you to interact with the keyboard/mouse, windows, displays, filesystem, and much more.</i> (via <a href=\"https://missing.csail.mit.edu/2020/potpourri/\">CSAIL&#8217;s Missing Semester Potpourri</a>)</li>\n<li><a href=\"https://github.com/blanchette/logical_verification_2020/raw/master/hitchhikers_guide.pdf\">The Hitchiker&#8217;s Guide to Logical Verification</a> (PDF) &#8212; book for <a href=\"https://lean-forward.github.io/logical-verification/2020/\">a course</a>, using Microsoft Research&#8217;s <a href=\"https://leanprover.github.io/\">Lean</a> theorem prover.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/V8u8aZ2VPaE\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 7 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/bh3WKpMqNYY/\n<ol>\n<li><a href=\"https://locust.io/\">locust</a> &#8212; <i>open source load testing tool: define user behaviour with Python code, and swarm your system with millions of simultaneous users. (via <a href=\"https://twitter.com/nzigel/status/1247430768927715328\">@nzigel</a>)</i></li>\n<li><a href=\"http://grail.cs.washington.edu/projects/background-matting/\">Background Matting</a> &#8212; <i>a method for creating a matte – the per-pixel foreground color and alpha – of a person by taking photos or videos in an everyday setting with a handheld camera. Most existing matting methods require a green screen background or a manually created trimap to produce a good matte.</i> With source.</li>\n<li><a href=\"https://www.cmlab.csie.ntu.edu.tw/~yulunliu/ObstructionRemoval\">Learning to See Through Obstructions</a> &#8212; <i>a learning-based approach for removing unwanted obstructions, such as window reflections, fence occlusions or raindrops, from a short sequence of images captured by a moving camera.</i></li>\n<li><a href=\"https://covid19primer.com/\">Covid-19 Primer</a> &#8212; algorithmic summaries of Covid-19 research, updated every 24h. (via <a href=\"https://twitter.com/sgourley/status/1247345646899613697\">Sean Gourley</a>)</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/bh3WKpMqNYY\" height=\"1\" width=\"1\" alt=\"\"/>\nGovernance and Discovery\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/bDh1ARjfuqw/\n<p><em>Data Governance</em> sounds like a candidate for the most boring topic in technology: something dreamed up by middle-managers to add friction to data scientists&#8217; lives. The funny thing about governance, though, is that it’s closely related to data discovery. And data discovery is neither dull nor additional friction; it&#8217;s an exciting process that enables great data projects, ranging from traditional reporting to artificial intelligence and machine learning.</p>\n\n\n\n<p>The idea of data governance originated in regulation and compliance. Not that long ago, data was a “wild west”: there were few rules and regulations about how it could be used or transferred, and most were industry-specific. That started to change with HIPAA, which covered medical data (though not much else). It changed in a big way with Europe&#8217;s GDPR, which enacted stringent requirements for how data is used and how individuals control the use of data about themselves; it also provided significant penalties for organizations that disobeyed the rules. In the US, California enacted a data privacy law (CCPA) that is similar to GDPR in many ways, and other states are likely to follow.</p>\n\n\n\n<p>The need for data governance is simple. People who work with data need to take those regulations into account. They need to track the data they have, where it came from, who was allowed to modify it, and how it was modified. If their dataset merges multiple data sources, they have to track those other sources. They need to be able to find and delete data on short notice if a customer requests it (for example, by exercising the GDPR’s “right to be forgotten”). They need to know how the data was collected—not just whether consent was requested and granted, but how their data sources were chosen. Who (or what) appears in the dataset? Are the data sources biased, and how might those biases affect results? And this requires a set of tools that is more sophisticated than dumping the data into a data warehouse or submerging it in a data lake. </p>\n\n\n\n<p>But a funny thing happened. At the same time that companies had to prepare for increased regulation and scrutiny, they were also becoming more sophisticated about how they were using data. They were experimenting with machine learning and artificial intelligence; they were building models that could easily go astray (with embarrassing repercussions) if they were based on data that was out of date or erroneous. And they realized that their data science teams were spending an inordinate amount of time searching for data, which was frequently locked up in a departmental silo or submerged in a data swamp. They often compounded the time spent searching when they realized, after starting their analysis, the data they found was unusable. It was stale, incorrect, incomplete, badly described, or subject to any of a dizzying number of problems. If your data isn&#8217;t trustworthy, the results you get from that data won&#8217;t be trustworthy, either.</p>\n\n\n\n<p>What did the data scientists need? Tools to help them find relevant data, understand its schema, understand how it was collected, understand how and where it was used and whether they could trust it. What did the compliance experts need? Tools to help them find relevant data, understand its schema so they knew just what was included in the data, understand how the data was collected, how and where it was used, and whether they could trust it. Pretty soon, people realized that these were almost exactly the same problem.</p>\n\n\n\n<p>The problem boils down to managing metadata—the data about the data, the data that describes the data. Companies need to manage their metadata so they know what their data means: how it was collected, how the data is represented, how the columns in a table are defined, when the data was updated, and even how frequently it is accessed. Data that hasn’t been used for a few years probably hasn’t been used for a good reason. Companies also need to track restrictions on data’s use, who is allowed to access it, who is allowed to change it, and much more. <a href=\"https://arxiv.org/pdf/1803.09010.pdf\">Datasheets for Datasets</a> describes some of the metadata that has to be tracked to manage data effectively. Managing this metadata has often been handled by a “data steward”; but as data scales, delegating metadata management to a single person becomes ineffective. It&#8217;s impossible to keep up with all the data flowing into an organization—even a small one.</p>\n\n\n\n<p>And that&#8217;s what makes data governance interesting. It&#8217;s not just a requirement that&#8217;s imposed by external regulators. It&#8217;s about the process of understanding what data you have, what that data means, and how to use it. And it&#8217;s surprising (well, not to any data scientist) how few companies actually understand the data they have, and what they can do with it. And once you understand your data—what you have, what it means, where it came from—you’re finally in a position to use it effectively.</p>\n\n\n\n<p>How does this look in practice? The open source project <a href=\"https://github.com/lyft/amundsen\">Amundsen</a> was started to enable <a href=\"https://eng.lyft.com/amundsen-lyfts-data-discovery-metadata-engine-62d27254fbb9\">data discovery at Lyft</a>. It enables data scientists to search for data in Lyft&#8217;s “data lake,” and implements something like Google&#8217;s PageRank algorithm to rank relevant data sources. It also tracks who has accessed the data, how often, and when; data that is used frequently is more likely to be well-maintained. Although Amundsen was built to solve a supposedly different problem, it has also become a tool for data governance. It’s really about metadata management, and that’s at the heart of data governance.&nbsp; </p>\n\n\n\n<p>It’s also important to think about what metadata management tools like Amundsen <em>don’t</em> provide. Amundsen tracks data access, so there’s a virtual “paper trail” about how data was used, but it doesn&#8217;t implement any kind of access control. It won’t prevent someone from accessing data they shouldn’t; it just lets you document what happened after the fact. It’s better at tracking down a violation than preventing one. It also doesn&#8217;t track data lineage (at least, not yet), although users can add metadata about how data is modified and remixed. So it’s not a complete solution—but it’s a step toward a solution. </p>\n\n\n\n<p>Going beyond metadata management, many data governance platforms are designed to enforce data access policies. They go beyond leaving a “paper trail” by restricting data access to those who have appropriate credentials, even on a record-by-record basis. They can also track data lineage, build data catalogs, and search for relevant data. Most of the commercial tools provide explicit support for regulatory compliance, such as GDPR and CPPA.&nbsp; </p>\n\n\n\n<p>Regardless of the tools, data governance and data discovery go together. You can’t use your data if you can’t find it. You can’t use your data if you don’t even know what data you have. And you’re still at risk of data breaches, legal liability, and violating customer’s trust, even if—especially if—you don’t know what data you have. Data governance starts with metadata. And once you understand that, you understand that by requiring you to manage your metadata, data governance is an enabler, not a hindrance. That’s when you can really think productively about how to use your data</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/bDh1ARjfuqw\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 6 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/4PONL-GlTVk/\n<ol>\n<li><a href=\"https://rufus.ie/\">Rufus</a> &#8212; <i>Create bootable USB drives the easy way.</i></li>\n<li><a href=\"https://ai.googleblog.com/2020/04/improving-audio-quality-in-duo-with.html\">Improving Audio Quality in Duo with WaveNetEQ</a> &#8212; Google filling in missing packets in voice calls using deep learning.</li>\n<li><a href=\"https://arxiv.org/abs/1809.07430\">CRN++</a> &#8212; <i>language for programming deterministic (mass-action) chemical kinetics to perform computation.</i></li>\n<li><a href=\"http://journal.stuffwithstuff.com/2020/04/05/crafting-crafting-interpreters/\">Crafting Crafting Interpreters</a> &#8212; story behind the writing of the <a href=\"http://craftinginterpreters.com/\">Crafting Interpreters</a> book.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/4PONL-GlTVk\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 3 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/oihNdyY6L8c/\n<ol>\n<li><a href=\"https://blog.paloaltonetworks.com/2020/04/network-zero-trust-learning-curve/\">The Zero Trust Learning Curve</a> (Palo Alto Networks) &#8212; don&#8217;t learn with the Crown Jewels. <i>The trouble with starting with the most sensitive protect surfaces is that they’re often too fragile and many people don’t know how they work. Starting there with Zero Trust frequently results in failures. Too often, when this happens, organizations blame these failures on Zero Trust. In fact, the problem is that no one in the organization has experience building Zero Trust environments.</i></li>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf\">Software Engineering Advice from Building Large-Scale Distributed Systems</a> (Jeff Dean) &#8212; slide deck from a Stanford talk he gave.</li>\n<li><a href=\"https://github.com/iTaysonLab/gorkiy\">gorkiy</a> &#8212; decompilation of Russia&#8217;s COVID-19 person tracker.</li>\n<li><a href=\"http://everest-pipkin.com/teaching/tools.html\">Open Source, Experimental, and Tiny Tools Roundup</a> &#8212; tons of tools for games, graphics, sounds, live coding, zines, and more.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/oihNdyY6L8c\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 2 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/TJN5y_x03mc/\n<p><ol>\n<li><a href=\"https://github.com/ImperialCollegeLondon/covid19model\">Imperial College&#8217;s COVID19 Model</a> &#8212; in github, in R, MIT-licensed. <i>This repository has code for replication purposes. The bleeding edge code and advancements are done in a private repository.</i></li>\n<li><a href=\"https://prabros.com/readings-on-time\">Readings on Time</a> &#8212; <i>I bumped on this idea while reading Alan Kay’s writing about making the difference between mutable and immutable data “moot” in the context of FP vs. OOP by bringing in the concept of managed time. Since then I have been on the look out for material that helps develop my understanding on this subject. It is a fertile area with a lot of open problems for research and bringing back the fruits of these labour as an interactive system will unlock new pathways in computing. Here I present a collection of some of the resources that have helped me in charting my journey.</i></li>\n<li><a href=\"https://twitter.com/davidpaulk/status/1245299840944201729\">Douyin Suspending Cantonese Livestreamers</a> &#8212; you might dislike Facebook&#8217;s privacy settings but they don&#8217;t tell people they can&#8217;t speak their own language.</li>\n<li><a href=\"https://github.com/oakes/vim_cubed\">vim cubed</a> &#8212; awful to use, but it looks GREAT.</li>\n</ol></p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/TJN5y_x03mc\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 1 April 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/4lXCER6WqOc/\n<ol><li><a href=\"https://devrealm.org/automated-tests-for-proprietary-systems/\">Replaying Traffic to Test Proprietary Systems</a> &#8212; using Wiresham to replay traffic to test blackbox proprietary systems.</li><li><a href=\"https://cris.brighton.ac.uk/ws/files/180417/Harnassing_the_Hackers_DRUID.pdf\">Outlaw Innovations</a> &#8212; <i>This paper will explore how the often illegal activities of hackers (in the original usage of the term to refer to individuals who modify computer hardware and software) may produce valuable innovations. It will explore how these innovations, termed Outlaw Innovations, may be appropriated by firms and provide case studies where this has taken place. The paper will seek to locate this phenomenon in the existing innovation literature, and explore the implications for firm innovation processes.</i></li><li><a href=\"https://www.kapwing.com/resources/we-tested-the-five-best-tiktok-algorithm-theories/\">Testing TikTok Algorithm Theories</a> &#8212; I&#8217;m fascinated by people reverse-engineering algorithms like this. It&#8217;s kinda like people trying to figure out what the gods want.</li>\n<li><a href=\"https://github.com/hyperlogic/riftty\">riftty</a> &#8212; <i>Terminal emulator meant for use with the Oculus Rift headseat.</i> I used to dream of lying in bed with a split keyboard and a headset, never needing to even get vertical. Now I&#8217;m in my 40s, I acknowledge that removing the only movement I get in my working life (walking to the desk and sitting) would probably a step in the wrong direction. But still, this feels nerd-important.</li></ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/4lXCER6WqOc\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 31 March 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/rWYuEOCk7ng/\n<ol>\n<li><a href=\"https://www.medtronic.com/us-en/e/open-files.html?cmpid=vanity_url_medtronic_com_openventilator_Corp_US_Covid19_FY20\">Medtronic Releases Ventilator Designs</a> &#8212; not open source, as the <a href=\"https://www.medtronic.com/content/dam/medtronic-com/global/Corporate/covid19/documents/permissive-license-open-ventilator.pdf\">license</a> is a limited-time limited-purpose license that retains rights. I imagine some corporate lawyers have done some frantic Googling for open meditech licensing clauses.</li>\n<li><a href=\"https://github.com/liquidata-inc/dolt\">dolt</a> &#8212; version history for tabular data. Compare to <a href=\"https://sno.earth/\">sno</a>, which is version control for geospatial and tabular data.</li>\n<li><a href=\"https://github.com/nhn/tui.editor\">Toast UI Editor</a> &#8212; extensible WYSIWYG Markdown editor.</li>\n<li><a href=\"https://rexdouglass.github.io/TIGR/Douglass_2020_How_To_Be_Curious_Instead_of_Contrarian_About_Covid19.nb.html\">How to be Curious Instead of Contrarian</a> &#8212; it&#8217;s about Coronavirus/Covid-19 but could apply equally well to any topic. <i>1) Care about the answer to a question; 2) Post a question and propose a research design that could answer it; 3) Use failures of your predictions to revise your mode; 4) Form meaningful prior beliefs with a thorough literature review; 5) Don&#8217;t form strong prior beliefs based on cherry-picked data; 6) Be specific and concrete about your theory; 7) Choose enough cases to actually test your theory; 8) Convey uncertainty with specificity not doublespeak.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/rWYuEOCk7ng\" height=\"1\" width=\"1\" alt=\"\"/>\nWhat you need to know about product management for AI\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/pqmrP2XDVmU/\n<p>If you’re already a software product manager (PM), you have a head start on becoming a PM for artificial intelligence (AI) or machine learning (ML). You already know the game and how it is played: you’re the coordinator who ties everything together, from the developers and designers to the executives. You’re responsible for the design, the product-market fit, and ultimately for getting the product out the door. But there’s a host of new challenges when it comes to managing AI projects: more unknowns, non-deterministic outcomes, new infrastructures, new processes and new tools. A lot to learn, but worthwhile to access the unique and special value AI can create in the product space.</p>\n<p>Whether you manage customer-facing AI products, or internal AI tools, you will need to ensure your projects are in sync with your business. This means that the AI products you build align with your existing business plans and strategies (or that your products are driving change in those plans and strategies), that they are delivering value to the business, and that they are delivered on time. A PM for AI needs to do everything a traditional PM does, but they also need an operational understanding of machine learning software development along with a realistic view of its capabilities and limitations.</p>\n<h2>Why AI software development is different</h2>\n<p>AI products are automated systems that collect and learn from data to make user-facing decisions. Pragmatically, machine learning is the part of AI that “works”: algorithms and techniques that you can implement now in real products. We won’t go into the mathematics or engineering of modern machine learning here. All you need to know for now is that machine learning uses statistical techniques to give computer systems the ability to &#8220;learn&#8221; by being trained on existing data. After training, the system can make predictions (or deliver other results) based on data it hasn’t seen before.</p>\n<p>AI systems differ from traditional software in many ways, but the biggest difference is that machine learning shifts engineering from a deterministic process to a probabilistic one. Instead of writing code with hard-coded algorithms and rules that always behave in a predictable manner, ML engineers collect a large number of examples of input and output pairs and use them as training data for their models.</p>\n<p>For example, if engineers are training a neural network, then this data teaches the network to approximate a function that behaves similarly to the pairs they pass through it. In the best case scenario, the trained neural network accurately represents the underlying phenomenon of interest and produces the correct output even when presented with new input data the model didn’t see during training. For machine learning systems used in consumer internet companies, models are often continuously retrained many times a day using billions of entirely new input-output pairs.</p>\n<h2>Machine learning adds uncertainty</h2>\n<p>With machine learning, we often get a system that is statistically more accurate than simpler techniques, but with the tradeoff that some small percentage of model predictions will always be incorrect, sometimes in ways that are hard to understand.</p>\n<p>This shift requires a fundamental change in your software engineering practice. The same neural network code trained with seemingly similar datasets of input and output pairs can give entirely different results. The model outputs produced by the same code will vary with changes to things like the size of the training data (number of labeled examples), network training parameters, and training run time. This has serious implications for software testing, versioning, deployment, and other core development processes.</p>\n<p>For any given input, the same program won’t necessarily produce the same output; the output depends entirely on how the model was trained. Make changes to the training data, repeat the training process with the same code, and you’ll get different output predictions from your model. Maybe the differences will be subtle, maybe they’ll be substantial, but they’ll be different.</p>\n<p>The model is produced by code, but it isn’t code; it’s an artifact of the code and the training data. That data is never as stable as we’d like to think. As your user base grows, the demographics and behavior of the user population in production shift away from your initial training data, which was based on early adopters. Models also become stale and outdated over time. To make things even more challenging, the real world adapts to your model’s predictions and decisions. A model for detecting fraud will make some kinds of fraud harder to commit–and bad actors will react by inventing new kinds of fraud, invalidating the original model. Models within AI products change the same world they try to predict.</p>\n<p>Underneath this uncertainty lies further uncertainty in the development process itself. It’s hard to predict how long an AI project will take. Predicting development time is hard enough for traditional software, but at least we can make some general guesses based on past experience. We know what “progress” means. With AI, you often don’t know what’s going to happen until you try it. It isn’t uncommon to spend weeks or even months before you find something that works and improves model accuracy from 70% to 74%. It’s hard to tell whether the biggest model improvement will come from better <a href=\"https://towardsdatascience.com/designing-your-neural-networks-a5e4617027ed\">neural network design</a>, <a href=\"https://developers.google.com/machine-learning/crash-course/representation/feature-engineering\">input features</a>, or training data. You often can’t tell a manager that the model will be finished next week or next month; your next try may be the one that works, or you may be frustrated for weeks. You frequently don’t know whether something is feasible until you do the experiment.</p>\n<h2>AI product estimation strategies</h2>\n<p>Planning and estimation are difficult for AI products because it is rare to find two real-world systems where the training data and algorithms applied are the same.</p>\n<p>Imagine you are a data scientist at Disney. Your division is starting a new video streaming service and you’re tasked with building a system to recommend movies. You might establish a baseline by replicating <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">collaborative filtering</a> models published by teams that built recommenders for MovieLens, Netflix, and Amazon. There may even be someone on your team who built a personalized video recommender before and can help scope and estimate the project requirements using that past experience as a point of reference.</p>\n<p>In this scenario, your Disney team appears to be solving a problem similar to the early <a href=\"https://en.wikipedia.org/wiki/Netflix_Prize\">Netflix Prize</a> recommendation problem. You have a highly curated catalog with a small number of professionally produced movies and TV series, and need to recommend those items to users based on their interests and viewing habits. Your team also needs to solve a <a href=\"https://en.wikipedia.org/wiki/Cold_start_(computing)\">cold start problem</a> so you can recommend movies before the system begins collecting user feedback data (typically solved by using contextual topic-based or popularity-based recommendations), but once you gather explicit user ratings and video viewing data, you should be able to build a reasonable system. It may even be faster to launch this new recommender system, because the Disney data team has access to published research describing what worked for other teams.</p>\n<p>But this is a best-case scenario, and it’s not typical. What if instead of a narrow, curated video catalog, you were building a <a href=\"https://ai.google/research/pubs/pub45530\">recommender system for a consumer video app</a>, where anyone could create and upload user-generated content (UGC)? You might have millions of <a href=\"http://ai-lab-challenge.bytedance.com/tce/vc/\">short videos</a>, with user ratings and limited metadata about the creators or content. Social and trending signals in this network will be important, and <a href=\"https://www.washingtonpost.com/technology/2019/01/25/youtube-is-changing-its-algorithms-stop-recommending-conspiracies/\">controlling spam and abuse</a> will be a <a href=\"https://www.wsj.com/articles/facebook-youtube-overrun-with-bogus-cancer-treatment-claims-11562072401\">challenge</a>. It may even be necessary to do <a href=\"https://ai.google/research/pubs/pub45619\">image or video analysis</a> to make content-based recommendations, detect fraud, or reject content that violates your rules (for example, live shooter videos). You could still begin by shipping a simple cold-start recommender system, but it will take you much longer to build and iterate on your model to achieve the level of accuracy the business expects. You will likely encounter many challenges training your recommender with large amounts of constantly changing UGC and <a href=\"https://dl.acm.org/citation.cfm?id=3346997\">conflicting objectives</a>.</p>\n<p>These issues may be unexpected for teams that aren’t familiar with developing machine learning systems trained on user-generated content. If you ignore these complications during planning and assume your system will behave similarly to the original recommenders at Netflix, the project will end up significantly behind schedule, and may have serious abuse problems that Netflix didn’t face. In each of these examples, the machine learning problem faced by the business was similar (recommend movies to users), but the required approach ended up being very different based on subtle differences in the data and product design.</p>\n<p>Predicting development time becomes even more difficult when you apply an algorithm successfully used in one domain to a different problem. Consider using the Netflix collaborative filtering algorithm to recommend jobs to job seekers. On the surface, these problems seem similar: we have a dataset of items (jobs) and users (job seekers), so, in theory, we could use a job seeker’s history of saved jobs or job applications to recommend similar new jobs. Complications arise when you consider the nuances of recruiting data and job applications. Features like geography and <a href=\"https://www.linkedin.com/help/lms/answer/96116/ad-targeting-by-job-seniority-overview?lang=en\">job seniority</a> are critical to getting a good match. Job postings have a much shorter relevant lifetime than movies, so content-based features and metadata about the company, skills, and education requirements will be more important in this case. Job recommendations also include additional <a href=\"https://engineering.linkedin.com/blog/2018/10/building-representative-talent-search-at-linkedin\">algorithmic and regulatory challenges</a> related to diversity, bias, and fairness that are not encountered in movie recommendations.</p>\n<p>The point isn’t that estimating AI projects is intractably hard; it’s that you aren’t likely to succeed if you expect an AI project to behave like a traditional software project. There are strategies for dealing with all of this uncertainty–starting with the proverb from the early days of Agile: “<a href=\"http://wiki.c2.com/?DoTheSimplestThingThatCouldPossiblyWork\">do the simplest thing that could possibly work</a>.” You don’t always need to start with a complex neural network; a simple regression (or even simpler, an average) might be enough to get your project off the ground. In some cases, that simple model may be all you ever need. The biggest problems arise from taking shortcuts and assuming that a machine learning model that works for one application will perform well in a different context without looking at the underlying data.</p>\n<h2>Organizational prerequisites for AI at scale</h2>\n<p>Particularly at a company that’s new to AI, part of an AI product manager’s job is helping the organization build the culture it needs to succeed with AI. Because it’s so different from traditional software development, where the risks are more or less well-known and predictable, AI rewards people and companies that are willing to take intelligent risks, and that have (or can develop) an experimental culture. As Jeff Bezos has <a href=\"https://www.inc.com/bill-murphy-jr/17-jeff-bezos-quotes-that-suddenly-take-on-a-whole-new-meaning-after-2-stunning-decisions.html\">said</a>, “If you only do things where you know the answer in advance, your company goes away.”</p>\n<p>No company wants to dry up and go away; and at least if you follow the media buzz, machine learning gives companies real competitive advantages in prediction, planning, sales, and almost every aspect of their business. If machine learning is so amazing, why hasn’t every company applied it and reinvented itself?</p>\n<p>Even simple machine learning projects can be difficult, and managing these projects in a real business is <a href=\"https://hbr.org/2017/04/the-first-wave-of-corporate-ai-is-doomed-to-fail\">much harder</a> than most people realize; that’s why VentureBeat claims <a href=\"https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/\">87% of machine learning products never make it into production</a>, and Harvard Business Review says that “<a href=\"https://hbr.org/2017/04/the-first-wave-of-corporate-ai-is-doomed-to-fail\">The first wave of corporate AI is bound to fail</a>.” Machine learning is not fairy dust you can sprinkle on your existing product. You can’t just plug in off-the-shelf cloud APIs that will magically make your product intelligent. Machine learning requires a complete rethinking; your products and your workflows are likely to change in fundamental ways. Product managers for AI need to lead that rethinking.</p>\n<p><a href=\"https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/\">VentureBeat</a> discusses two reasons for failure: management that believes you can solve problems by throwing money at them (whether that means hiring more, or better, developers), and data that is locked away into silos, where the people building your ML applications can’t get it. These are fundamentally cultural problems. You need to understand that many solutions can’t be bought (yet), that AI products require collaboration between teams, that data silos stand in the way of success, and that the best remedy for failure is picking yourself up and trying again. (To be clear, we are not saying that data can or should be used indiscriminately, without concern for legal compliance, customer privacy, bias, and other ethical issues.)</p>\n<p>The need for an experimental culture implies that machine learning is currently better suited to the consumer space than it is to enterprise companies. For <a href=\"https://blog.tryexponent.com/consumer-enterprise-product-management/\">enterprise products</a>, requirements often come from a small number of vocal customers with large accounts. It’s difficult to be experimental when your business is built on long-term relationships with customers who often dictate what they want. Measurement, tracking, and logging is less of a priority in enterprise software. An enterprise company like Oracle has a lot of customers, but Oracle’s customer base is dwarfed by Amazon’s or Walmart’s. Consumer product management is typically more bottom-up, driven by large volumes of user feedback and usage tracking data. Many consumer internet companies invest heavily in analytics infrastructure, instrumenting their online product experience to measure and improve user retention. It turns out that type of data infrastructure is also the foundation needed for building AI products.</p>\n<p>The ability to make decisions based on data analytics is a prerequisite for an “experimental culture.” This was the path taken by companies like Google, Facebook, and LinkedIn, which were <a href=\"https://learning.oreilly.com/library/view/data-driven/9781491925454/\">driven by analytics</a> from the beginning. At measurement-obsessed companies, every part of their product experience is quantified and adjusted to optimize user experience.</p>\n<p>These companies eventually moved beyond using data to inform product design decisions. They have deployed machine learning at scale to recommend movies and friends, personalize ads, and deliver search results. Their user agreements <a href=\"https://safety.google/privacy/data/\">allow them to use data</a> to improve their products. They’ve built the infrastructure needed to collect, manage, and analyze their data, and <a href=\"https://medium.com/@jamal.robinson/how-facebook-scales-artificial-intelligence-machine-learning-693706ae296f\">deploy AI products</a> that can automatically make user-facing decisions in real time. By putting these pieces together, these companies created an environment where machine learning discoveries and innovation in AI are an integral property of their culture.</p>\n<p>You are unlikely to succeed at AI if you haven’t laid a proper foundation for it. That foundation means that you have already shifted the culture and data infrastructure of your company. In “<a href=\"https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007\">The AI Hierarchy of Needs</a>,” Monica Rogati argues that you can build an AI capability only after you’ve built a solid data infrastructure, including data collection, data storage, data pipelines, data preparation, and traditional analytics. If you can’t walk, you’re unlikely to run. Just as AI product managers need to help build a culture in which they can succeed, they need to help define and build the infrastructure that will allow an organization to walk, and then to run.</p>\n<p>If you’re just learning to walk, there are ways to speed up your progress. Although machine learning projects differ in subtle ways from traditional projects, they tend to require similar infrastructure, similar data collection processes, and similar developer habits. A relatively narrow project, like an intelligent search interface for your product, will require you to develop a lot of the basics, starting with the ability to acquire, clean, store, and analyze data. You’ll become familiar with the problems that real-world data presents. You’ll have to build the infrastructure that data projects require. Most important, you’ll start building relationships with other teams–and those relationships will become crucial when you tackle bigger projects.</p>\n<p>The prospect of taking on a costly data infrastructure project is daunting. If your company is starting out on this path, it’s important to recognize that there are now widely available open source tools and commercial platforms that can power this foundation for you. <a href=\"https://medium.com/@l2k/how-to-build-a-machine-learning-team-when-you-are-not-google-or-facebook-f639238eafa2\">According to Lukas Biewald</a>, founder of Figure Eight and Weights &amp; Biases: “Big companies should avoid building their own machine learning infrastructure. Almost every tech company I talk to is building their own custom machine learning stack and has a team that’s way too excited about doing this.”</p>\n<p>If you are still figuring out your analytics strategy, you are fighting the last war. That doesn’t mean you shouldn’t be thinking about AI, but it’s a goal, not the next step. Start with a simple project, build your infrastructure, learn how to use your data effectively, build relationships within the organization, then make the leap.</p>\n<h2>Identifying “viable” machine learning problems</h2>\n<p>Any product manager is part of the team that determines what product to build. If you are just starting out with AI, that decision is especially important–and difficult. The stakes are high–and you can be pardoned if you’re uncomfortable with ideas that are expensive and have an uncertain probability of success. Product managers are more comfortable with roadmaps that can get to market value in the next 12 months, and costs that can be kept to a minimum. AI doesn’t fit that model. An AI pilot project, even one that sounds simple, probably won’t be something you can demo quickly. You will struggle to make the case to invest in research upfront.</p>\n<p>Therefore, you need to pay particular attention to defining a “minimum viable product” (MVP). How do you find an MVP, with the stress on both “minimum” and “viable”? What features should be deferred to later versions, and what belongs in the initial release? A demo, or even a first release, can be based on heuristics or simple models (linear regression, or even averages). Having something you can demo takes some of the pressure off your machine learning team. But you still need to answer the question: how do you tell the difference between technology you can productize now, and that which will be viable in an uncertain time frame? Most interesting things in AI are on the cutting edge of what we can do in engineering, and that makes them unpredictable: you don’t know when the engineering team will have the insight needed to make the product work. Those cutting-edge ideas are also attractive, both to managers who don’t understand the risks and to developers who want to try something that’s really challenging. And you, as the product manager, are caught between them.</p>\n<p>Effective product managers for AI know the difference between easy, hard, and impossible problems. A good example of a problem that has been hard or impossible <a href=\"https://arxiv.org/abs/1909.03186\">until recently</a> is generative text summarization. It seems like it should be within reach of our current machine learning algorithms, but in practice, accurately summarizing arbitrary text is still beyond the state of the art. You can generate text that, at first glance, appears to be written by a human, but upon closer inspection, you will often find it filled with factual and grammatical errors unacceptable in most business applications. This the “art of the possible,” an intuition for what is and isn’t feasible. It’s an intuition that you can learn through experience–and it’s why understanding your failures is at least as important as understanding your successes.</p>\n<p>For AI products, one important part of being “feasible” is being precisely defined. As Jeremy Jordan says, “<a href=\"https://www.jeremyjordan.me/ml-requirements/\">A problem well-defined is half solved</a>.” It’s easy to look at the many successes of AI over the past few years and think that there’s some magic, but there really isn’t. If you can state what you want to accomplish very precisely, and break that down into even simpler problems, you’re off to a good start. Jordan has some good advice: start by solving the problem yourself, by hand. If you want to help customers organize pictures on their phones, spend some time on your phone, organizing pictures. Interview actual customers to see what they want. Build a prototype they can try with real data. Above all, don’t think that “we want to help customers organize pictures” is a sufficient problem statement. It isn’t; you’ve got to go into much more detail about who your customers are, how they want to organize their pictures, what kinds of pictures they’re likely to have, how they want to search, and more.</p>\n<p>Another good proxy for identifying “viable” machine learning problems is to see how quickly you can construct a labeled benchmark dataset along with clear, narrowly defined accuracy goals for your ML algorithm. Data labeling ease is a good proxy for whether machine learning is cost effective. If you can build data labeling into normal user activities within your product (for example, flagging spam emails), then you have a shot at gathering enough input-output pairs to train your model. Otherwise, you will burn money paying external services for labeled data, and that up-front cost–before you can do your first demo–can easily be the most expensive part of the project. Without large amounts of good raw and labeled training data, solving most AI problems is not possible.</p>\n<p>Even with good training data and a clear objective metric, it can be difficult to reach accuracy levels sufficient to satisfy end users or upper management. When you’re planning a product, it’s important to have a gut feel for what error rates are achievable and what aren’t, and what error rates are acceptable for your application. Product recommendations are easy; nobody is injured if you recommend products that your customers don’t want, though you won’t see much ROI. Fraud detection is riskier; you’re working with real money, and errors show up in your bottom line. Autonomous vehicles are a different matter; if you’re building an autonomous vehicle, you need AI that is close to perfect. (And perfect will never be achievable.) That kind of difference has a tremendous effect on how you structure the development process.</p>\n<h2>Work on things that matter to your business</h2>\n<p>The most important advice we can give is to make sure you work on AI products that matter to the business. It’s entirely too easy to define a problem, spend three to six months solving it, and then find out the solution works, but nobody cares; it doesn’t make a difference to the business. One of a product manager’s most important jobs is ensuring that the team is solving a problem that’s worth solving.</p>\n<p>If you have a good data team and an intuitive understanding of your company’s data, there should be no shortage of ideas around how to improve your product. You will probably have more ideas than you can possibly use–so how do you prioritize the list of machine learning projects? How do you select what to work on? What delivers the greatest ROI? Shipping any machine learning system requires a huge mountain of organizational and data engineering effort, so the ultimate payoff needs to match that investment.</p>\n<p>The buzz around AI has encouraged many people to think that AI can suddenly double or triple your profitability. That’s unlikely to be true–but what is likely? A product manager needs to be realistic about expectations. You shouldn’t over-promise, and you shouldn’t under-deliver. But neither should you under-promise: while simple products might help you to get started, you want to show upper management you can move the needle significantly. If the needle doesn’t move, you will undermine your team. If a product is feasible, if it’s something customers want, if you can get realistic error rates, and if you understand the development flows, you still have to ask whether it’s the best investment of time and resources. Is there another product that will generate a greater return more quickly?</p>\n<p>To make these judgements, an AI product manager needs to understand the company’s data inside and out. That includes the ability to do your own analysis, to run SQL queries, to develop metrics, and to build dashboards. If you don’t understand your data intimately, you will have trouble knowing what’s feasible and what isn’t. You will have trouble understanding problems with data quality–you should know in your bones why 80% of a data scientist’s time is spent cleaning data. Without this data familiarity, you will have trouble spotting ethical problems that arise from biased or insufficient data. If you can’t define the right metrics to monitor, you won’t know whether or not your product is successful, nor will you know when your model performance has degraded (as it almost inevitably will).</p>\n<p>Even if a product is feasible, that’s not the same as product-market fit. Is the product something that customers need? Will it help a small segment of customers or will it increase the most important metric for the majority of your users? Too many companies focus on building something cool without thinking about whether anyone really cares. Customers want you to solve their problems; they don’t care what kind of neural network you’re using. You may discover that you don’t need AI at all, and that’s just fine.</p>\n<h2>Prioritizing with the business in mind</h2>\n<p>There are a <a href=\"https://www.quora.com/What-are-the-best-ways-to-prioritize-a-list-of-product-features/answer/Adam-Nash\">number</a> of <a href=\"https://wavelength.asana.com/workstyle-the-process-and-math-behind-prioritization/\">different</a> <a href=\"https://www.sachinrekhi.com/how-to-prioritize-a-product-roadmap\">ways</a> to prioritize features into a product roadmap, and it&#8217;s likely your product organization already has its own preferred methodology for this. That said, there are many new machine learning teams working on a large number of projects without a clear prioritization or roadmap. Many companies invest a lot in hiring data scientists and building ML platforms, but then they focus them on solving the wrong problems.</p>\n<p>One successful approach to this issue is to organize ML product feature ideas by theme and concentrate on a few high ROI projects. To prioritize, start with your company’s mission and near-term strategic objectives. What is the business trying to achieve? Pair a machine learning application directly to one of those objectives, so that when you improve the accuracy metric for your model it directly impacts metrics the business cares about. Build a direct connection between your machine learning application and something the company values.</p>\n<p>For example, at LinkedIn (where co-author Pete Skomoroch previously worked) the mission was to connect the world’s professionals to make them more productive and successful. A strategic objective for the company was to become the professional profile of record and have complete and up-to-date resume data in the LinkedIn profiles for all professionals. A project idea under this objective was to create a machine learning model to <a href=\"https://engineering.linkedin.com/research/2014/linkedin-skills-large-scale-topic-extraction-and-inference\">recommend skills</a> a member should add to their profile. A team came up with an impact estimate for the product feature by estimating the expected increase in conversion rate when users were shown ML recommendations.</p>\n<p><a href=\"https://engineering.linkedin.com/teams/data/artificial-intelligence/people-you-may-know\">People You May Know</a> (PYMK) was a successful example of this type of strategic alignment from LinkedIn&#8217;s data team. The PYMK recommendation system was trained on data including existing LinkedIn connections, profile similarity, and contacts imported from email to suggest other members a user should connect with. PYMK directly paired what the company wanted to do (drive connections) with a machine learning solution. With a small number of engineers, the data team built a production machine learning model that directly improved the most important metric for the company. Within months it also drove new user growth for the site and created a flywheel of user growth that was critical as LinkedIn became a public company.</p>\n<p>Once you prune down the set of ideas to ones that align with strategic objectives, there are a number of ways to prioritize them. One effective approach is to get everyone in a room who will be building the system, and have the group form consensus estimates of difficulty, headcount, and impact for each project. Then you can create a chart of impact and ease, rank each project by return on investment and prioritize accordingly. In reality, prioritization is a messy and fluid process, as projects often have dependencies and face staffing limitations or conflicts with other stakeholder deadlines. Scope often needs to be reduced or <a href=\"https://randsinrepose.com/archives/bits-features-and-truth/\">quality sacrificed</a> to align with other teams or priorities.</p>\n<p>Working on something that matters to the business is not the only important criteria to consider, since without access to data, your ML system will be useless. In larger companies, it’s best to start by focusing on business units that are eager to work with you and where your help is needed. When you begin development of your first ML product, try to work with teams that already have training data available and help them drive their most important metric. Ideally, that also aligns with the larger set of company priorities.</p>\n<h2>Resources</h2>\n<p>Where do you go from here as a product manager new to the world of AI? This role is still being defined, but there are already many useful resources out there for you. Here are some great places to start:</p>\n<ul>\n<li>“<a href=\"http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf\">Rules of Machine Learning: Best Practices for ML Engineering” (Google)</a></li>\n<li>“<a href=\"https://pair.withgoogle.com/\">People + AI Guidebook” (Google)</a></li>\n<li>“<a href=\"https://d1.awsstatic.com/whitepapers/aws-managing-ml-projects.pdf\">Managing Machine Learning Projects” (AWS)</a></li>\n<li><u>“</u><a href=\"https://developer.apple.com/videos/play/wwdc2019/803/\">Designing Great ML Experiences” (Apple)</a></li>\n<li><a href=\"https://conferences.oreilly.com/strata-data-ai\">O’Reilly Strata Data &amp; AI Conference</a></li>\n<li><a href=\"https://www.insightdatapm.com/\">Insight Fellows Data PM Program</a></li>\n<li><a href=\"https://fullstackdeeplearning.com/march2019\">Spring 2019 Full Stack Deep Learning Bootcamp (Berkeley)</a></li>\n<li>“<a href=\"https://medium.com/@treycausey/rise-of-the-data-product-manager-2fb9961b21d1\">Rise of the Data Product Manager” (Trey Causey)</a></li>\n<li>“<a href=\"https://firstround.com/review/everything-we-wish-wed-known-about-building-data-products/\">Everything We Wish We&#8217;d Known About Building Data Products” (First Round / DJ Patil)</a></li>\n<li>“<a href=\"https://www.ben-evans.com/benedictevans/2018/12/19/does-ai-make-strong-tech-companies-stronger\">Does AI make strong tech companies stronger?” (a16z)</a></li>\n<li>“<a href=\"https://www.youtube.com/watch?v=iMaqGHkUKgI\">Product Management for AI” (Pete Skomoroch)</a></li>\n</ul>\n<p>AI has tremendous potential for those who are willing to learn and to think differently. We hear a lot about AI and corporate transformation; but what we need to make this transformation are people who are willing to lead the changes in corporate culture, help build the data infrastructure, and explore problems that will deliver a measurable return with reasonable investment.</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/pqmrP2XDVmU\" height=\"1\" width=\"1\" alt=\"\"/>\nThe unreasonable importance of data preparation\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/Pt-JBUG44GM/\n<p>In a world focused on buzzword-driven models and algorithms, you’d be forgiven for forgetting about the unreasonable importance of data preparation and quality: <em>your models are only as good as the data you feed them</em>. This is the <a href=\"https://en.wikipedia.org/wiki/Garbage_in,_garbage_out\">garbage in, garbage out</a> principle: flawed data going in leads to flawed results, algorithms, and business decisions. If a self-driving car’s decision-making algorithm is trained on data of traffic collected during the day, you wouldn’t put it on the roads at night. To take it a step further, if such an algorithm is trained in an environment with cars driven by humans, how can you expect it to perform well on roads with other self-driving cars? Beyond the autonomous driving example described, the &#8220;garbage in&#8221; side of the equation can take many forms—for example, incorrectly entered data, poorly packaged data, and data collected incorrectly, more of which we’ll address below.</p>\n<p>When executives ask me how to approach an AI transformation, I show them Monica Rogati’s <a href=\"https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007\">AI Hierarchy of Needs</a>, which has AI at the top, and everything is built upon the foundation of data (Rogati is a data science and AI advisor, former VP of data at Jawbone, and former LinkedIn data scientist):</p>\n<figure class=\"center\"><img alt=\"AI Hierarchy of Needs\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/03/image1.png\"><figcaption>Image courtesy of Monica Rogati, used with permission.</figcaption></figure>\n<p>Why is high-quality and accessible data foundational? If you’re basing business decisions on dashboards or the results of online experiments, you need to have the right data. On the machine learning side, we are entering what Andrei Karpathy, director of AI at Tesla, dubs the <a href=\"https://medium.com/@karpathy/software-2-0-a64152b37c35\">Software 2.0</a> era, a new paradigm for software where machine learning and AI require less focus on writing code and more on configuring, selecting inputs, and iterating through data to create higher level models that learn from the data we give them. In this new world, data has become a first-class citizen, where computation becomes increasingly probabilistic and programs no longer do the same thing each time they run. The model and the data specification become more important than the code.</p>\n<p id=\"F1\"><span id=\"F2\"></span>Collecting the right data requires a principled approach that is a function of your business question. Data collected for one purpose can have limited use for other questions. The assumed value of data is a myth leading to inflated valuations of start-ups capturing said data. <a href=\"https://twitter.com/johnmyleswhite/status/1116676992387244038\">John Myles White</a>, data scientist and engineering manager at Facebook, wrote: &#8220;The biggest risk I see with data science projects is that analyzing data <em>per se</em> is generally a bad thing. Generating data with a pre-specified analysis plan and running that analysis is good. Re-analyzing existing data is often very bad.&#8221; John is drawing attention to thinking carefully about what you hope to get out of the data, what question you hope to answer, what biases may exist, and what you need to correct before jumping in with an analysis<a href=\"#_ftn1\"><sup>[1]</sup></a>. With the right mindset, you can get a lot out of analyzing existing data—for example, descriptive data is often quite useful for early-stage companies<a href=\"#_ftn2\"><sup>[2]</sup></a>.</p>\n<p id=\"F3\">Not too long ago, &#8220;save everything&#8221; was a common maxim in tech; you never knew if you might need the data. However, attempting to repurpose pre-existing data can muddy the water by shifting the semantics from why the data was collected to the question you hope to answer. In particular, determining causation from correlation can be difficult. For example, a pre-existing correlation pulled from an organization’s database should be tested in a new experiment and not assumed to imply causation<a href=\"#_ftn3\"><sup>[3]</sup></a>, instead of this commonly encountered pattern in tech:</p>\n<ol>\n<li>A large fraction of users that do X do Z</li>\n<li>Z is good</li>\n<li>Let&#8217;s get everybody to do X</li>\n</ol>\n<p>Correlation in existing data is evidence for causation that then needs to be verified by collecting more data.</p>\n<p id=\"F4\">The same challenge plagues scientific research. Take the case of Brian Wansink, former head of the Food and Brand Lab at Cornell University, who stepped down after <a href=\"http://news.cornell.edu/stories/2018/09/provost-issues-statement-wansink-academic-misconduct-investigation\">a Cornell faculty review reported</a> he &#8220;committed academic misconduct in his research and scholarship, including misreporting of research data, problematic statistical techniques [and] failure to properly document and preserve research results.&#8221; One of his more egregious errors was to continually test already collected data for new hypotheses until one stuck, after his initial hypothesis failed<a href=\"#_ftn4\"><sup>[4]</sup></a>. <a href=\"https://www.npr.org/sections/thesalt/2018/09/26/651849441/cornell-food-researchers-downfall-raises-larger-questions-for-science\">NPR put it well</a>: &#8220;the gold standard of scientific studies is to make a single hypothesis, gather data to test it, and analyze the results to see if it holds up. By Wansink&#8217;s own admission in the blog post, that&#8217;s not what happened in his lab.&#8221; He continually tried to fit new hypotheses unrelated to why he collected the data until he got a null hypothesis with an acceptable p-value—a perversion of the scientific method.</p>\n<h2>Data professionals spend an inordinate amount on time cleaning, repairing, and preparing data</h2>\n<p>Before you even think about sophisticated modeling, state-of-the-art machine learning, and AI, you need to make sure your data is ready for analysis—this is the realm of data preparation. You may picture data scientists building machine learning models all day, but the common trope that they spend 80% of their time on data preparation is <a href=\"https://www.ibm.com/cloud/blog/ibm-data-catalog-data-scientists-productivity\">closer to the truth</a>.</p>\n<figure class=\"center\"><img alt=\"common trope that data scientists spend 80% of their time on data preparation\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/03/image2.png\"><figcaption></figcaption></figure>\n<p>This is old news in many ways, but it’s old news that still plagues us: a <a href=\"https://www.oreilly.com/ideas/the-quest-for-high-quality-data\">recent O’Reilly survey found that</a> lack of data or data quality issues was one of the main bottlenecks for further AI adoption for companies at the AI evaluation stage and was <em>the</em> main bottleneck for companies with mature AI practices.</p>\n<p id=\"F5\">Good quality datasets are all alike, but every low-quality dataset is low-quality in its own way<a href=\"#_ftn5\"><sup>[5]</sup></a>. Data can be low-quality if:</p>\n<ul>\n<li>It doesn’t fit your question or its collection wasn&#8217;t carefully considered;</li>\n<li>It’s erroneous (it may say &#8220;cicago&#8221; for a location), inconsistent (it may say &#8220;cicago&#8221; in one place and &#8220;Chicago&#8221; in another), or missing;</li>\n<li>It’s good data but packaged in an atrocious way—e.g., it’s stored across a range of siloed databases in an organization;</li>\n<li>It requires human labeling to be useful (such as manually labeling emails as &#8220;spam&#8221; or &#8220;not&#8221; for a spam detection algorithm).</li>\n</ul>\n<p>This definition of low-quality data defines quality as a function of how much work is required to get the data into an analysis-ready form. Look at the responses to my <a href=\"https://twitter.com/hugobowne/status/1164929866346749955\">tweet</a> for data quality nightmares that modern data professionals grapple with.</p>\n<h2>The importance of automating data preparation</h2>\n<p>Most of the conversation around AI automation involves automating machine learning models, a field known as <a href=\"https://en.wikipedia.org/wiki/Automated_machine_learning\">AutoML</a>. This is important: consider how many modern models need to operate at scale and in real time (such as Google’s search engine and the relevant tweets that Twitter surfaces in your feed). We also need to be talking about automation of all steps in the data science workflow/pipeline, including those at the start. Why is it important to automate data preparation?</p>\n<ol>\n<li>It occupies an inordinate amount of time for data professionals. Data drudgery automation in the era of <a href=\"https://www.techopedia.com/definition/28093/data-smog\">data smog</a> will free data scientists up for doing more interesting, creative work (such as modeling or interfacing with business questions and insights). &#8220;76% of data scientists view data preparation as the least enjoyable part of their work,&#8221; according to <a href=\"https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#747151796f63\">a CrowdFlower survey</a>.</li>\n<li id=\"F6\"><span id=\"F7\"></span>A series of subjective data preparation micro-decisions can bias your analysis. For example, one analyst may throw out data with missing values, another may infer the missing values. For more on how micro-decisions in analysis can impact results, I recommend <a href=\"https://journals.sagepub.com/doi/10.1177/2515245917747646\"><em>Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results</em></a><a href=\"#_ftn6\"><sup>[6]</sup></a> (note that the analytical micro-decisions in this study are not only data preparation decisions). Automating data preparation won’t necessarily remove such bias, but it will make it systematic, discoverable, auditable, unit-testable, and correctable. Model results will then be less reliant on individuals making hundreds of micro-decisions. An added benefit is that the work will be reproducible and robust, in the sense that somebody else (say, in another department) can reproduce the analysis and get the same results<a href=\"#_ftn7\"><sup>[7]</sup></a>;</li>\n<li>For the increasing number of real-time algorithms in production, humans need to be taken out of the loop at runtime as much as possible (and perhaps be kept in the loop more as <a href=\"https://hbr.org/2016/01/algorithms-need-managers-too\">algorithmic managers</a>): when you use Siri to make a reservation on OpenTable by asking for a table for four at a nearby Italian restaurant tonight, there’s a speech-to-text model, a geographic search model, and a restaurant-matching model, all working together in real time. No data analysts/scientists work on this data pipeline as everything must happen in real time, requiring an automated data preparation and data quality workflow (e.g., to resolve if I say &#8220;eye-talian&#8221; instead of &#8220;it-atian&#8221;).</li>\n</ol>\n<p>The third point above speaks more generally to the need for automation around all parts of the data science workflow. This need will grow as smart devices, IoT, voice assistants, drones, and augmented and virtual reality become more prevalent.</p>\n<p>Automation represents a specific case of democratization, making data skills easily accessible for the broader population. Democratization involves both education (which I focus on in my work at <a href=\"https://www.datacamp.com/\">DataCamp</a>) and developing tools that many people can use.</p>\n<p id=\"F8\"><span id=\"F9\"></span>Understanding the importance of general automation and democratization of all parts of the DS/ML/AI workflow, it’s important to recognize that we’ve done pretty well at democratizing data collection and gathering, modeling<a href=\"#_ftn8\"><sup>[8]</sup></a>, and data reporting<a href=\"#_ftn9\"><sup>[9]</sup></a>, but what remains stubbornly difficult is the whole process of preparing the data.</p>\n<h2>Modern tools for automating data cleaning and data preparation</h2>\n<p>We’re seeing the emergence of modern tools for automated data cleaning and preparation, such as <a href=\"https://hazyresearch.github.io/snorkel/blog/holoclean.html\">HoloClean</a> and <a href=\"https://www.snorkel.org/\">Snorkel</a> coming from <a href=\"https://cs.stanford.edu/~chrismre/\">Christopher Ré’s group at Stanford</a>. HoloClean decouples the task of data cleaning into error detection (such as recognizing that the location &#8220;cicago&#8221; is erroneous) and repairing erroneous data (such as changing &#8220;cicago&#8221; to &#8220;Chicago&#8221;), and formalizes the fact that &#8220;data cleaning is a statistical learning and inference problem.&#8221; All data analysis and data science work is a combination of data, assumptions, and prior knowledge. So when you’re missing data or have &#8220;low-quality data,&#8221; you use assumptions, statistics, and inference to repair your data. HoloClean performs this automatically in a principled, statistical manner. All the user needs to do is &#8220;to specify high-level assertions that capture their domain expertise with respect to invariants that the input data needs to satisfy. No other supervision is required!&#8221;</p>\n<p id=\"F10\">The HoloClean team also has a system for automating the &#8220;building and managing [of] training datasets without manual labeling&#8221; called Snorkel. Having correctly labeled data is a key part of preparing data to build machine learning models<a href=\"#_ftn10\"><sup>[10]</sup></a>. As more and more data is generated, manually labeling it is unfeasible. Snorkel provides a way to automate labeling, using a modern paradigm called <a href=\"https://arxiv.org/abs/1605.07723\">data programming</a>, in which users are able to &#8220;inject domain information [or heuristics] into machine learning models in higher level, higher bandwidth ways than manually labeling thousands or millions of individual data points.&#8221; <a href=\"https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html\">Researchers at Google AI</a> have adapted Snorkel to label data at industrial/web scale and demonstrated its utility in three scenarios: topic classification, product classification, and real-time event classification.</p>\n<p>Snorkel doesn’t stop at data labeling. It also allows you to automate two other key aspects of data preparation:</p>\n<ol>\n<li>Data augmentation—that is, creating more labeled data. Consider an image recognition problem in which you are trying to detect cars in photos for your self-driving car algorithm. Classically, you’ll need at least several thousand labeled photos for your training dataset. If you don’t have enough training data and it’s too expensive to manually collect and label more data, you can create more by rotating and reflecting your images.</li>\n<li>Discovery of critical data subsets—for example, figuring out which subsets of your data really help to distinguish spam from non-spam.</li>\n</ol>\n<p>These are two of many current examples of the augmented data preparation revolution, which includes products from <a href=\"https://www.ibm.com/support/knowledgecenter/en/SS3RA7_15.0.0/com.ibm.spss.modeler.help/idh_idd_adp_objective.htm\">IBM</a> and <a href=\"https://www.datarobot.com/webinar/minimizing-model-risk-automated-data-preparation-machine-learning/\">DataRobot</a>.</p>\n<h2>The future of data tooling and data preparation as a cultural challenge</h2>\n<p>So what does the future hold? In a world with an increasing number of models and algorithms in production, learning from large amounts of real-time streaming data, we need both education and tooling/products for domain experts to build, interact with, and audit the relevant data pipelines.</p>\n<p>We’ve seen a lot of headway made in democratizing and automating data collection and building models. Just look at the emergence of drag-and-drop tools for machine learning workflows coming out of <a href=\"https://www.nextbigfuture.com/2018/01/google-automl-makes-adding-ai-as-simple-as-drag-and-drop.html\">Google</a> and <a href=\"https://techcrunch.com/2019/05/02/microsoft-launches-a-drag-and-drop-machine-learning-tool-and-hosted-jupyter-notebooks/\">Microsoft</a>. As we saw from the recent O’Reilly survey, data preparation and cleaning still take up a lot of time that data professionals don’t enjoy. For this reason, it’s exciting that we’re now starting to see headway in automated tooling for data cleaning and preparation. It will be interesting to see how this space grows and how the tools are adopted.</p>\n<p>A bright future would see data preparation and data quality as first-class citizens in the data workflow, alongside machine learning, deep learning, and AI. Dealing with incorrect or missing data is unglamorous but necessary work. It’s easy to justify working with data that’s obviously wrong; the only real surprise is the amount of time it takes. Understanding how to manage more subtle problems with data, such as data that reflects and perpetuates historical biases (for example, real estate redlining) is a more difficult organizational challenge. This will require honest, open conversations in any organization around what data workflows actually look like.</p>\n<p>The fact that business leaders are focused on predictive models and deep learning while data workers spend most of their time on data preparation is a cultural challenge, not a technical one. If this part of the data flow pipeline is going to be solved in the future, everybody needs to acknowledge and understand the challenge.</p>\n<p><em>Many thanks to Angela Bassa, Angela Bowne, Vicki Boykis, Joyce Chung, Mike Loukides, Mikhail Popov, and Emily Robinson for their valuable and critical feedback on drafts of this essay along the way.</em></p>\n<hr>\n<aside data-type=\"sidebar\">\n<p id=\"_ftn1\">\n<p><a href=\"#F1\"><sup>[1]</sup></a> For example, let’s say that you have existing data on how many users on your e-commerce website have clicked on items after a search. If you want to repurpose this data later on to rank your website’s search results, you need to correct for the bias introduced by the initial order when the data was collected.</p>\n<p id=\"_ftn2\">\n<p><a href=\"#F2\"><sup>[2]</sup></a> For example, Mikhail Popov, a data analyst at the Wikimedia Foundation, told me that they’re still getting new descriptive analyses out of years of existing data to get new insights on their users (especially editors) and trends. As a specific example: one of their biggest data sources is editing history across all their projects, publicly available at <a href=\"https://dumps.wikimedia.org/other/analytics/\">Analytics Datasets</a>, which they use to answer ad-hoc questions like &#8220;across the 300 languages of Wikipedia, what % of newly registered accounts make an edit in their first 24 hours?&#8221; or to look at how readership traffic (pageviews also available publicly) has correlated historically with editing activity – which are all descriptive insights into their many communities.</p>\n<p id=\"_ftn3\">\n<p><a href=\"#F3\"><sup>[3]</sup></a> Related is the supreme focus on “big data.” “Small data”, when collected in a principled, thoughtful manner can have a lot of signal. Look no further than the fact that <a href=\"https://www.scientificamerican.com/article/howcan-a-poll-of-only-100/\">a poll of only 1,004 Americans represents 260 million people with only a 3 percent margin of error</a>, when the sample is representative (this is rarely the case but there are sophisticated correction methods that can get experts close). Similarly, <a href=\"https://medium.com/ethnography-matters/why-big-data-needs-thick-data-b4b3e75e3d7\">“thick (or qualitative) data”</a> can often tell us more than merely collecting more and more “big data”.</p>\n<p id=\"_ftn4\">\n<p><a href=\"#F4\"><sup>[4]</sup></a> This is an example of what’s known as <a href=\"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002106\">p-hacking</a>.</p>\n<p id=\"_ftn5\">\n<p><a href=\"#F5\"><sup>[5]</sup></a> To paraphrase Hadley Wickham’s rendition of Tolstoy in <a href=\"https://vita.had.co.nz/papers/tidy-data.pdf\">this paper</a>.</p>\n<p id=\"_ftn6\">\n<p><a href=\"#F6\"><sup>[6]</sup></a> In which 29 expert teams are given “the same data set to address the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players.” 69% said “yes” while 31% said “no”. What’s even more concerning is that most teams were even more confident of their own results after seeing the other teams’ analyses. According to the paper, “These findings suggest that significant variation in the results of analyses of complex data may be difficult to avoid, even by experts with honest intentions.”</p>\n<p id=\"_ftn7\">\n<p><a href=\"#F7\"><sup>[7]</sup></a> Yet another benefit is that building such automated data preparation pipelines is essentially a form of preregistering analytical techniques (specifying your methodology before actually doing it so you can’t alter it as a function of what you find in your data), which also reduces human bias. More and more research scientists are advocating for preregistration, particularly with <a href=\"https://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970\">the ongoing reproducibility crisis in scientific research</a>, along with its <a href=\"http://theconversation.com/sciences-credibility-crisis-why-it-will-get-worse-before-it-can-get-better-86865\">credibility crisis</a>.</p>\n<p id=\"_ftn8\">\n<p><a href=\"#F8\"><sup>[8]</sup></a> With automated machine learning packages such as <a href=\"https://epistasislab.github.io/tpot/\">TPOT</a> and drag-and-drop interfaces like <a href=\"https://techcrunch.com/2019/05/02/microsoft-launches-a-drag-and-drop-machine-learning-tool-and-hosted-jupyter-notebooks/\">Azure’s automated machine learning tool</a>.</p>\n<p id=\"_ftn9\">\n<p><a href=\"#F9\"><sup>[9]</sup></a> Such as <a href=\"https://rmarkdown.rstudio.com/\">R Markdown</a> and <a href=\"https://jupyter.org/\">Jupyter Notebooks</a>.</p>\n<p id=\"_ftn10\">\n<p><a href=\"#F10\"><sup>[10]</sup></a> For example, if you’re building a spam detection model, then you need to feed the model both spam and non-spam emails, labelled correctly as “spam” or “non-spam” (called training data as you use it to train your model). To see how important the challenge of getting good quality labelled data, look no further than data labelling start-up <a href=\"https://techcrunch.com/2019/08/05/scale-ai-and-its-22-year-old-ceo-lock-down-100-million-to-help-label-silicon-valleys-data/\">Scale AI’s recent $100 million Series C funding round</a>, which brought their valuation past $1 billion (also note that Scale AI is still using humans to label their data on the back end).</p>\n</aside>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/Pt-JBUG44GM\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 24 March 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/1Vby7nmqKsw/\n<ol>\n<li><a href=\"https://twitter.com/muratdemirbas/status/1242185716093853697\">Potential Distributed Reading Group on Distributed Systems</a> &#8212; for some folks, this will be a great time to start reading groups to work through papers. You&#8217;ll never get a time with less physical distraction. (Just remember to ration your socials time or you and your time will vanish into the maelstrom.)</li>\n<li><a href=\"https://meet.jit.si/\">Jitsi Meet</a> &#8212; <a href=\"https://github.com/jitsi\">open source</a> videoconferencing.</li>\n<li><a href=\"http://pigweed.googlesource.com/\">Pigweed</a> &#8212; <i>open source collection of [&#8230;] modules built to enable faster and more reliable development on 32-bit microcontrollers.</i> See also <a href=\"https://opensource.googleblog.com/2020/03/pigweed-collection-of-embedded-libraries.html\">Google Open Source blog</a>)</li>\n<li><a href=\"https://www.fastbuild.org/\">FASTBuild</a> &#8212; <i>a high-performance, open source build system for Windows, Linux, and OS X. It supports highly scalable compilation, caching, and network distribution. From the largest studios in the world to the smallest independent developers, FASTBuild is used in production every day to develop for PC/Mac/Linux, Consoles, Smartphones, and retro systems.</i></li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/1Vby7nmqKsw\" height=\"1\" width=\"1\" alt=\"\"/>\n3 ways to confront modern business challenges\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/_YW6drzYyR4/\n<p>I interviewed four business leaders in late 2019 to get their perspectives on the biggest obstacles and opportunities organizations are facing.</p>\n<p><a href=\"https://www.oreilly.com/radar/strong-leaders-forge-an-intersection-of-knowledge-and-experience\">Craig Lemasters</a> was the president and CEO of Assurant Solutions. Under his leadership, Assurant Solutions doubled in size to $4B, underwent a digital transformation to expand an offering of risk management solutions in the connected living space, and became established in 25 new markets around the world. After Lemasters left Assurant, he bought a company called GXG where, as the chief executive officer, he focuses on accelerating the growth of companies through rapid-cycle learning. (Disclosure: GXG is a partner of Science House, a consultancy I co-direct.)</p>\n<p><a href=\"https://www.oreilly.com/radar/leaders-need-to-mobilize-change-ready-workforces\">Jen Bruno</a> is the SVP of culture and human capital at LPL Financial, a firm founded to help entrepreneurial financial advisors offer independent financial guidance. Early in her career, Bruno was a florist who dreamed of working at the Walt Disney company. The dream became reality. (Disclosure: LPL is a client of my consultancy.)</p>\n<p><a href=\"https://www.oreilly.com/radar/an-enterprise-vision-is-your-companys-north-star\">Dana Codispoti</a> is the head of HR transformation at AIG. Previously, she worked at BNY Mellon and Morgan Stanley, and in multiple industries spanning consumer products, pharmaceuticals, and hospitality. With an engineering background and a mind for data and analytics, Codispoti is adept at leading change in processes that have scaled across large companies, with an eye for both humanity and technology.</p>\n<p><a href=\"https://www.oreilly.com/radar/great-leaders-inspire-innovation-and-creativity-from-within-their-workforces\">James Jorasch</a> is the founding CEO of Science House, a New York-based consultancy that I co-direct. For 14 years prior to founding Science House, Jorasch was the head of inventing at Walker Digital. He’s a named inventor on more than 750 patents, including the patents at the core of Priceline, and his innovation work spans many industries, including retail, health care, and gaming.&nbsp;</p>\n<p>Below, you’ll find notable themes that emerged during the discussions. You can see the full interviews <a href=\"https://www.oreilly.com/radar/tag/big-systemic-thinking/\">here</a>.</p>\n<h2>Continuous learning and continuous improvement</h2>\n<p>When people ask Craig Lemasters how long he ran Assurant Solutions, he says 44 quarters rather than 11 years.</p>\n<p>“That’s how we think,” he said. “How do you free up time to think beyond a quarter or two or a year or two? We can do that. We can get to that place.”</p>\n<p>But when Assurant’s distribution model—big box retailers—started collapsing, Lemasters wondered how he would shape the company’s future while focusing on the short term.</p>\n<p>He knew it started with him as a CEO, but he didn’t know that other “lonely CEOs” were stuck in the same place. He engaged GXG (a company he later purchased) to help him over the hurdle by exposing him to the wisdom of others who navigated the same path. Continuous learning, especially from others who have developed wisdom from being in the same position, helps leaders get unstuck and become more agile.</p>\n<p>Continuous learning is also required to understand the relationship between humanity and technology.</p>\n<p>“Technology is driving and enabling at the same time,” Dana Codispoti said. “It’s a matter of how we use it. We need the human mind.”</p>\n<p>From an HR perspective, Codispoti said, we need to go faster to get our minds ready. Companies should understand, among other things, the power of robotics and AI, along with the art of the possible, “while they are fixing the foundation,” Codispoti said. Too often, companies try to grasp at the next big thing without laying the foundation for learning first.</p>\n<p>“There’s a whole world of things to learn,” Codispoti said. “I look at it as an enabler.”</p>\n<p>Jen Bruno agreed. “Every business professional should consider themselves a continuous learner,” Bruno said. She noted that people need to be “change ready,”and get better at applying what they know in different areas for the greater good. Every company should get employees excited and engaged to learn because change keeps happening “faster than we can imagine.”</p>\n<p>What makes a company a world-class learning organization?</p>\n<p>“When people truly are in a mindset of continuous improvement,” Bruno said. “We can learn something from every person we meet. That’s good for business. Share talent and knowledge, and foster collaboration for greater outcomes.”</p>\n<h2>Business lessons from technology processes</h2>\n<p>Companies need a clear vision in a complex world, Codispoti said. “Create a north star that people can align to, that gets people excited about solving a problem,” she said. “Without it, they spin and spin and spin. If people don’t know how their work is value-add, you lose engagement. It ties to the enterprise vision.”</p>\n<p>As more companies shift to Agile software development and, more importantly, an Agile mindset, the culture of companies has begun to mimic the iterative nature of technology. Smaller, granular pieces need to communicate with each other in the most effective way. This is true for microservices architecture, for example, and for people across teams.</p>\n<p>Codispoti said that creating a process requires an end-to-end vision, but silos often lead to fragments being created piecemeal. “Once [a broken process] is enabled through technology and you want to make changes, it’s hard and people blame the technology,” Codispoti said.</p>\n<p>Huge problems, James Jorasch said, need to be “distilled down to something that a client can understand and take action on.” Science House works with large enterprise clients, often on transformational software projects that can span years. The parallel between technology and people applies here, too.&nbsp; Making complex projects and transformations more modular creates a parallel impact on people and organizational structures, changing the nature of their responsibilities and spans of control. Bringing modular pieces together, whether the modules are temporal or functional, changes the role of traditional hierarchical organizational structures as they adapt to increased complexity.</p>\n<p>“The nature of management is changing, and not just because of Agile,” Jorasch said. “It’s a different way of thinking. Managers have gone from managing people to managing processes, mindsets, skills, and problems.”</p>\n<p>They also need to manage information flow into and from these groups.</p>\n<p>“There are lessons learned from tech that will be applicable to people,” Jorasch said. “Where are the bottlenecks? What are the styles of thinking you need? Focus on what’s essential. How do you get the right information to the right person at the right time?”</p>\n<h2>Humility is an asset</h2>\n<p>One of the themes that came throughout the interviews was the need for humility. Without it, companies tend to stay inward looking and siloed.</p>\n<p>“Companies struggle with cross-collaboration,” Codispoti said. “People tend to work in silos. They need to partner with experts in other areas. They don’t need to do it on their own, and they’re missing opportunities.”</p>\n<p>Bruno and Lemasters both cited humility as a critical trait for leaders. Humility gives people the energy to cross over into an unfamiliar area, Bruno said, and creates the capacity for empathy.</p>\n<p>“I look for the humility quotient,” Lemasters said. “A willingness for leaders to embrace outside thinking and ideas. Some would call it criticism, but it isn’t. Have the humility to accept people who have wisdom in their swim lanes. We learn quickly. There’s goodness in humanity, and people want to help.”</p>\n<p>Jorasch often cites the need for not taking ourselves too seriously during innovation sessions, for example, because one person’s silly or half-formed comment gives another person a great idea. Humility helps prevent people from having to project authority or expertise every time they speak. With humility comes better listening; more honest, authentic input; less defensiveness; and more collaboration based on respect for one’s peers’ opinions.</p>\n<p><a href=\"https://www.oreilly.com/radar/tag/big-systemic-thinking/\">Be sure to check out the full interviews for additional insights</a>.</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/_YW6drzYyR4\" height=\"1\" width=\"1\" alt=\"\"/>\nAn enterprise vision is your company’s North Star\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/UNR8GT2bHms/\n<p>Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with Dana Codispoti, head of HR Transformation at AIG, about how to address the human factor in business transformations to keep employees engaged and connected to the overall business mission. They also discuss the future of the human-technology relationship and why technology should be viewed as an enabler rather than a replacement for human contributions.</p>\n<p>Here are some highlights from their conversation:</p>\n<p>With technology iterating and improving at ever-increasing speeds, companies are challenged with how best to utilize data and analytics to inform new technology decisions. Codispoti stresses that it&#8217;s imperative to start with the foundation, the &#8220;building blocks,&#8221; and not jump straight to the innovation or &#8220;shiny object.&#8221; The key, Codispoti notes, to successfully navigating new technologies and processes lies with the people and their engagement with the company&#8217;s overall vision. &#8220;One of the most important things you need to do in technology initiatives,&#8221; she says, &#8220;is to create a vision to help people understand what they are driving toward. I see a lot of work being done in the trenches where people don&#8217;t see the bigger picture—everybody&#8217;s working on an individual project or set of projects, but they can&#8217;t understand how it fits into a broader picture. If there isn&#8217;t a vision for the company, create one, or create a North Star that people can align to. That gets people excited about a problem; it gets people excited about participating in the solution. &#8230; If people don&#8217;t know why their work is value add and how it ties to a broader picture, you lose engagement.&#8221; (<a href=\"#t=118\">01:58</a>)</p>\n<p>Mitigating risk is a hurdle for any company facing changing technology and business processes. Codispoti says the solution lies in breaking out of silos and comfort zones to leverage the expertise of colleagues across an organization. &#8220;I find companies struggle with cross collaboration,&#8221; She explains. &#8220;If someone&#8217;s, for example, working in a business, they need to leverage their partners. In my case, it would be HR, finance, the risk organization, the audit, and legal folks. I think people tend to work in silos, and they need to lift up their heads, look around and say, these people are experts in those areas. Talk through and partner with them to understand the problems they&#8217;re solving for so that they can help point out the risk. People think they need to do all that on their own, and they&#8217;re missing opportunities to mitigate risk. &#8230; It&#8217;s about breaking through silos and pointing out how collaboration is additive—when you work in teams, you get more. People also have a mindset that &#8216;I need to fix this for my area,&#8217; and it&#8217;s not an enterprise mentality. As you go through these transformations, it&#8217;s about trying to influence the culture to say you wear two hats: one is for whatever you&#8217;re working on and one is for the enterprise, and lead with that enterprise mindset.&#8221; (<a href=\"#t=328\">05:28</a>)</p>\n<p>Looking toward the future and humanity&#8217;s evolving relationship with technology, Codispoti stresses that machines will always need people and humans should not fear being replaced. &#8220;There&#8217;s a large level of awareness around technology driving the future in a lot of ways, but I think there&#8217;s also fear that technology is going to take over humanity—we know that&#8217;s not the case,&#8221; She says. &#8220;You need both. &#8230; At the end of the day, the work is in the work, in the process, in the culture, in the people, and then technology becomes an enabler. So, it&#8217;s driving and enabling at the same time, but I think everybody needs to co-exist. Nobody&#8217;s going to be wiped out by technology; it&#8217;s a matter of how we use it and we recognize that it can do things faster than we can, but in some ways we need the human mind to enhance whatever technology is doing.&#8221;(<a href=\"#t=880\">14:40</a>)</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/UNR8GT2bHms\" height=\"1\" width=\"1\" alt=\"\"/>\nLeaders need to mobilize change-ready workforces\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/JICZx5XMzRM/\n<p>Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with Jen Bruno, SVP of culture and human capital at LPL Financial, about mobilizing a change-ready workforce, leadership rotation programs, and fostering continuous learning.</p>\n<p>Here are some highlights from their conversation:</p>\n<p>The reality, Bruno argues, is that businesses are in a state of change. And while humans tend to have a hard time with change, the time is ripe for people to take advantage of the coming changes to grow and develop. &#8220;Companies have a hard time mobilizing a workforce that is change-ready because people inherently want to do what they know; we build our careers on the skills that have allowed us to move to the next level. We&#8217;re at a time right now where people can look beyond that and use those skills in another department or a new area; crossing over can enable the imagination, the creativity, and the innovation that companies so desperately want in order to grow and best serve their customers. It&#8217;s an exciting opportunity for people to think of themselves as change agents and be willing to crossover and work in different areas, leveraging what they know and learning what they don&#8217;t know. (<a href=\"#t=383\">06:23</a>)</p>\n<p>Bridging culture gaps—and communication gaps— between departments is essential, Bruno says, to enable teams to work together efficiently and effectively to reap better outcomes. Creating these working relationship bridges, she argues, starts at the top. &#8220;I&#8217;m a big fan of having leaders rotate through the different jobs within an organization. The true way to learn empathy is to do the work yourself and understand what the people in specific roles go through on a day-to-day business. You&#8217;ll have a better understanding of the business operation as a whole. I think it makes you a better business leader because it does help develop that empathy, and it allows you to build your network of people internally, and that&#8217;s really important too.&#8221; (<a href=\"#t=656\">10:56</a>)</p>\n<p>The key to weathering the transition to what work will become in the future, Bruno argues, is continuous learning. &#8220;Every business professional should consider themselves a continuous learner. There is so much to learn from other organizations that have similar situations, from business people we have things in common with, and it&#8217;s important to be change-ready and willing to leverage what you know in different areas for the greater good. We should all be preparing ourselves as much as we can so we can bring value to the companies we work for, whatever that might look like.&#8221; To that end, it&#8217;s important for learning and development approaches to evolve, she says, to be more effective in the face of the changes coming our way. &#8220;I hope I never see a PowerPoint presentation being held up in a room for an hour while somebody talks to an audience, because that&#8217;s not really fostering learning in a way that gets people excited and engaged.&#8221; (<a href=\"#t=839\">13:59</a>)</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/JICZx5XMzRM\" height=\"1\" width=\"1\" alt=\"\"/>\nGreat leaders inspire innovation and creativity from within their workforces\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/Uz6cibmqT1I/\n<p>Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with James Jorasch, founding CEO of Science House, about the importance of innovation and how to inspire and harness the creative talent in your workforce.</p>\n<p>Here are some highlights from their conversation:</p>\n<p>It&#8217;s important, Jorasch says, to appropriate the techniques of innovation that bring together ideas from disparate sources and apply those to people in your company. &#8220;We need people also to collide; people with different perspectives, different concepts, different ideas need to come together over and over again.&#8221; He also notes that invention isn&#8217;t only an innate talent; it can also be a learned skill. &#8220;We train many people, and I would say that everyone can invent. Believe in yourself, relax, find a problem, come up with a solution, keep going. It&#8217;s not a complicated thing. Just believe in yourself and try. Trying is probably 90% of it.&#8221; (<a href=\"#t=315\">05:15</a>)</p>\n<p>To effectively get the creative juices flowing, Jorasch recommends ditching large meetings, as they allow people to avoid contributing by simply hiding in the crowd. &#8220;When you bring a meeting down to just two people, there&#8217;s no hiding, there&#8217;s no, &#8216;Well, I&#8217;m going to be on my cell phone. We&#8217;re working on this.&#8217; There&#8217;s no getting away from what you&#8217;re there to do. It is that sense of focus that you get from two people that really ignites the imagination process.&#8221; That focus, he says, is key to addressing the new challenges coming. &#8220;There&#8217;s a lot that can be accomplished from creative pairs. It is a purpose driven, very focused way of tackling problems, and tackling very complicated and very deep problems. It takes away everything else—you&#8217;re lasered in on that one thing for, potentially, hours at a time. And that&#8217;s what it takes, right? 10-second solutions are not going to cut it in this world.&#8221; (<a href=\"#t=449\">07:29</a>)</p>\n<p>The data Science House has gathered from large companies over the years has afforded interesting insights into the changing nature of management, Jorasch says. For instance, in our increasingly Agile approaches to business and systems, the well-established, traditional hierarchy of individual contributor, manager, director, VP, SVP, and so forth, is no longer a great fit. &#8220;We have rules around the standard hierarchy,&#8221; he observes. &#8220;We don&#8217;t really have rules, per se, around Agile. And we&#8217;re seeing a collision of managers and directors now saying, &#8216;I&#8217;ve been a director for 15 years—what&#8217;s my role now with these Agile teams?&#8217; People are starting to question what it is they&#8217;re supposed to do.&#8221; And it&#8217;s not only evolving cultures and approaches challenging leaders, but evolving technologies, too. &#8220;The idea of using microservices, for example, is a very different way of thinking,&#8221; he notes. &#8220;Those managers and directors and VPs are evolving from managing people to managing a process or managing mindsets and skills of the workers, and managing problems or managing the information flow into these groups. That&#8217;s going to require a very different set of skills and new types of training.&#8221; (<a href=\"#t=790\">13:10</a>)</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/Uz6cibmqT1I\" height=\"1\" width=\"1\" alt=\"\"/>\nStrong leaders forge an intersection of knowledge and experience\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/cQpks9Bw11E/\n<p>Rita J. King, co-director and EVP for business development at Science House, recently conducted a series of interviews with business leaders, exploring the challenges and hurdles companies face in evolving business landscapes. In this interview, King chats with Craig Lemasters, CEO of Global Executive Group, about what companies face when navigating the digital transformation. They also talk about the power of humility and what it means to be an agile leader.</p>\n\n\n\n<p>Here are some highlights from their conversation:</p>\n\n\n\n<p>&#8220;Digital transformation&#8221; means something different to every company. The key to successfully traversing the transformation, Lemasters explains, is to identify specifically what it means to a particular company. In his case, he was running a global insurance company called Assurance Solutions, and he identified two specific areas of focus: &#8220;we knew we needed to have a digital relationship with the end consumer. &#8230; [And] we knew we needed to have some type of digital distribution model.&#8221; (<a href=\"#t=153\">02:33</a>)</p>\n\n\n\n<p>To succeed in a new space, Lemasters came to realize, requires both knowledge and experience—an intersection Lemasters uses to define &#8220;wisdom.&#8221; This realization led to Lemasters&#8217; big &#8220;ah-ha!&#8221; moment: &#8220;The stumbling block for digital was, quite frankly, that we didn&#8217;t have either knowledge or experience on digital, and it started with me. I mean, it started with me even as a CEO. I started looking at my team and realized none of us really had a lot of knowledge and experience on this thing called digital. The whole &#8220;ah-ha&#8221; experience was that speed bump. What if we inserted knowledge and experience into the room—could we get to the point much quicker? That&#8217;s what&#8217;s become my passion &#8212; how do we interject this thing called wisdom into the conversation, into the process, just to get us there faster?&#8221; (<a href=\"#t=340\">05:40</a>)</p>\n\n\n\n<p>Lemasters argues that humility is key to being a strong, agile leader. Being able to make decisions at the rate of speed required today takes, if not a village, at least <em>some</em> additional expertise. &#8220;The &#8216;humility quotient&#8217; is the willingness for leaders to literally embrace outside thinking,&#8221; Lemasters explained. &#8220;Some would call it criticism; it really isn&#8217;t. I mean, most of this work is about the unknown, and you just haven&#8217;t been there yet. What I found is if we just have enough humility to accept that and actually invite in some people who have the wisdom in these swim lanes, increasing the speed at which we learn, we get over ourselves pretty quickly.&#8221; (<a href=\"#t=676\">11:16</a>)</p>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/cQpks9Bw11E\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 23 March 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/vMm8_OsqJ-4/\n<ol>\n<li><a href=\"https://arxiv.org/abs/2003.07082\">Stanza: A Python Natural Language Processing Toolkit for Many Human Languages</a> &#8212; <i>Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition.</i> Code and models available for 66 languages.</li>\n<li><a href=\"https://matt.ucc.asn.au/dropbear/dropbear.html\">Dropbear SSH</a> &#8212; <i>Dropbear is a relatively small SSH server and client. It runs on a variety of POSIX-based platforms. Dropbear is open source software, distributed under an MIT-style license. Dropbear is particularly useful for &#8220;embedded&#8221;-type Linux (or other Unix) systems, such as wireless routers.</i></li>\n<li><a href=\"https://github.com/tripleblindmarket/private-kit\">Private Kit</a> &#8212; <i>an open source privacy preserving system</i> for logging locations and sharing with researchers on your own terms—e.g., to track contact in coronavirus without losing control.</li>\n<li><a href=\"https://keleshev.com/eax-x86-register-meaning-and-history/\">Why the EAX Register is Called That</a> &#8212; some neat history, showing how deep the roots of backward compatibility are.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/vMm8_OsqJ-4\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 20 March 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/GGLbZECmPJI/\n<ol>\n<li><a href=\"https://www.engadget.com/2020/03/19/nascar-esports-racing-series-fox/\">NASCAR Replaces Canceled Races with Esports Featuring Pro Drivers</a> (Engadget) &#8212; the world is getting weirder.</li>\n<li><a href=\"https://www.reuters.com/article/us-google-antitrust-focus/google-critics-see-its-firebase-tools-as-another-squeeze-play-idUSKBN2161GA\">Firebase Scrutinized By Antitrust Regulators</a> &#8212; <i>Firebase tools give Google, the internet’s top ad seller, information on what consumers are doing inside apps that it can exploit to target ads to users, according to makers of Firebase alternatives.</i></li>\n<li><a href=\"https://mads-hartmann.com/sre/2020/03/05/journey-into-observability-glitchs-journey.html\">Journey into Observability: Glitch&#8217;s Story</a> (Mads Hartmann) &#8212; an easy-to-follow and honest recap of their journey from lots of logging to being able to look at heatmaps and resolve more problems.</li>\n<li><a href=\"https://www.hyphalmesh.com/\">Hyphal Mesh</a> &#8212; <i>30 mins. 2 convos, 1-on-1.</i> Nifty idea for connecting people in these weird times.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/GGLbZECmPJI\" height=\"1\" width=\"1\" alt=\"\"/>\n6 trends framing the state of AI and ML\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/fqGcC2mtuhI/\n<p id=\"F1\"><a href=\"https://www.oreilly.com/online-learning/\">O’Reilly online learning</a> is a trove of information about the trends, topics, and issues tech leaders need to know about to do their jobs. We use it as a data source for <a href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis/\">our annual platform analysis</a>, and we’re using it as the basis for this report, where we take a close look at the most-used and most-searched topics in machine learning (ML) and artificial intelligence (AI) on O’Reilly<a href=\"#_ftn1\"><sup>[1]</sup></a>.</p>\n<p>Our analysis of ML- and AI-related data from the O’Reilly online learning platform indicates:</p>\n<ul>\n<li>Unsupervised learning surged in 2019, with usage up by 172%.</li>\n<li>Deep learning cooled slightly in 2019, slipping 10% relative to 2018, but deep learning still accounted for 22% of all AI/ML usage.</li>\n<li>Although TensorFlow grew by just 3%, it, too, garnered 22% share of AI/ML usage in 2019.</li>\n<li>PyTorch looks like a contender: it posted triple-digit growth in usage share rates in both 2018 and 2019.</li>\n<li>Reinforcement learning fell by 5% in 2019; it’s up hugely—1,500+%—since 2017, however.</li>\n<li>Sustained strength in unsupervised learning, neural networks, reinforcement learning, etc., demonstrates that organizations are experimenting with advanced ML tools and methods.</li>\n</ul>\n<figure class=\"center\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/03/figure1-aiml-topic-usage-e1583525661870.png\" alt=\"AI/ML topics on the O’Reilly online learning platform with the most usage in 2019 (left) and the rate of change for each topic (right)\"><figcaption>Figure 1. AI/ML topics on the O’Reilly online learning platform with the most usage in 2019 (left) and the rate of change for each topic (right).</figcaption></figure>\n<h2>Growth in ML and AI is unabated</h2>\n<p>Engagement with the artificial intelligence topic continues to grow, up 88% in 2018 and 58% in 2019 (see Figure 1), outpacing share growth in the much larger machine learning topic (+14% in 2018, up 5% in 2019). Aggregating artificial intelligence and machine learning topics accounts for nearly 5% of all usage activity on the platform, a touch less than, and growing 50% faster than, the well-established “data science” topic (see Figure 2).</p>\n<p>Data engineering remains the largest topic in the data category with just over 8% usage share on the platform (Figure 2). But the data engineering share is down about 8% in 2019, mostly from declines in engagement with data management topics.</p>\n<figure class=\"center\"><img src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/03/figure2-high-level-trends-e1583525766237.png\" alt=\"High-level data topics on the O’Reilly online learning platform with the most usage (left) and and the rate of change for each topic (right).\"><figcaption>Figure 2. High-level data topics on the O’Reilly online learning platform with the most usage (left) and and the rate of change for each topic (right).</figcaption></figure>\n<h2>Unsupervised learning is growing</h2>\n<p id=\"F2\">Interest in the unsupervised learning topic increased significantly, with usage up by 53% in 2018 and by 172% in 2019<a href=\"#_ftn2\"><sup>[2]</sup></a> (see Figure 1). What’s driving this growth?</p>\n<p>First, for most people and most use cases, <em>supervised</em> learning serves as the default, assumed strategy for machine learning. That makes unsupervised learning worth noting as a separate topic, given the growth in engagement driven by more sophisticated users, improved tools, and use cases not easily addressed with supervised methods. By analogy, users are more apt to engage with specific supervised learning methods—e.g., linear and logistic regressions, support vector machines—than with the canonical topic of supervised learning itself.</p>\n<p>Unsupervised learning, by contrast, isn’t as well understood, even if the names of its methods—e.g., clustering and association—and its applications (neural networks) are familiar to many users.</p>\n<p id=\"F3\">In all likelihood, the surge in unsupervised learning activity on O’Reilly is being driven by a lack of familiarity with the term itself, as well as with its uses, benefits, requirements, etc. It’s likely, too, that the visible success of unsupervised learning in neural networks and deep learning<a href=\"#_ftn3\"><sup>[3]</sup></a> has helped spur interest, as has the diversity of open source tools, libraries, tutorials, etc., that support unsupervised learning. That some of these tools (<a href=\"https://scikit-learn.org/stable/\">scikit-learn</a>, <a href=\"https://en.wikipedia.org/wiki/PyTorch\">PyTorch</a>, and <a href=\"https://en.wikipedia.org/wiki/TensorFlow\">TensorFlow</a>) are also Python-based doesn’t hurt, either.</p>\n<h2>Usage in advanced techniques is up—mostly</h2>\n<p>It’s said that the success of <a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network#History\">neural networks</a> and, especially, <a href=\"https://en.wikipedia.org/wiki/Deep_learning#History\">deep learning</a>—neither of which is new—helped spur the resurrection of a number of other disused or neglected ideas.</p>\n<p>One example is <a href=\"https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf\">reinforcement learning</a>, which experienced an exponential spike in usage on the O’Reilly platform in 2018—growing by 1,612%—before regressing slightly (-5%) in 2019 (see Figure 1).</p>\n<p>Looking at AI/ML topic detail, we see usage in neural networks continuing its upward trend—up 52% in 2018; up 17% in 2019—but the related topic of deep learning dropped 10% in 2019. The drop in deep learning seems likely a function of inter-year noise and not evidence of an emerging trend, given the significant usage growth in 2018 (+52%). These closely related topics are popular: aggregating neural networks, deep learning, and TensorFlow usage nets nearly half (47%) of all AI/ML category usage, showing a slight decline (-3%) in 2019 after growing 24% in 2018.</p>\n<p id=\"F4\">In our “<a href=\"https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2020/\">AI adoption in the enterprise 2020</a>” survey, we found that deep learning was the most popular ML method among companies that are evaluating AI. Among companies using AI to support production use cases, deep learning was No. 2<a href=\"#_ftn4\"><sup>[4]</sup></a>. It might be that—at 1% of platform usage and 22% of all AI/ML usage—deep learning has approached its asymptote. Growth could be slow from here on out.</p>\n<h2>The rising AI/ML tide lifts (almost) all boats</h2>\n<p>Another topic showing consistent growth is natural language processing (NLP) (see Figure 1). Its growth rate isn’t spectacular—+15% in 2018, +9% in 2019—but NLP now accounts for about 12% of all AI/ML usage on O&#8217;Reilly. That’s about 6x the share of unsupervised learning and 5x the share of reinforcement learning usage.</p>\n<p>Interest in some methods or applications of ML seems to be waning, however. For example, the chatbots topic continues to decline, first by 17% in 2018 and by 34% in 2019. This is probably a reflection of the comparative maturity of the space. The chatbot was <a href=\"https://en.wikipedia.org/wiki/Chatbot#Development\">one of the first applications of AI</a> in experimental and production usage. This likely doesn’t portend the end of interactions with occasionally helpful—and <a href=\"https://www.nytimes.com/interactive/2018/02/21/technology/conversational-bots.html\">still sometimes horrifying</a>—customer service chatbots.</p>\n<p>Computer vision usage shows a slow decline, falling by 3% in 2018 and 2% in 2019. Probably more noise than trend, moreover, computer vision accounts for about twice as much usage activity as the fast growing unsupervised learning topic.</p>\n<h2>Python-based tools are ascendant in AI/ML</h2>\n<p>Reports of <a href=\"https://en.wikipedia.org/wiki/Torch_(machine_learning)\">Torch’s</a> death are <a href=\"https://github.com/torch/torch7\">somewhat misleading</a>. In fact, <a href=\"https://en.wikipedia.org/wiki/PyTorch\">PyTorch</a>—a <a href=\"https://en.wikipedia.org/wiki/Adapter_pattern\">wrapper</a> that permits users to call Torch’s ML libraries from Python—posted triple-digit growth in usage in just the last few years, surging by almost 400% in 2018 and by 111% in 2019 (see Figure 1). PyTorch’s popularity is probably a function of the success of Python itself, particularly for ML and AI: vanilla Torch uses <a href=\"https://en.wikipedia.org/wiki/Lua_(programming_language)\">Lua</a> as a wrapper to expose its core C libraries; PyTorch eschews Lua (in favor of Python) for the same purpose.</p>\n<p>Once you factor <a href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis/\">in the preeminence of Python</a>, the rising popularity of PyTorch <a href=\"https://madnight.github.io/githut/#/pull_requests/2019/4\">makes a lot of sense</a>.</p>\n<p id=\"F5\">This may have something to do with <a href=\"https://en.wikipedia.org/wiki/TensorFlow\">TensorFlow</a>’s outsized presence in ML, too. In 2019, it accounted for 1% of all usage, about a third as much usage as machine learning and 22% of all AI/ML usage. TensorFlow isn’t a Python-exclusive technology—it exposes stable C <em>and</em> Python APIs<a href=\"#_ftn5\"><sup>[5]</sup></a>—but its users tend to be Python-savvy and its related projects, patterns, tutorials, etc., disproportionately involve Python.</p>\n<p id=\"F6\">The results of our recent <a href=\"https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2020/\">AI adoption survey</a> underscore this trend. TensorFlow was also the No. 1 ML technology in the survey, while PyTorch came in at No. 4. Two additional Python-based tools (<a href=\"https://scikit-learn.org/stable/\">scikit-learn</a> and <a href=\"https://en.wikipedia.org/wiki/Keras\">Keras</a>) also cracked the top five<a href=\"#_ftn6\"><sup>[6]</sup></a>. We know from <a href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis/\">our annual </a><a href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis/\">analysis of usage and search on the O’Reilly online learning platform</a> that one of Python’s fastest areas of growth is in ML- and AI-related development. The prominence of these and other Python-related tools attests to this fact.</p>\n<h2>What’s in a name? The shift to “artificial intelligence”</h2>\n<p>Does the growing engagement in neural networks, reinforcement learning, unsupervised learning, and the increased focus on putting models into production augur a shift in how practitioners in the space frame what they do? We think yes, with practitioners increasingly calling their work “artificial intelligence”—a notion supported by the growth in AI usage on O’Reilly, the increasing embrace of sophisticated tools, and the empirical trend of putting those tools into production, which we see in our AI surveys.</p>\n<p>AI has always been the general term for building intelligent systems, with machine learning covering the more specific case of building software that learns and modifies its outputs without the need for additional coding. Here are some examples of what, when viewed in aggregate, helps explain why those in the space think machine learning doesn’t quite cover all they do:</p>\n<ul>\n<li>Machine learning produces models that are widely used in the automation of tasks such as credit scoring, fraud detection, recommendation engines, etc., but ML models are increasingly deployed in libraries or services and exposed via APIs—such that a model or ensemble of models can be invoked by any valid user, program, or service.</li>\n<li>To some extent, models can be built with an aim toward reuse, such that, for example, a data profiling model can be invoked and used to support different business use cases.</li>\n<li>Tools and techniques like reinforcement learning and unsupervised learning open up new use cases, including decision support, interactive games, real-time retail recommendation engines, and data discovery.</li>\n<li>The focus of usage—and, with it, design and development—is shifting from the specific to the generalized. ML libraries and services have the potential to transform the software products we deliver, the processes that consume them, and—concomitant with this—the experiences of users, customers, partners, etc., alike.</li>\n<li>This isn’t <em>just</em> ML; it’s a kind of AI: a new way of thinking about and applying machine intelligence. It has implications for software architecture, infrastructure, and operations—for virtually all domains.</li>\n</ul>\n<p>So, this isn’t <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\">artificial general intelligence</a>, but AI as the application of machine learning to solve problems, increase productivity, accelerate processes, and in many cases deliver wholly new products and services.</p>\n<h2>Concluding thoughts</h2>\n<p>As organizations adopt analytic technologies, they’re discovering more about themselves and their worlds. Adoption of ML, especially, prompts people at all levels of an organization to start asking questions that challenge in different ways what the organization <a href=\"https://www.eckerson.com/articles/the-data-modeling-conundrum-do-you-create-a-model-from-the-real-or-the-ideal\">thinks it knows about itself</a>.</p>\n<p>An organization’s use of ML tools and techniques, and the contexts in which it uses them, will tend to change, too. For example, the techniques of supervised learning are useful for classifying known-knowns and for elucidating certain kinds of known-unknowns; they’re unsuitable for surfacing <a href=\"https://scet.berkeley.edu/artificial-intelligence-and-the-rumsfeld-test/\">unknown-unknowns</a>, however. Unsupervised techniques are better for this. Not for classifying, synthesizing, or <em>understanding</em> unknown-unknowns—that’s the responsibility of human intelligence—but for <em>surfacing them in the first place</em>. The upshot is that adopters are integrating <em>both</em> kinds of learning into their ML practices. They’re also apt to experiment with advanced ML methods—such as deep learning—that have applications for both supervised and unsupervised learning. In fact, we found in our AI adoption survey that those new to ML are almost as likely to experiment with deep learning as mature adopters.</p>\n<p>Right now, companies are successfully using ML to ferret out known-unknowns and unknown-unknowns in their business worlds. They’re instantiating what they discover, analyze, and understand about their worlds in models. Some are also starting to incorporate these models into automated, quasi-intelligent products, services, and software. All of this partakes of the propulsive logic of self-discovery. It’s at the root of a question Plato first formulated almost 2,500 years ago: “But how will you look for something when you don’t in the least know what it is?” he has Meno ask Socrates. “How on earth are you going to set up something you don’t know as the object of your search?”</p>\n<p>Philosophical tradition <a href=\"https://plato.stanford.edu/entries/epistemic-paradoxes/#MenParInqPuzAboGaiKno\">treats this question as a paradox</a>. It’s also possible to see it as an inquiry into how an object of knowledge augments and transforms <em>itself</em>. With ML and AI, we’re training machines to surface new objects of knowledge that help us as we learn to ask new, different, and sometimes difficult questions about ourselves. By all indications, we seem to be having some success with this.</p>\n<hr>\n<aside data-type=\"sidebar\">\n<p id=\"_ftn1\"><a href=\"#F1\"><sup>[1]</sup></a> This article is based on non-personally-identifiable information about the top search terms and most-used topics on O’Reilly online learning. We compared aggregated data for the last three years; a full year of data for 2017 and 2018, and through the end of October for 2019.</p>\n<p id=\"_ftn2\"><a href=\"#F2\"><sup>[2]</sup></a> Overall usage share for the unsupervised learning topic on O’Reilly more than tripled year-over-year. For the platform as a whole, unsupervised learning accounts for an extremely small percentage of usage activity—&lt; 0.1%. Share for specific applications (e.g., deep learning) is much higher.</p>\n<p id=\"_ftn3\"><a href=\"#F3\"><sup>[3]</sup></a> Neural networks and deep learning are not exclusive to unsupervised learning. However, research into either topic is likely to surface the connection to unsupervised learning, as well as to reinforcement learning, transfer learning, etc.</p>\n<p id=\"_ftn4\"><a href=\"#F4\"><sup>[4]</sup></a> In “<a href=\"https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2020/\">AI adoption in the enterprise 2020</a>” we found that two thirds of mature AI adopters and 55% of organizations that are evaluating AI are using deep learning.</p>\n<p id=\"_ftn5\"><a href=\"#F5\"><sup>[5]</sup></a> TensorFlow supports stable C and Python APIs. The project supports API-level access in other languages—including C++, Go, Java, and JavaScript—<a href=\"https://www.tensorflow.org/guide/versions\">but does not guarantee compatibility with them</a>.</p>\n<p id=\"_ftn6\"><a href=\"#F6\"><sup>[6]</sup></a> Neither scikit-learn nor Keras generated significant activity on the O’Reilly platform itself, however. By contrast, in our <a href=\"https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2020/\">2020 AI adoption survey</a>, the scikit-learn library (No. 2) was used by about 48% of respondents in 2019 and 2020. Keras, a Python library used in developing neural networks, climbed to No. 5 in the 2020 edition of the survey; it was used by more than one-third of all respondents.</p>\n</aside>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/fqGcC2mtuhI\" height=\"1\" width=\"1\" alt=\"\"/>\nFour short links: 19 March 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/DoxRc12sFEA/\n<ol>\n<li><a href=\"https://geirsson.com/open-source.html\">Dos and Don&#8217;ts in Open Source</a> (Olaf Geirsson) &#8212; really useful advice to would-be contributors and project owners. <i>It&#8217;s tempting to respond to a welcome contribution with a quick, &#8220;This looks amazing, I will review tomorrow!&#8221; Consider giving a thumbs-up reaction instead and wait with commenting until you complete the review. Promises are estimates and estimates are hard. Unless I&#8217;m bound by a paid contract, I try to avoid promising my future time no matter how confident I am about delivering on the promise.</i></li>\n<li><a href=\"https://twitter.com/ubiquity75/status/1240076628408930304\">Thread on AI Content Moderation</a> (Sarah T. Roberts) &#8212; content moderators can&#8217;t work from home (she explains why), so Facebook is leaning hard on its AI systems, which are triggering false positives (censoring things it shouldn&#8217;t) and people are noticing. It will be interesting to see how the systems improve, how people react, and whether we go back to human teams of moderators at the same scale we had before (with the accompanying mental damage to them).</li>\n<li><a href=\"https://twitter.com/alexlmiller/status/1240073789586714626\">Zoom Community Calls</a> (Alex L. Miller) &#8212; how to configure your Zoom session for maximum audience fun but minimal exposure to trolling.</li>\n<li><a href=\"https://twitter.com/KateMontgom/status/1240032242002321408\">How to Survive Self-Isolating Without Losing It</a> (Kate Montgomery) &#8212; from someone with years of experience. There are now many of these guides to maintaining mental health during isolation, and you should read a few (before the isolation starts, if you&#8217;re in a position to do so, to prep for it). They&#8217;re also worth reading if you now work from home, because it can end up being remarkably similar.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/DoxRc12sFEA\" height=\"1\" width=\"1\" alt=\"\"/>\nAI adoption in the enterprise 2020\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/51j23cc8IHc/\n<p>Last year, when we felt interest in artificial intelligence (AI) was approaching a fever pitch, we created a survey to ask about AI adoption. When we analyzed the <a href=\"https://www.oreilly.com/data/free/ai-adoption-in-the-enterprise.csp\">results</a>, we determined the AI space was in a state of rapid change, so we eagerly commissioned a follow-up survey to help find out where AI stands right now. The new survey, which ran for a few weeks in December 2019, generated an enthusiastic 1,388 responses. The update sheds light on what AI adoption looks like in the enterprise— hint: deployments are shifting from prototype to production—the popularity of specific techniques and tools, the challenges experienced by adopters, and so on. There’s a lot to bite into here, so let’s get started.</p>\n<p>Key survey results:</p>\n<ul id=\"F1\">\n<li>The majority (85%) of respondent organizations are evaluating AI or using it in production<a href=\"#_ftn1\"><sup><sup>[1]</sup></sup></a>. Just 15% are not doing anything at all with AI.</li>\n</ul>\n<ul>\n<li>More than half of respondent organizations identify as “mature” adopters of AI technologies: that is, they’re using AI for analysis or in production.</li>\n<li>Supervised learning is the most popular ML technique among mature AI adopters, while deep learning is the most popular technique among organizations that are still evaluating AI.</li>\n<li>Though a problem, the lack of ML and AI skills isn’t the biggest impediment to AI adoption. Almost 22% of respondents identified a lack of institutional support as the most significant issue.</li>\n<li>Few organizations are using formal governance controls to support their AI efforts.</li>\n</ul>\n<p>The takeaway: AI adoption is proceeding apace. Most companies that were evaluating or experimenting with AI are now using it in production deployments. It’s still early, but companies need to do more to put their AI efforts on solid ground. Whether it’s controlling for common risk factors—bias in model development, missing or poorly conditioned data, the tendency of models to degrade in production—or instantiating formal processes to promote data governance, adopters will have their work cut out for them as they work to establish reliable AI production lines.</p>\n<h2>Respondent demographics</h2>\n<p>Survey respondents represent 25 different industries, with “Software” (~17%) as the largest distinct vertical. The sample is far from tech-laden, however: the only other explicit technology category—“Computers, Electronics, &amp; Hardware”—accounts for less than 7% of the sample. The “Other” category (~22%) comprises 12 separate industries.</p>\n<figure class=\"center\"><img alt=\"Industry of survey respondents\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/1-industry.png\"><figcaption>Figure 1. Industry of survey respondents.</figcaption></figure>\n<h3>Data scientists dominate, but executives are amply represented</h3>\n<p>One-sixth of respondents identify as data scientists, but executives—i.e., directors, vice presidents, and CxOs—account for about 26% of the sample. The survey does have a data-laden tilt, however: almost 30% of respondents identify as data scientists, data engineers, AIOps engineers, or as people who manage them. What is more, almost three-quarters of survey respondents say they work with data in their jobs. All told, more than 70% of respondents work in technology roles.</p>\n<figure class=\"center\"><img alt=\"Role of survey respondents\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/2-role.png\"><figcaption>Figure 2. Role of survey respondents.</figcaption></figure>\n<h3>Regional breakdown</h3>\n<p>Close to 50% of respondents work in North America, most of them in the United States, which by itself is home to almost 40% of survey participants. Western Europe (~23%) was the next largest region, followed by Asia at 15%. Participants from South America, Eastern Europe, Oceania, and Africa account for roughly 15% of responses.</p>\n<h2>Analysis: The state of AI adoption today</h2>\n<p id=\"F2\">More than half of respondent organizations are in the “mature” phase of AI adoption (using AI for analysis/production), while about one-third are still evaluating AI<a href=\"#_ftn2\"><sup><sup>[2]</sup></sup></a>. This is close to a mirror image of <a href=\"https://www.oreilly.com/data/free/ai-adoption-in-the-enterprise.csp\">last year’s AI survey results</a>, when 54% of respondent organizations were evaluating AI and just 27% were in the “mature” adoption phase. This year, about 15% of respondent organizations are not doing anything with AI, down ~20% from our 2019 survey.</p>\n<p>The upshot is that 85% of organizations are using AI, and (of these) most are using it in production. It seems as if the experimental AI projects of 2019 have borne fruit. But what kind?</p>\n<figure class=\"center\"><img alt=\"Where AI projects are being used within companies\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/3-functional-parts-of-companies.png\"><figcaption>Figure 3. Where AI projects are being used within companies.</figcaption></figure>\n<p>The bulk of AI use is in research and development—cited by just under half of all respondents—followed by IT, which was cited by just over one-third. (Respondents were encouraged to make multiple selections.) Another high-use functional area is customer service, with just under 30% of share. Two functional areas—marketing/advertising/PR and operations/facilities/fleet management—see usage share of about 20%. Clearly respondent organizations see the value of AI in a raft of different functional organizations, and the flat results from last year show a consistency to that pattern.</p>\n<h2>Common challenges to AI adoption</h2>\n<p>The acquisition and retention of AI-specific skills remains a significant impediment to adoption in most organizations. This year, slightly more than one-sixth of respondents cited difficulty in hiring/retaining people with AI skills as a significant barrier to AI adoption in their organizations. This is down, albeit slightly, from 2019, when 18% of respondents blamed an AI skills gap for lagging adoption.</p>\n<figure class=\"center\"><img alt=\"Bottlenecks to AI adoption\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/4-bottlenecks.png\"><figcaption>Figure 4. Bottlenecks to AI adoption.</figcaption></figure>\n<p>Believe it or not, a skills gap isn’t the biggest impediment to AI adoption. In 2020, as in 2019, a plurality of respondents—almost 22%—identified a lack of institutional support as the biggest problem. In both 2019 and 2020, the AI skills gap actually occupied the <em>No. 3</em> slot; this year, it trailed “Difficulties in identifying appropriate business use cases,” which was cited by 20% of respondents.</p>\n<p>A more detailed look at the bottleneck data shows executives selecting an unsupportive culture less often (15%) than the practitioners and managers (23%) who responded to the survey.</p>\n<figure class=\"center\"><img alt=\"Bottlenecks to AI adoption with AI maturity level\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/5-bottlenecks-with-maturity.png\"><figcaption>Figure 5. Bottlenecks to AI adoption with AI maturity level.</figcaption></figure>\n<p>By a 2:1 margin, respondents in companies that are evaluating AI are much more likely to cite an unsupportive culture as the primary bulwark to AI adoption. This disparity is striking—and intriguing. Is it just the case that late-adopters are <em>ipso facto</em> more resistant to—less open to—AI?</p>\n<p>By contrast, AI adopters are about one-third more likely to cite problems with missing or inconsistent data. We saw in our “<a href=\"https://www.oreilly.com/radar/the-state-of-data-quality-in-2020/\">State of Data Quality in 2020</a>” survey that ML and AI projects tend to surface latent or hidden data quality issues, with the result that organizations that are using ML and AI are more likely to identify issues with the quality or completeness of their data. The logic in this case partakes of <a href=\"https://en.wikipedia.org/wiki/Garbage_in%2C_garbage_out\">garbage-in, garbage out</a>: data scientists and ML engineers need quality data to train their models. Companies evaluating AI, by contrast, may not yet know to what extent data quality can create AI woes.</p>\n<h2>AI/ML skill shortages: Consistent and persistent</h2>\n<p>We asked survey respondents to identify the most critical ML- and AI-specific skills gaps in their organizations. The shortage of ML modelers and data scientists topped the list, cited by close to 58% of respondents. The challenge of understanding and maintaining a set of business use cases came in at number two, cited by almost half of participants. (Survey takers could choose more than one selection.) Close to 40% selected data engineering as a practice area for which skills are lacking. Finally, just under one quarter highlighted a lack of compute infrastructure skills.</p>\n<figure class=\"center\"><img alt=\"AI/ML skills gaps within organizations\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/6-skills-gaps.png\"><figcaption>Figure 6. AI/ML skills gaps within organizations.</figcaption></figure>\n<p>The most remarkable thing about these results is their year-over-year consistency. The same skill areas that were problematic in 2019 are again problematic in 2020—and by about the same margins. In 2019, 57% of respondents cited a lack of ML modeling and data science expertise as an impediment to ML adoption; this year, slightly more—close to 58%—did so. This is true of other in-demand skills, too. The uncomfortable truth is that the most critical skill shortages cannot easily be addressed. The data scientist, for example, is a hybrid creature: ideally, she should possess not only theoretical and technical expertise, but practical, domain-specific business expertise, too.</p>\n<p>This last is almost always acquired in practice, with the result that <a href=\"https://www.ft.com/content/428f1502-2b5c-11e8-9b4b-bc4b9f08f381\">the freshly minted data scientist</a> is invariably trained on the job. This helps explain why the proportion of respondents who cited a shortage of people skilled in understanding and maintaining business use cases increased year over year, from 47% in 2019 to 49% this year. The data scientist uses her domain-specific expertise to identify appropriate business use cases for AI. The ML modeler supplements her technical competency with domain-specific business knowledge that she accrues in practice. Both types of practitioner must also develop <a href=\"https://en.wikipedia.org/wiki/Soft_skills\">soft skills</a> in team work, listening, and, most important, <a href=\"https://www.infoq.com/articles/book-review-empathy-at-work/\">empathy</a>. This takes time and is a function of experience.</p>\n<h2>Managing AI/ML risk</h2>\n<p>We asked respondents to select all of the applicable risks they try to control for in building and deploying ML models. The results suggest that <em>all</em> organizations—especially those with “mature” AI practices—are alert to the risks inherent in the design and use of ML and AI technologies.</p>\n<figure class=\"center\"><img alt=\"Risks checked for during ML model building and deployment (with AI adoption maturity level)\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/7-risks.png\"><figcaption>Figure 7. Risks checked for during ML model building and deployment (with AI adoption maturity level).</figcaption></figure>\n<p>Unexpected outcomes/predictions was the single most common risk factor, cited by close to two-thirds of mature—and by about 53% of still-evaluating—AI practitioners. Among mature adopters, the need to control for the <a href=\"https://arxiv.org/pdf/1905.08883.pdf\">interpretability and transparency</a> of ML models was the second most common risk factor (cited by about 55%); by contrast, a different option—fairness, bias, and ethics (~40%)—was the No. 2 risk factor among companies still evaluating AI. It ranks high (No. 3) with mature AI practitioners, too: ~48% check for fairness and bias during model building and deployment.</p>\n<p>Mature AI practitioners are significantly more likely to implement checks for model degradation than companies that are still evaluating AI. Model degradation is the No. 4 risk factor among mature adopters (checked for by about 46%); however, it is next to last among organizations that are in the evaluation phase of AI adoption—finishing ahead of the “Other compliance” category.</p>\n<p>These risk factors are common, well understood, and don’t stand alone. With respondents able to pick “all that apply” to the question, we find that 41% of respondents list at least four issues, and 61% select at least three issues.</p>\n<h2>Supervised learning is dominant, deep learning continues to rise</h2>\n<p><a href=\"https://en.wikipedia.org/wiki/Supervised_learning\">Supervised learning</a> remains the most popular ML technique among all adopters. In 2019, more than 80% of mature adopters—and two-thirds of respondent organizations that were then evaluating AI—used it. And in 2020, almost 73% of self-identified “mature” AI practices are using it. (The survey questionnaire encouraged respondents to select all applicable techniques.)</p>\n<figure class=\"center\"><img alt=\"AI technologies organizations are using (with AI adoption maturity level)\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/8-ai-technologies.png\"><figcaption>Figure 8. AI technologies organizations are using (with AI adoption maturity level).</figcaption></figure>\n<p>This year, however, <a href=\"https://en.wikipedia.org/wiki/Deep_learning\">deep learning</a> displaced supervised learning as the most popular technique among organizations that are in the evaluation phase of AI adoption. To wit: in respondent organizations that are evaluating AI, slightly more say they’re using deep learning (~55%) than supervised learning (~54%). And close to 66% of respondents who work for “mature” AI adopters say they’re using deep learning, making it the second most popular technique in the mature cohort—behind supervised learning.</p>\n<p>It’s true that usage of all ML or AI techniques is greater among mature adopters than among organizations still evaluating AI. That said, there are a number of striking differences between mature and less mature AI adopters. For example, about 23% of “mature” AI practices use <a href=\"https://en.wikipedia.org/wiki/Transfer_learning\">transfer learning</a>, nearly double the rate of usage in less mature practices (12%). <a href=\"https://hai.stanford.edu/news/humans-loop-design-interactive-ai-systems\">Human-in-the-loop</a> AI models are considerably more popular among mature users than among those still evaluating AI.</p>\n<p>Selecting the right tool for the job has more than three-quarters (78%) of respondents selecting at least two of ML techniques, 59%, using at least three, and 39% choosing at least four.</p>\n<h2>The dominant tools aren’t getting any less dominant</h2>\n<p>TensorFlow remains, by far, the single most popular tool for use in AI-related work. It was cited by almost 55% of respondents in both 2019 and 2020, which gives it a creditable consistency over time.</p>\n<p>TensorFlow’s staying power also reinforces the fact that deep learning and neural networks—with which it is strongly associated—are far from niche techniques.</p>\n<figure class=\"center\"><img alt=\"AI tools organizations are using\" src=\"https://www.oreilly.com/radar/wp-content/uploads/sites/3/2020/02/9-ai-tools.png\"><figcaption>Figure 9. AI tools organizations are using.</figcaption></figure>\n<p>The most popular tools for AI development in 2019 were once again predominant in 2020. This could be a function of what we’ll call the “Python factor,” however: four of the five most popular tools for AI-related work are either Python-based or <a href=\"https://octoverse.github.com/\">dominated by Python tools, libraries, patterns, and projects</a>.</p>\n<p>Of these, TensorFlow, <a href=\"https://scikit-learn.org/stable/\">scikit-learn</a>, and <a href=\"https://en.wikipedia.org/wiki/Keras\">Keras</a> held steady, while PyTorch grew its share to more than 36%. This tracks with usage and search activity on the O’Reilly online learning platform, where interest in PyTorch has grown quickly from a relatively small base. Our <a href=\"https://www.oreilly.com/radar/oreilly-2020-platform-analysis\">analysis of Python-related activity on O’Reilly</a> likewise shows that Python is seeing explosive growth in ML and AI-related development.</p>\n<h2>Data governance isn’t yet a priority</h2>\n<p>Slightly more than one-fifth of respondent organizations have implemented formal data governance processes and/or tools to support and complement their AI projects. This is consistent with the results of <a href=\"https://www.oreilly.com/radar/the-state-of-data-quality-in-2020/\">our data quality survey</a>.</p>\n<p>The good news is that just over 26% of respondents say their organizations plan to instantiate formal data governance processes and/or tools by 2021; almost 35% expect this to happen in the next three years. The bad news is that AI adopters—much like organizations everywhere—seem to treat data governance as an additive rather than an essential ingredient.</p>\n<p>Ideally, <a href=\"https://en.wikipedia.org/wiki/Provenance#Science\">data provenance</a>, <a href=\"https://en.wikipedia.org/wiki/Data_lineage\">data lineage</a>, consistent <a href=\"https://en.wikipedia.org/wiki/Data_definition_specification\">data definitions</a>, rich <a href=\"https://en.wikipedia.org/wiki/Metadata_management\">metadata management</a>, and other essentials of good data governance would be baked into, not grafted on top of, an AI project.</p>\n<p>Think of data governance as analogous to <a href=\"https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/ch01.html\">observability</a> in software development: it is easier to build a capacity for observability into a system than to retrofit an existing system to make it observable. In the same way, it is easier to build a capacity for data governance into a system or service than to “add” it after the fact. Data governance is a data-specific take on observability that not only permits traceability and reproducibility, but permits transparency into what an AI asset is doing—and how it’s doing it.</p>\n<h2>Takeaways</h2>\n<p>A review of the survey results yields a few takeaways organizations can apply to their own AI projects.</p>\n<ul>\n<li>If you do not have plans to evaluate AI, it’s time to think about catching up. With an abundance of open source tools, libraries, tutorials, etc., not to mention an accessible <em>lingua franca</em>—Python—the bar for entry is actually pretty low. Most companies are experimenting with AI—why risk being left behind?</li>\n<li>AI projects align with dominant trends in software architecture and infrastructure and operations. AI features can be decomposed into functional primitives and instantiated as microservices—e.g., data cleansing services that profile data and generate statistics, perform deduplication and fuzzy matching, etc.—or function-as-a-service designs.</li>\n<li>Think broadly: AI is used everywhere, not just in R&amp;D and IT. A large share of survey respondents use AI in customer service, marketing, operations, finance, and other domains.</li>\n<li>Train your organization, too—not just your models. Institutional support remains the biggest barrier to AI adoption. If you think AI can help, you should spend time explaining how, why, and what to expect.</li>\n<li>The risks associated with AI implementation are consistent and now better understood. The upshot is that it’s easier to explain to executives and stakeholders what to expect in implementing AI projects.</li>\n</ul>\n<h2>Concluding thoughts</h2>\n<p>Clearly, we see AI practices maturing, even if many production use cases appear primitive. Adopters are also taking proactive steps to control for the most common risk factors. Both mature and not-so-mature adopters are experimenting with sophisticated techniques to build their AI products and services. Adopters are using a wide variety of ML and AI tools, but have coalesced around a single language—the ubiquitous, irrepressible Python. However, organizations need to address important data governance and data conditioning to expand and scale their AI practices.</p>\n<hr>\n<aside data-type=\"sidebar\">\n<p id=\"_ftn1\"><a href=\"#F1\"><sup><sup>[1]</sup></sup></a> We define “production” as the use of AI models in deployed applications that either serve users or are exposed as part of an automated, repeatable process—such as data collection, profiling, cleansing, and engineering. This is distinct from AI models that are used for static predictive analytics, categorization studies, natural language tasks, or for other analytic purposes.</p>\n<p id=\"_ftn2\"><a href=\"#F2\"><sup><sup>[2]</sup></sup></a> We asked participants to distinguish between “mature” adoption and “evaluation” on the basis of the following criteria: “None” (no use of AI in any projects); “Evaluation” (limited to trial evaluations and proofs-of-concept); “Analysis” (exploring, classifying, summarizing, and organizing data); and “Production” (revenue-bearing AI projects that are used in production). We group those respondents that selected “Analysis” and “Production” into our “mature” cohort.</p>\n</aside>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/51j23cc8IHc\" height=\"1\" width=\"1\" alt=\"\"/>\nIt’s an unprecedented crisis: 8 things to do right now\nhttp://feedproxy.google.com/~r/oreilly/radar/atom/~3/zsrywhHLzI8/\n<p>Even with a stellar crisis plan, the COVID-19 pandemic presents a set of challenges unprecedented in our lifetimes. We don’t know what’s going to happen, and we’re dealing with something growing exponentially, creating uncertainty on a global scale. I managed a team of 40 in Singapore during SARS. That crisis was different, hitting Singapore and a handful of other cities. But plenty of parallels exist: it was a health crisis, and the lessons learned might serve you and your organization well now. Here are some things to do immediately, including addressing issues around remote work, to ensure that business continues as usual.</p>\n<ol>\n<li><strong>This <em>is</em> your full-time job right now</strong>. Whatever was on your priority list last month, isn’t anymore. This is your full-time job right now. That means you may need to tell the C-suite that their pet project has been delayed, and you may need to tell employees that performance reviews and team meetings are on hold. You and your team may be working very long days in the coming weeks.</li>\n<li><strong>Push communications twice a day</strong>. In the arc of a crisis, we don’t know quite where we are—and that uncertainty can cause panic for some employees. News is coming out fast and good information is hard to come by. Create a morning and late afternoon update so your people know you are paying attention to their well-being. Share new information and repeat facts you already know. As we move from crisis to recovery—and we will recover—your updates can move from twice a day back to once a day and, then, less often.</li>\n<li><strong>Let go of perfection</strong>. It’s better to send out a revised set of rules everyday rather than being silent for days while executives try to land on the perfect policy and ideal language. Modify standard policies and make exceptions to long-held rules. Be transparent—it’s OK not to have all the answers because there are few definitive answers. Be transparent and say what you know and admit what you don’t know.</li>\n<li><strong>Monitor the CDC and your state health authorities</strong>. There will be rumors, fake news, and speculation. The only thing we know is that we have never been through this before. In 1918 during the Spanish Flu, it took days to cross the Atlantic and antibiotics hadn’t been invented. Because this is unprecedented in our modern world, the CDC and your state health authorities are doing admirable work providing the most reliable and trustworthy information.</li>\n<li><strong>People will respond very differently—prepare for that to cause problems</strong>. Some people may begin refusing to come to work—others might seem cavalier about COVID19. That divide may create serious friction in your organization. People who come to work begin to resent those who don’t. Those who stay home begin to believe that some of their co-workers don’t care about the health of families. After SARS, it took a long time to heal this split in the office. Acknowledge the split and that both points of view are valid.</li>\n<li><strong>Create new remote work guidelines—today</strong>. It doesn’t matter if you change these guidelines (see #3), just put out some basics. Is there a daily meeting? Will teams need to check in every day? What tools should they use? Should all meeting participants turn on their video? Whatever you decide—put out some guidelines so people have a place to start. You can modify these tomorrow and completely rewrite them when the crisis passes.</li>\n<li><strong>We may not return to “business as usual.”</strong> You are going to want to reassure people, and that may be an important part of your job. Tell people it will be OK—because it will. But be careful: don’t make any promises, because “OK” may not mean what it used to mean. Companies will likely make changes during the crisis or as things begin to recover. And, this may be an opportunity to change how your organization works. You are going to learn things about how your people learn, adapt, and improvise that will inform the new future.</li>\n<li><strong>Take care of yourself</strong>. This is a marathon not a sprint. And, to carry that metaphor forward, we don’t know the course of the marathon. We know some of you have been working around the clock—that’s not going to end tomorrow. If you aren’t healthy and grounded, you can’t see your team through this. Ground yourself; whatever gives you peace and contentment—you need that now, for you, for your family, and for the demands of your work.</li>\n</ol>\n<img src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/zsrywhHLzI8\" height=\"1\" width=\"1\" alt=\"\"/>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":" txt = \"Mr. Green killed Colonel Mustard in the study with the \\\n... candlestick. Mr. Green is not a very nice fellow.\"","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt.split(\".\")","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"['Mr',\n ' Green killed Colonel Mustard in the study with the candlestick',\n ' Mr',\n ' Green is not a very nice fellow',\n '']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install nltk","execution_count":20,"outputs":[{"output_type":"stream","text":"Collecting nltk\n  Downloading nltk-3.5.zip (1.4 MB)\n\u001b[K     |████████████████████████████████| 1.4 MB 2.8 MB/s eta 0:00:01\n\u001b[?25hCollecting click\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n\u001b[K     |████████████████████████████████| 82 kB 916 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.6/site-packages (from nltk) (0.14.1)\nCollecting regex\n  Downloading regex-2020.5.14-cp36-cp36m-manylinux2010_x86_64.whl (675 kB)\n\u001b[K     |████████████████████████████████| 675 kB 22.1 MB/s eta 0:00:01\n\u001b[?25hCollecting tqdm\n  Downloading tqdm-4.46.0-py2.py3-none-any.whl (63 kB)\n\u001b[K     |████████████████████████████████| 63 kB 790 kB/s  eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: nltk\n  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434675 sha256=36cb6aaf6a54f2b993911d068ed31469890639ae7c4f8b7bc802733abb6cfb39\n  Stored in directory: /home/jovyan/.cache/pip/wheels/de/5e/42/64abaeca668161c3e2cecc24f864a8fc421e3d07a104fc8a51\nSuccessfully built nltk\nInstalling collected packages: click, regex, tqdm, nltk\nSuccessfully installed click-7.1.2 nltk-3.5 regex-2020.5.14 tqdm-4.46.0\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('punkt')\ntxt = \"Mr. Green killed Colonel Mustard in the study with the  \\\n... candlestick. Mr. Green is not a very nice fellow.\"\ntxt = \"Mr. Green killed Colonel Mustard in the study with the \\\n... candlestick. Mr. Green is not a very nice fellow.\"\nsentences = nltk.tokenize.sent_tokenize(txt)\nsentences","execution_count":22,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n","name":"stderr"},{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"['Mr. Green killed Colonel Mustard in the study with the ... candlestick.',\n 'Mr. Green is not a very nice fellow.']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokens = [nltk.tokenize.word_tokenize(s) for s in sentences]\ntokens","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"[['Mr.',\n  'Green',\n  'killed',\n  'Colonel',\n  'Mustard',\n  'in',\n  'the',\n  'study',\n  'with',\n  'the',\n  '...',\n  'candlestick',\n  '.'],\n ['Mr.', 'Green', 'is', 'not', 'a', 'very', 'nice', 'fellow', '.']]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('averaged_perceptron_tagger')\npos_tagged_tokens = [nltk.pos_tag(t) for t in tokens]\npos_tagged_tokens","execution_count":25,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","name":"stderr"},{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"[[('Mr.', 'NNP'),\n  ('Green', 'NNP'),\n  ('killed', 'VBD'),\n  ('Colonel', 'NNP'),\n  ('Mustard', 'NNP'),\n  ('in', 'IN'),\n  ('the', 'DT'),\n  ('study', 'NN'),\n  ('with', 'IN'),\n  ('the', 'DT'),\n  ('...', ':'),\n  ('candlestick', 'NN'),\n  ('.', '.')],\n [('Mr.', 'NNP'),\n  ('Green', 'NNP'),\n  ('is', 'VBZ'),\n  ('not', 'RB'),\n  ('a', 'DT'),\n  ('very', 'RB'),\n  ('nice', 'JJ'),\n  ('fellow', 'NN'),\n  ('.', '.')]]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install batch_ne_chunk","execution_count":30,"outputs":[{"output_type":"stream","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement batch_ne_chunk (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for batch_ne_chunk\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nne_chunks = nltk.batch_ne_chunk(pos_tagged_tokens)\nprint (ne_chunks)","execution_count":32,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'nltk' has no attribute 'batch_ne_chunk'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-e439b626a2fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mne_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_ne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tagged_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mne_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'batch_ne_chunk'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install feedparser\n","execution_count":4,"outputs":[{"output_type":"stream","text":"Collecting feedparser\n  Downloading feedparser-5.2.1.tar.bz2 (192 kB)\n\u001b[K     |████████████████████████████████| 192 kB 3.0 MB/s eta 0:00:01     |████████████                    | 71 kB 2.9 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: feedparser\n  Building wheel for feedparser (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for feedparser: filename=feedparser-5.2.1-py3-none-any.whl size=44939 sha256=2804d96d191ec22162eb1aa042675732ec141be8b2def7c657c6948f5d498e5a\n  Stored in directory: /home/jovyan/.cache/pip/wheels/2f/70/50/16138238f6447854a1300f7d457766789dc7122cfaf46bcef2\nSuccessfully built feedparser\nInstalling collected packages: feedparser\nSuccessfully installed feedparser-5.2.1\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install beautifulsoup4\n","execution_count":9,"outputs":[{"output_type":"stream","text":"Collecting beautifulsoup4\n  Downloading beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n\u001b[K     |████████████████████████████████| 115 kB 3.5 MB/s eta 0:00:01\n\u001b[?25hCollecting soupsieve>1.2\n  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\nInstalling collected packages: soupsieve, beautifulsoup4\nSuccessfully installed beautifulsoup4-4.9.1 soupsieve-2.0.1\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport nltk\n\n# Download nltk packages used in this example\nnltk.download('stopwords')\n\nBLOG_DATA = \"feed.json\"\n\nblog_data = json.loads(open(BLOG_DATA).read())\n\n# Customize your list of stopwords as needed. Here, we add common\n# punctuation and contraction artifacts.\n\nstop_words = nltk.corpus.stopwords.words('english') + [\n    '.',\n    ',',\n    '--',\n    '\\'s',\n    '?',\n    ')',\n    '(',\n    ':',\n    '\\'',\n    '\\'re',\n    '\"',\n    '-',\n    '}',\n    '{',\n    u'—',\n    ]\n\nfor post in blog_data:\n    sentences = nltk.tokenize.sent_tokenize(post['content'])\n\n    words = [w.lower() for sentence in sentences for w in\n             nltk.tokenize.word_tokenize(sentence)]\n\n    fdist = nltk.FreqDist(words)\n\n    # Basic stats\n\n    num_words = sum([i[1] for i in fdist.items()])\n    num_unique_words = len(fdist.keys())\n\n    # Hapaxes are words that appear only once\n\n    num_hapaxes = len(fdist.hapaxes())\n\n    top_10_words_sans_stop_words = [w for w in fdist.items() if w[0]\n                                    not in stop_words][:10]\n\n    print (post['title'])\n    print ('\\tNum Sentences:'.ljust(25), len(sentences))\n    print ('\\tNum Words:'.ljust(25), num_words)\n    print ('\\tNum Unique Words:'.ljust(25), num_unique_words)\n    print ('\\tNum Hapaxes:'.ljust(25), num_hapaxes)\n    print ('\\tTop 10 Most Frequent Words (sans stop words):\\n\\t\\t', \\\n            '\\n\\t\\t'.join(['%s (%s)'\n            % (w[0], w[1]) for w in top_10_words_sans_stop_words]))\n    print()","execution_count":37,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stderr"},{"output_type":"stream","text":"Four short links: 21 August 2017\n\tNum Sentences:           10\n\tNum Words:               250\n\tNum Unique Words:        153\n\tNum Hapaxes:             112\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t cloud (4)\n\t\toperations (2)\n\t\tmachine (2)\n\t\tlearning (2)\n\t\tradio (2)\n\t\tflying (2)\n\t\tcameras (2)\n\t\ttext (2)\n\t\torganization (1)\n\t\tparacloud (2)\n\n6 practical guidelines for implementing conversational AI\n\tNum Sentences:           69\n\tNum Words:               1733\n\tNum Unique Words:        625\n\tNum Hapaxes:             380\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t organizations (3)\n\t\tcreate (1)\n\t\tfluid (2)\n\t\tinteractions (6)\n\t\thumans (3)\n\t\tmachines.it (1)\n\t\tseven (1)\n\t\tyears (1)\n\t\tsince (2)\n\t\tapple (1)\n\nFour short links: 18 August 2017\n\tNum Sentences:           16\n\tNum Words:               534\n\tNum Unique Words:        271\n\tNum Hapaxes:             199\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t neural (2)\n\t\tstyle (3)\n\t\ttransfer (2)\n\t\thype (9)\n\t\tcycles (3)\n\t\tautomation (2)\n\t\tjobs (5)\n\t\tbecome (2)\n\t\tbayesian (4)\n\t\toverview (1)\n\nHow Ray makes continuous learning accessible and easy to scale\n\tNum Sentences:           5\n\tNum Words:               148\n\tNum Unique Words:        90\n\tNum Hapaxes:             61\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ’ (1)\n\t\treilly (1)\n\t\tdata (3)\n\t\tshow (2)\n\t\tpodcast (1)\n\t\trobert (2)\n\t\tnishihara (2)\n\t\tphilipp (2)\n\t\tmoritz (2)\n\t\tnew (1)\n\nJulie Stanford on vetting designs through rapid experimentation\n\tNum Sentences:           3\n\tNum Words:               82\n\tNum Unique Words:        57\n\tNum Hapaxes:             41\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ’ (2)\n\t\treilly (1)\n\t\tdesign (5)\n\t\tpodcast (2)\n\t\tquickly (1)\n\t\ttest (1)\n\t\tideas (1)\n\t\tlike (1)\n\t\tthinker.in (1)\n\t\tweek (1)\n\nJack Daniel on building community and historical context in InfoSec\n\tNum Sentences:           2\n\tNum Words:               86\n\tNum Unique Words:        51\n\tNum Hapaxes:             36\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t o'reilly (1)\n\t\tsecurity (3)\n\t\tpodcast (2)\n\t\trole (1)\n\t\tcommunity (4)\n\t\tproliferation (1)\n\t\tbsides (2)\n\t\tinfosec (2)\n\t\tevents (1)\n\t\tcelebrating (1)\n\nFour short links: 17 August 2017\n\tNum Sentences:           11\n\tNum Words:               329\n\tNum Unique Words:        193\n\tNum Hapaxes:             152\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t implementing (1)\n\t\tcompression (1)\n\t\teliminating (2)\n\t\thumans (1)\n\t\tmapping (2)\n\t\tnes (2)\n\t\tclassifying (1)\n\t\tdefects (1)\n\t\timplementation (1)\n\t\tminimum (1)\n\nContouring learning rate to optimize neural nets\n\tNum Sentences:           115\n\tNum Words:               2697\n\tNum Unique Words:        770\n\tNum Hapaxes:             455\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t tips (1)\n\t\ttricks (1)\n\t\ttreating (1)\n\t\tlearning (70)\n\t\trate (45)\n\t\thyperparameter (5)\n\t\tusing (3)\n\t\tvisualizations (4)\n\t\tsee (3)\n\t\t’ (16)\n\nCreating better disaster recovery plans\n\tNum Sentences:           73\n\tNum Words:               1514\n\tNum Unique Words:        500\n\tNum Hapaxes:             300\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t five (1)\n\t\tquestions (1)\n\t\ttanya (3)\n\t\treilly (3)\n\t\tservice (3)\n\t\tinterdependencies (3)\n\t\tmake (6)\n\t\trecovery (8)\n\t\tharder (2)\n\t\t’ (3)\n\nAnnouncing the Rebecca Bace Pioneer Award for Defensive Security\n\tNum Sentences:           34\n\tNum Words:               836\n\tNum Unique Words:        341\n\tNum Hapaxes:             228\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t carrying (1)\n\t\tbecky (17)\n\t\tbace (10)\n\t\t’ (8)\n\t\tlegacy (1)\n\t\tencouraging (1)\n\t\tcelebrating (1)\n\t\tdefenders.in (1)\n\t\tkeynote (1)\n\t\treilly (4)\n\nHow synthetic biology startups are building the future at RebelBio\n\tNum Sentences:           132\n\tNum Words:               3047\n\tNum Unique Words:        1101\n\tNum Hapaxes:             724\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t accelerator (5)\n\t\thelping (1)\n\t\tscientists (2)\n\t\tturn (2)\n\t\tmoonshot (2)\n\t\tvisions (2)\n\t\tviable (1)\n\t\tbusinesses (1)\n\t\tfast (1)\n\t\tbiology (18)\n\nThe impact of design at Shopify\n\tNum Sentences:           87\n\tNum Words:               1644\n\tNum Unique Words:        577\n\tNum Hapaxes:             371\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t five (1)\n\t\tquestions (2)\n\t\tcynthia (3)\n\t\tsavard (2)\n\t\tsaucier (2)\n\t\tdesign (16)\n\t\timpacts (1)\n\t\tshopify (6)\n\t\t’ (26)\n\t\tbusiness (5)\n\nTake the 2018 Data Science Salary Survey\n\tNum Sentences:           5\n\tNum Words:               79\n\tNum Unique Words:        52\n\tNum Hapaxes:             38\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t data (2)\n\t\tprofessional (1)\n\t\tinvited (1)\n\t\tshare (1)\n\t\tvaluable (1)\n\t\tinsights (1)\n\t\thelp (1)\n\t\tus (1)\n\t\tgain (1)\n\t\tinsight (1)\n\nFour short links: 16 August 2017\n\tNum Sentences:           13\n\tNum Words:               294\n\tNum Unique Words:        180\n\tNum Hapaxes:             127\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t iot (2)\n\t\thacking (1)\n\t\tvirtual (3)\n\t\tschool (1)\n\t\tfails (1)\n\t\tneural (4)\n\t\tnetwork (3)\n\t\tnlp (1)\n\t\tusing (2)\n\t\tlogical (2)\n\nFour short links: 15 August 2017\n\tNum Sentences:           19\n\tNum Words:               393\n\tNum Unique Words:        200\n\tNum Hapaxes:             135\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t p (4)\n\t\t! (1)\n\t\t= (1)\n\t\tnp (4)\n\t\topen (2)\n\t\tsource (2)\n\t\tlab (2)\n\t\tnotebook (2)\n\t\tscience (3)\n\t\tdata (3)\n\nHow to use Presto Sketching to clarify your team’s purpose\n\tNum Sentences:           44\n\tNum Words:               1198\n\tNum Unique Words:        367\n\tNum Hapaxes:             231\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t team (31)\n\t\tpurpose (24)\n\t\tmap (10)\n\t\tvisually (2)\n\t\tguide (3)\n\t\tcapture (3)\n\t\t’ (33)\n\t\tdiscussions (2)\n\t\tidentity (3)\n\t\tdirection.this (1)\n\nFour short links: 14 August 2017\n\tNum Sentences:           9\n\tNum Words:               222\n\tNum Unique Words:        142\n\tNum Hapaxes:             103\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t robotics (3)\n\t\tinterviews (3)\n\t\tcustomer (2)\n\t\tdevelopment (2)\n\t\tengineering (2)\n\t\tmethod (2)\n\t\tcomplex (3)\n\t\tsystem (1)\n\t\tfailures (6)\n\t\tmike (1)\n\nA multi-cloud strategy is the foundation for digital transformation\n\tNum Sentences:           32\n\tNum Words:               974\n\tNum Unique Words:        431\n\tNum Hapaxes:             311\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t using (4)\n\t\tsingle (2)\n\t\tcloud (15)\n\t\tprovider (1)\n\t\tthing (1)\n\t\tpast.when (1)\n\t\tnews (1)\n\t\tbroke (1)\n\t\tamazon (2)\n\t\tacquiring (1)\n\nHow to choose a cloud provider\n\tNum Sentences:           60\n\tNum Words:               1121\n\tNum Unique Words:        392\n\tNum Hapaxes:             246\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t practical (1)\n\t\tquestions (5)\n\t\thelp (1)\n\t\tmake (6)\n\t\tdecision.if (1)\n\t\tlook (2)\n\t\tphrase (1)\n\t\t“ (2)\n\t\tboiling (1)\n\t\tocean (1)\n\nFour short links: 11 August 2017\n\tNum Sentences:           14\n\tNum Words:               358\n\tNum Unique Words:        208\n\tNum Hapaxes:             156\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t cracking (2)\n\t\twi-fi (3)\n\t\thacking (1)\n\t\tdna (5)\n\t\tanimation (2)\n\t\tplaythings (1)\n\t\tphysics (2)\n\t\tsimulation (4)\n\t\tbrief (1)\n\t\twalk-through (1)\n\nMike Roberts on serverless architectures\n\tNum Sentences:           3\n\tNum Words:               91\n\tNum Unique Words:        53\n\tNum Hapaxes:             34\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ’ (3)\n\t\treilly (3)\n\t\tprogramming (2)\n\t\tpodcast (2)\n\t\tnext (2)\n\t\ttechnological (1)\n\t\tevolution (1)\n\t\tcloud (2)\n\t\tsystems.in (1)\n\t\tepisode (1)\n\nHow to craft a voice user interface that won’t leave you frustrated\n\tNum Sentences:           1\n\tNum Words:               24\n\tNum Unique Words:        23\n\tNum Hapaxes:             22\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t design (1)\n\t\tprinciples (1)\n\t\tcreating (1)\n\t\ttruly (1)\n\t\tconversational (1)\n\t\tui.continue (1)\n\t\treading (1)\n\t\tcraft (1)\n\t\tvoice (1)\n\t\tuser (1)\n\nFour short links: 10 August 2017\n\tNum Sentences:           8\n\tNum Words:               226\n\tNum Unique Words:        143\n\tNum Hapaxes:             103\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t sarcasm (3)\n\t\tdetector (1)\n\t\tgmo (2)\n\t\tsalmon (5)\n\t\tnew (2)\n\t\tdeep (2)\n\t\tlearning (2)\n\t\tcourses (2)\n\t\tserverless (2)\n\t\tmalware (2)\n\nFour short links: 9 August 2017\n\tNum Sentences:           10\n\tNum Words:               291\n\tNum Unique Words:        179\n\tNum Hapaxes:             136\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t event (7)\n\t\ttrend (2)\n\t\tdetection (3)\n\t\tseparation (2)\n\t\tduties (2)\n\t\tonline (2)\n\t\tcommunities (2)\n\t\tautonomous (3)\n\t\ttractors (2)\n\t\tcomplete (1)\n\nDeep learning revolutionizes conversational AI\n\tNum Sentences:           120\n\tNum Words:               2412\n\tNum Unique Words:        663\n\tNum Hapaxes:             366\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t recent (9)\n\t\tai (17)\n\t\tbreakthroughs (5)\n\t\ttransform (1)\n\t\tspeech (54)\n\t\trecognition.the (1)\n\t\tdream (1)\n\t\trecognition (41)\n\t\tsystem (18)\n\t\ttruly (2)\n\nCancer detection, one slice at a time\n\tNum Sentences:           67\n\tNum Words:               1456\n\tNum Unique Words:        564\n\tNum Hapaxes:             389\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t new (2)\n\t\ttechnology (1)\n\t\tallowing (2)\n\t\tresearchers (7)\n\t\tuse (2)\n\t\tdigitization (2)\n\t\thelp (2)\n\t\tdetect (3)\n\t\tcancer (10)\n\t\tke (19)\n\nIntegrating data with AI\n\tNum Sentences:           17\n\tNum Words:               584\n\tNum Unique Words:        271\n\tNum Hapaxes:             184\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t tamr (3)\n\t\t’ (10)\n\t\teliot (2)\n\t\tknudsen (7)\n\t\talgorithms (1)\n\t\twork (3)\n\t\talongside (2)\n\t\thuman (3)\n\t\texperts.as (1)\n\t\tcompanies (1)\n\nJupyter Insights: Lorena Barba, an associate professor of mechanical and aerospace engineering\n\tNum Sentences:           45\n\tNum Words:               747\n\tNum Unique Words:        347\n\tNum Hapaxes:             248\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t jupyter (15)\n\t\teducation (3)\n\t\tjupyter-in-the-loop (2)\n\t\treproducibility (4)\n\t\tscience.lorena (1)\n\t\tbarba (3)\n\t\tassociate (2)\n\t\tprofessor (2)\n\t\tmechanical (2)\n\t\taerospace (2)\n\nFour short links: 8 August 2017\n\tNum Sentences:           7\n\tNum Words:               142\n\tNum Unique Words:        91\n\tNum Hapaxes:             65\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t better (1)\n\t\tbloom (2)\n\t\tfilter (2)\n\t\tai (3)\n\t\tfuture (2)\n\t\tadversarial (2)\n\t\tbenchmarking (2)\n\t\tcivilized (2)\n\t\tdiscourse​ (1)\n\t\tgeneral-purpose (1)\n\nWhy continuous learning is key to AI\n\tNum Sentences:           45\n\tNum Words:               1086\n\tNum Unique Words:        433\n\tNum Hapaxes:             270\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t look (4)\n\t\tahead (2)\n\t\ttools (5)\n\t\tmethods (1)\n\t\tlearning (31)\n\t\tsparse (2)\n\t\tfeedback.as (1)\n\t\tcompanies (5)\n\t\tbegin (2)\n\t\texperiment (1)\n\nFour short links: 7 August 2017\n\tNum Sentences:           8\n\tNum Words:               275\n\tNum Unique Words:        158\n\tNum Hapaxes:             118\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t social (4)\n\t\tagents (1)\n\t\tcomputational (4)\n\t\tzoom (4)\n\t\tliving (1)\n\t\tmemory (1)\n\t\tai (3)\n\t\tpolicy (2)\n\t\tprom (1)\n\t\tweek (1)\n\nHow to move your team closer to clarity\n\tNum Sentences:           36\n\tNum Words:               708\n\tNum Unique Words:        329\n\tNum Hapaxes:             240\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t design (10)\n\t\tthinking (8)\n\t\tlean (7)\n\t\tapproach (1)\n\t\tagile (8)\n\t\tsoftware (6)\n\t\tdevelopment (3)\n\t\tmake (2)\n\t\tdifference (1)\n\t\tteams.despite (1)\n\nFour short links: 4 August 2017\n\tNum Sentences:           6\n\tNum Words:               262\n\tNum Unique Words:        158\n\tNum Hapaxes:             117\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t chinese (1)\n\t\tspamsorship (1)\n\t\thistory (2)\n\t\tintelligence (2)\n\t\tpatreon (2)\n\t\tnumbers (1)\n\t\tjavascript (2)\n\t\twtfs (1)\n\t\tquackspeak (2)\n\t\tascendant (1)\n\nJupyterHub on Google Cloud\n\tNum Sentences:           67\n\tNum Words:               2062\n\tNum Unique Words:        595\n\tNum Hapaxes:             345\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t step-by-step (1)\n\t\ttutorial (3)\n\t\tinstall (14)\n\t\trun (8)\n\t\tjupyterhub (36)\n\t\tgcloud (12)\n\t\tdeploying (3)\n\t\tkubernetes (7)\n\t\tgoogle (6)\n\t\tcloud (5)\n\nWhy AI and machine learning researchers are beginning to embrace PyTorch\n","name":"stdout"},{"output_type":"stream","text":"\tNum Sentences:           5\n\tNum Words:               150\n\tNum Unique Words:        97\n\tNum Hapaxes:             71\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ’ (1)\n\t\treilly (1)\n\t\tdata (2)\n\t\tshow (2)\n\t\tpodcast (1)\n\t\tsoumith (2)\n\t\tchintala (3)\n\t\tbuilding (1)\n\t\tworthy (1)\n\t\tsuccessor (2)\n\nA DevOps approach to data management\n\tNum Sentences:           26\n\tNum Words:               646\n\tNum Unique Words:        285\n\tNum Hapaxes:             185\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t multi-model (4)\n\t\tapproach (3)\n\t\ttransforming (1)\n\t\tdata (24)\n\t\tliability (1)\n\t\tasset (1)\n\t\tderiving (1)\n\t\tknowledge (1)\n\t\tbecome (2)\n\t\tkey (2)\n\nFour short links: 3 August 2017\n\tNum Sentences:           12\n\tNum Words:               247\n\tNum Unique Words:        153\n\tNum Hapaxes:             115\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t pricing (1)\n\t\tunicorns (2)\n\t\tsoftware (1)\n\t\tfailures (1)\n\t\tfinding (2)\n\t\tprices (1)\n\t\tsimulating (1)\n\t\tpoverty (3)\n\t\tmade (1)\n\t\tone (1)\n\nDeclaring variables in Kotlin\n\tNum Sentences:           1\n\tNum Words:               22\n\tNum Unique Words:        20\n\tNum Hapaxes:             18\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t learn (1)\n\t\tdifference (1)\n\t\tmutable (1)\n\t\timmutable (1)\n\t\tvariables (2)\n\t\tcut (1)\n\t\tboilerplate (1)\n\t\tcode.continue (1)\n\t\treading (1)\n\t\tdeclaring (1)\n\nBuilding—and scaling—a reliable distributed architecture\n\tNum Sentences:           7\n\tNum Words:               184\n\tNum Unique Words:        109\n\tNum Hapaxes:             78\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t five (1)\n\t\tquestions (1)\n\t\tjoseph (3)\n\t\tbreuer (2)\n\t\trobert (3)\n\t\treta (2)\n\t\tmanaging (3)\n\t\tdependencies (3)\n\t\tbuilding (1)\n\t\tadaptability (1)\n\nOperationalizing security risk\n\tNum Sentences:           1\n\tNum Words:               17\n\tNum Unique Words:        16\n\tNum Hapaxes:             15\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t bruce (1)\n\t\tpotter (1)\n\t\tbuild (1)\n\t\trisk (2)\n\t\tassessment (1)\n\t\tprogram.continue (1)\n\t\treading (1)\n\t\toperationalizing (1)\n\t\tsecurity (1)\n\nReinforcement learning for complex goals, using TensorFlow\n\tNum Sentences:           112\n\tNum Words:               2861\n\tNum Unique Words:        698\n\tNum Hapaxes:             382\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t build (3)\n\t\tclass (2)\n\t\trl (5)\n\t\tagents (6)\n\t\tusing (7)\n\t\ttensorflow (8)\n\t\tnotebook.reinforcement (1)\n\t\tlearning (18)\n\t\ttraining (12)\n\t\tcomplete (1)\n\nJay Jacobs on data analytics and security\n\tNum Sentences:           2\n\tNum Words:               90\n\tNum Unique Words:        46\n\tNum Hapaxes:             25\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ’ (2)\n\t\treilly (2)\n\t\tsecurity (6)\n\t\tpodcast (2)\n\t\tprevalence (1)\n\t\tconvenient (2)\n\t\tdata (8)\n\t\tfirst (2)\n\t\tsteps (2)\n\t\ttoward (2)\n\nFour short links: 2 August 2017\n\tNum Sentences:           11\n\tNum Words:               215\n\tNum Unique Words:        143\n\tNum Hapaxes:             110\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t app (3)\n\t\tsize (1)\n\t\tdecision-making (1)\n\t\theadless (2)\n\t\tchrome (2)\n\t\tscientific (2)\n\t\tsignificance (2)\n\t\tsizes (2)\n\t\tcontrol (1)\n\t\tamen (1)\n\nThe wisdom hierarchy: From signals to artificial intelligence and beyond\n\tNum Sentences:           73\n\tNum Words:               1563\n\tNum Unique Words:        535\n\tNum Hapaxes:             340\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t framework (2)\n\t\tmoving (3)\n\t\tdata (37)\n\t\twisdom.we (1)\n\t\tswimming (1)\n\t\tpossibly (2)\n\t\tdrowning (1)\n\t\torganizations (1)\n\t\tindividuals (1)\n\t\tgenerating (2)\n\nFour short links: 1 August 2017\n\tNum Sentences:           9\n\tNum Words:               255\n\tNum Unique Words:        162\n\tNum Hapaxes:             125\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t rna (2)\n\t\tcoding (2)\n\t\tx86 (3)\n\t\tfuzzing (1)\n\t\t1960s (2)\n\t\tai (3)\n\t\ttraps (1)\n\t\tliving (1)\n\t\tprogrammable (1)\n\t\tbiocomputing (1)\n\nHow can I add simple, automated data visualizations and dashboards to Jupyter Notebooks\n\tNum Sentences:           1\n\tNum Words:               37\n\tNum Unique Words:        28\n\tNum Hapaxes:             21\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t learn (1)\n\t\tuse (1)\n\t\tpixiedust (1)\n\t\tjupyter (2)\n\t\tnotebooks (2)\n\t\tcreate (1)\n\t\tquick (1)\n\t\teasy (1)\n\t\tpowerful (1)\n\t\tvisualizations (2)\n\nFrom prototype to product with hybrid neural networks\n\tNum Sentences:           33\n\tNum Words:               1028\n\tNum Unique Words:        431\n\tNum Hapaxes:             286\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t apache (2)\n\t\tmxnet (6)\n\t\tmiddle (1)\n\t\tpath (1)\n\t\tdeclarative (7)\n\t\timperative (6)\n\t\tprogramming.after (1)\n\t\tseveral (3)\n\t\tdecades (1)\n\t\tinterest (2)\n\nFour short links: 31 July 2017\n\tNum Sentences:           9\n\tNum Words:               288\n\tNum Unique Words:        180\n\tNum Hapaxes:             136\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t statistics (2)\n\t\t& (1)\n\t\tfiction (3)\n\t\tstaying (1)\n\t\tanonymous (3)\n\t\tattacking (1)\n\t\tmachine (2)\n\t\tlearning (2)\n\t\tdigital (2)\n\t\tnative (2)\n\nFour short links: 28 July 2017\n\tNum Sentences:           13\n\tNum Words:               253\n\tNum Unique Words:        155\n\tNum Hapaxes:             118\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t usable (2)\n\t\tsecurity (3)\n\t\tphilosophy (2)\n\t\ttime (2)\n\t\tar (1)\n\t\ta-ha (3)\n\t\tmachine (4)\n\t\tknitting (3)\n\t\trant (1)\n\t\tjessie (1)\n\nEric Freeman and Elisabeth Robson on design patterns\n\tNum Sentences:           2\n\tNum Words:               92\n\tNum Unique Words:        62\n\tNum Hapaxes:             43\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ’ (2)\n\t\treilly (2)\n\t\tprogramming (2)\n\t\tpodcast (2)\n\t\tcreating (1)\n\t\tdesigns (1)\n\t\tflexible (1)\n\t\tresilient (1)\n\t\tchange.in (1)\n\t\tepisode (1)\n\nJohn Whalen on using brain science in design\n\tNum Sentences:           2\n\tNum Words:               124\n\tNum Unique Words:        81\n\tNum Hapaxes:             58\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ’ (3)\n\t\treilly (1)\n\t\tdesign (3)\n\t\tpodcast (2)\n\t\tdesigning (1)\n\t\t“ (2)\n\t\tsix (2)\n\t\tminds (2)\n\t\t” (2)\n\t\timportance (1)\n\nWhen you hear hooves, think horse, not zebra\n\tNum Sentences:           9\n\tNum Words:               236\n\tNum Unique Words:        153\n\tNum Hapaxes:             120\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t n't (1)\n\t\tovercomplicate (1)\n\t\tcybersecurity (1)\n\t\tfocus (1)\n\t\tbuilding (1)\n\t\tstrong (1)\n\t\tsecurity (1)\n\t\tfoundation (1)\n\t\tgo (1)\n\t\tthere.a (1)\n\nClassifying traffic signs with Apache MXNet: An introduction to computer vision with neural networks\n\tNum Sentences:           93\n\tNum Words:               3896\n\tNum Unique Words:        924\n\tNum Hapaxes:             503\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t step-by-step (1)\n\t\tinstructions (1)\n\t\timplement (3)\n\t\tconvolutional (3)\n\t\tneural (18)\n\t\tnet (1)\n\t\tusing (9)\n\t\tjupyter (4)\n\t\tnotebook.although (1)\n\t\tmany (1)\n\nFour short links: 27 July 2017\n\tNum Sentences:           6\n\tNum Words:               164\n\tNum Unique Words:        114\n\tNum Hapaxes:             93\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t next (2)\n\t\tdeath (1)\n\t\tevolution (2)\n\t\ttrust (3)\n\t\tindoor (2)\n\t\trobots (2)\n\t\tembryo (1)\n\t\tediting (1)\n\t\tpredicting (1)\n\t\tdies (1)\n\nR’s tidytext turns messy text into valuable insight\n\tNum Sentences:           48\n\tNum Words:               1321\n\tNum Unique Words:        448\n\tNum Hapaxes:             274\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t authors (1)\n\t\tjulia (2)\n\t\tsilge (3)\n\t\tdavid (2)\n\t\trobinson (3)\n\t\tdiscuss (2)\n\t\tpower (2)\n\t\ttidy (8)\n\t\tdata (24)\n\t\tprinciples (3)\n\nFour short links: 26 July 2017\n\tNum Sentences:           9\n\tNum Words:               243\n\tNum Unique Words:        161\n\tNum Hapaxes:             124\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t blockchain (2)\n\t\tsecurities (3)\n\t\tlaw (1)\n\t\tlow-energy (1)\n\t\tsensing (1)\n\t\trobotics (2)\n\t\tdeep (2)\n\t\tlearning (2)\n\t\tchipped (1)\n\t\temployees (4)\n\nMaking great hires in your design organization\n\tNum Sentences:           1\n\tNum Words:               21\n\tNum Unique Words:        19\n\tNum Hapaxes:             17\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t help (1)\n\t\tteam (1)\n\t\tsucceed (1)\n\t\tdevelop (1)\n\t\tstronger (1)\n\t\tdesign (2)\n\t\tpractice.continue (1)\n\t\treading (1)\n\t\tmaking (1)\n\t\tgreat (1)\n\nA lesson in prescriptive modeling\n\tNum Sentences:           1\n\tNum Words:               17\n\tNum Unique Words:        17\n\tNum Hapaxes:             17\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t simulate (1)\n\t\tnew (1)\n\t\tbusiness (1)\n\t\tmodels (1)\n\t\tpractices (1)\n\t\topen (1)\n\t\tsource (1)\n\t\tcode.continue (1)\n\t\treading (1)\n\t\tlesson (1)\n\nFour short links: 25 July 2017\n\tNum Sentences:           12\n\tNum Words:               232\n\tNum Unique Words:        151\n\tNum Hapaxes:             117\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t ai (3)\n\t\tsentencing (2)\n\t\tvocabulary (1)\n\t\tsoft (3)\n\t\tu2f (4)\n\t\tencrypted (2)\n\t\temail (2)\n\t\topening (1)\n\t\tlid (1)\n\t\tcriminal (1)\n\nData science startups focus on AI-enabled efficiency\n\tNum Sentences:           25\n\tNum Words:               577\n\tNum Unique Words:        307\n\tNum Hapaxes:             235\n\tTop 10 Most Frequent Words (sans stop words):\n\t\t recapping (1)\n\t\twinners (3)\n\t\tstrata (2)\n\t\tsan (2)\n\t\tjose (2)\n\t\tstartup (2)\n\t\tshowcase.every (1)\n\t\tfive (1)\n\t\tyears (2)\n\t\tinvent (1)\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Class outline:\n\n* A quick installation check of [ipython](https://ipython.org/install.html) and [jupyter notebook](https://jupyter.readthedocs.io/en/latest/install.html)\n* An overview of the IPython project from [the official website](http://ipython.org), and [jupyter](https://jupyter.org)\n* Super basic intro to the notebook: typing code.\n* [Notebook Basics](examples/Notebook/Notebook%20Basics.ipynb)\n* [IPython - beyond plain python](examples/IPython%20Kernel/Beyond%20Plain%20Python.ipynb)\n* [Markdown Cells](examples/Notebook/Working%20With%20Markdown%20Cells.ipynb)\n* [Rich Display System](examples/IPython%20Kernel/Rich%20Output.ipynb)\n* [Custom Display logic](examples/IPython%20Kernel/Custom%20Display%20Logic.ipynb)\n* [Customizing IPython - a condensed version](exercises/Customization/Condensed.ipynb)\n* [Running a Secure Public Notebook Server](examples/Notebook/Running%20the%20Notebook%20Server.ipynb#Securing-the-notebook-server)\n* [How Jupyter/IPython works](examples/Notebook/Multiple%20Languages%2C%20Frontends.ipynb) to run code in different languages."},{"metadata":{},"cell_type":"markdown","source":"Get this tutorial:\n\n    git clone https://github.com/ipython/ipython-in-depth\n\nInstall IPython and Jupyter:\n\nwith [conda](https://www.continuum.io/downloads):\n\n    conda install ipython jupyter\n\nwith pip:\n\n    # first, upgrade pip!\n    pip install --upgrade pip\n    pip install --upgrade ipython jupyter\n\nStart the notebook in the tutorial directory:\n\n    cd ipython-in-depth\n    jupyter notebook"},{"metadata":{},"cell_type":"markdown","source":"There are a lot more detailed notebooks in this same directory that cover other topics, but we can not cover all in a 3-hour tutorial. We encourage you to explore them and practice on your own."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}